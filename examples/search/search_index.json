{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the TTK Examples! \u00b6 This website hosts a list of data analysis pipelines exemplifying the usage of TTK with ParaView and its Python API pvpython . This website is targeting novice users who are not power users of ParaView but who would like to get started with topological data analysis with TTK in Python. Each example includes: a screenshot (or a tutorial video) a short description the command line to reproduce the example with ParaView the corresponding Python code, to: load the input data execute the analysis pipeline store the output to disk (for later analysis or visualization, e.g. with ParaView ) a description of the inputs and outputs pointers to the corresponding C++/Python documentation This documentation assumes a default TTK installation (with the pvpython API support enabled) and that the repository ttk-data has been downloaded locally. If you have any questions regarding these examples, please let us know by sending an email to the TTK user mailing list ! Scalar data \u00b6 Name Screenshot Dragon Morse persistence Built-in example 1 Interaction site Viscous fingering Morse molecule Tectonic puzzle Ocean vortices ! Contour around point CT bones Tribute Image processing Persistence driven compression Morse-Smale quadrangulation Bivariate scalar data \u00b6 Name Screenshot Built-in example 2 Bivariate toy Bivariate toy CSP peeling Mechanical Uncertain scalar data \u00b6 Name Screenshot Built-in example 3 Uncertain starting vortex Time-varying scalar data \u00b6 Name Screenshot Time tracking Merge tree feature tracking Merge tree temporal reduction Nested tracking graph Ensemble scalar data \u00b6 Name Screenshot Persistence diagram distance Persistence diagram clustering Merge tree clustering Contour tree alignment High-dimensional / point cloud data \u00b6 Name Screenshot Persistence clustering gallery Persistence clustering0 Persistence clustering1 Persistence clustering2 Persistence clustering3 Persistence clustering4 Karhunen-Love Digits 64-Dimensions 1-manifold learning 1-manifold learning circles 2-manifold learning In-situ features \u00b6 Name Screenshot Geometry approximation Cinema darkroom Misc features \u00b6 Name Screenshot Cinema IO Manifold checks","title":"Welcome to the TTK Examples!"},{"location":"#welcome-to-the-ttk-examples","text":"This website hosts a list of data analysis pipelines exemplifying the usage of TTK with ParaView and its Python API pvpython . This website is targeting novice users who are not power users of ParaView but who would like to get started with topological data analysis with TTK in Python. Each example includes: a screenshot (or a tutorial video) a short description the command line to reproduce the example with ParaView the corresponding Python code, to: load the input data execute the analysis pipeline store the output to disk (for later analysis or visualization, e.g. with ParaView ) a description of the inputs and outputs pointers to the corresponding C++/Python documentation This documentation assumes a default TTK installation (with the pvpython API support enabled) and that the repository ttk-data has been downloaded locally. If you have any questions regarding these examples, please let us know by sending an email to the TTK user mailing list !","title":"Welcome to the TTK Examples!"},{"location":"#scalar-data","text":"Name Screenshot Dragon Morse persistence Built-in example 1 Interaction site Viscous fingering Morse molecule Tectonic puzzle Ocean vortices ! Contour around point CT bones Tribute Image processing Persistence driven compression Morse-Smale quadrangulation","title":"Scalar data"},{"location":"#bivariate-scalar-data","text":"Name Screenshot Built-in example 2 Bivariate toy Bivariate toy CSP peeling Mechanical","title":"Bivariate scalar data"},{"location":"#uncertain-scalar-data","text":"Name Screenshot Built-in example 3 Uncertain starting vortex","title":"Uncertain scalar data"},{"location":"#time-varying-scalar-data","text":"Name Screenshot Time tracking Merge tree feature tracking Merge tree temporal reduction Nested tracking graph","title":"Time-varying scalar data"},{"location":"#ensemble-scalar-data","text":"Name Screenshot Persistence diagram distance Persistence diagram clustering Merge tree clustering Contour tree alignment","title":"Ensemble scalar data"},{"location":"#high-dimensional-point-cloud-data","text":"Name Screenshot Persistence clustering gallery Persistence clustering0 Persistence clustering1 Persistence clustering2 Persistence clustering3 Persistence clustering4 Karhunen-Love Digits 64-Dimensions 1-manifold learning 1-manifold learning circles 2-manifold learning","title":"High-dimensional / point cloud data"},{"location":"#in-situ-features","text":"Name Screenshot Geometry approximation Cinema darkroom","title":"In-situ features"},{"location":"#misc-features","text":"Name Screenshot Cinema IO Manifold checks","title":"Misc features"},{"location":"1manifoldLearning/","text":"1-Manifold Learning \u00b6 Pipeline description \u00b6 This example first loads a point cloud from disk. In a pre-processing, the DimensionReduction is used to reduce the dimension of the input to 2D points. The data is then converted to a format understandable by Paraview using the TableToPoints filter. GaussianResampling is applied to the data (upper left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting SplatterValues field is a density estimation (with a Gaussian kernel) of the point cloud projected in 2D. Then, the PersistenceDiagram of a slice of the obtained data is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram. The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. Only certain maximal edges are displayed here: using thresholds, the edges connecting at least one critical point situated in the boundary are discarded. This way, the \"S\" shape made by the point cloud is outlined. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/1manifoldLearning.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' pointCloudcsv = CSVReader ( FileName = [ 'pointCloud.csv' ]) # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = pointCloudcsv , ModulePath = 'default' ) tTKDimensionReduction1 . InputColumns = [ 'Points:0' , 'Points:1' , 'Points:2' ] tTKDimensionReduction1 . UseAllCores = 0 # create a new 'Table To Points' tableToPoints2 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints2 . XColumn = 'Component_0' tableToPoints2 . YColumn = 'Component_1' tableToPoints2 . a2DPoints = 1 # create a new 'Gaussian Resampling' gaussianResampling2 = GaussianResampling ( Input = tableToPoints2 ) gaussianResampling2 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling2 . ResamplingGrid = [ 128 , 64 , 3 ] gaussianResampling2 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling2 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 3.0 , 999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold2 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold3 = Threshold ( Input = threshold2 ) threshold3 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold3 ) tTKGeometrySmoother1 . IterationNumber = 100 SaveData ( 'OutputArc.vtu' , tTKGeometrySmoother1 ) Inputs \u00b6 pointCloud.csv : a table containing point coordinates. Outputs \u00b6 OutputArc.vtu : edges (or 1 dimensional elements) of the output Morse Smale Complex that are not connected to any boundary critical point in VTK file format (right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 DimensionReduction GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"1-Manifold Learning"},{"location":"1manifoldLearning/#1-manifold-learning","text":"","title":"1-Manifold Learning"},{"location":"1manifoldLearning/#pipeline-description","text":"This example first loads a point cloud from disk. In a pre-processing, the DimensionReduction is used to reduce the dimension of the input to 2D points. The data is then converted to a format understandable by Paraview using the TableToPoints filter. GaussianResampling is applied to the data (upper left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting SplatterValues field is a density estimation (with a Gaussian kernel) of the point cloud projected in 2D. Then, the PersistenceDiagram of a slice of the obtained data is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram. The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. Only certain maximal edges are displayed here: using thresholds, the edges connecting at least one critical point situated in the boundary are discarded. This way, the \"S\" shape made by the point cloud is outlined.","title":"Pipeline description"},{"location":"1manifoldLearning/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/1manifoldLearning.pvsm","title":"ParaView"},{"location":"1manifoldLearning/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' pointCloudcsv = CSVReader ( FileName = [ 'pointCloud.csv' ]) # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = pointCloudcsv , ModulePath = 'default' ) tTKDimensionReduction1 . InputColumns = [ 'Points:0' , 'Points:1' , 'Points:2' ] tTKDimensionReduction1 . UseAllCores = 0 # create a new 'Table To Points' tableToPoints2 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints2 . XColumn = 'Component_0' tableToPoints2 . YColumn = 'Component_1' tableToPoints2 . a2DPoints = 1 # create a new 'Gaussian Resampling' gaussianResampling2 = GaussianResampling ( Input = tableToPoints2 ) gaussianResampling2 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling2 . ResamplingGrid = [ 128 , 64 , 3 ] gaussianResampling2 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling2 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 3.0 , 999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold2 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold3 = Threshold ( Input = threshold2 ) threshold3 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold3 ) tTKGeometrySmoother1 . IterationNumber = 100 SaveData ( 'OutputArc.vtu' , tTKGeometrySmoother1 )","title":"Python code"},{"location":"1manifoldLearning/#inputs","text":"pointCloud.csv : a table containing point coordinates.","title":"Inputs"},{"location":"1manifoldLearning/#outputs","text":"OutputArc.vtu : edges (or 1 dimensional elements) of the output Morse Smale Complex that are not connected to any boundary critical point in VTK file format (right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"1manifoldLearning/#cpython-api","text":"DimensionReduction GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"1manifoldLearningCircles/","text":"1-Manifold Learning Circles \u00b6 Pipeline description \u00b6 This example first loads a point cloud from disk. The points are arranged in mainly two concentric circles, one bigger than the other. In a pre-processing, the data is converted to a format understandable by Paraview using the TableToPoints filter (upper left view, above screenshot). GaussianResampling is applied to the data. This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. Only a slice of the data is kept (upper right, above screenshot). The resulting SplatterValues field is a density estimation (with a Gaussian kernel) of the point cloud in 2D. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom left view, above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (bottom right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. The generators of the clusters are edges of the Morse-Smale Complex. Not all edges of the Complex are useful: using thresholds, only the separatrices connected to maxima are kept ( Separatrix = 1 ). Then the edges with the field SeparatrixFunctionMinimum below a certain value (here 2) are also discarded. This corresponds to the two green and yellow generators (bottom right view, above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/1manifoldLearningCircles.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold2 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold3 = Threshold ( Input = threshold2 ) threshold3 . Scalars = [ 'CELLS' , 'SeparatrixFunctionMinimum' ] threshold3 . ThresholdRange = [ 2.0 , 999.0 ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the ouput SaveData ( 'Clustering.csv' , resampleWithDataset1 ) SaveData ( 'Generators.vtu' , threshold3 ) Inputs \u00b6 clustering0.csv : a table containing 2D point coordinates arranged in concentric circles. Outputs \u00b6 Clustering.csv : Resampled dataset to store the clustering (field AscendingManifold ). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. Generators.vtu : edges (or 1 dimensional elements) of the output Morse Smale Complex after passing through two thresholds in VTK file format (bottom right view, above screenshot). Only the edges connected to maximam with the field SeparatrixFunctionMinimum below 2 are saved in this file. You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"1-Manifold Learning Circles"},{"location":"1manifoldLearningCircles/#1-manifold-learning-circles","text":"","title":"1-Manifold Learning Circles"},{"location":"1manifoldLearningCircles/#pipeline-description","text":"This example first loads a point cloud from disk. The points are arranged in mainly two concentric circles, one bigger than the other. In a pre-processing, the data is converted to a format understandable by Paraview using the TableToPoints filter (upper left view, above screenshot). GaussianResampling is applied to the data. This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. Only a slice of the data is kept (upper right, above screenshot). The resulting SplatterValues field is a density estimation (with a Gaussian kernel) of the point cloud in 2D. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom left view, above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (bottom right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. The generators of the clusters are edges of the Morse-Smale Complex. Not all edges of the Complex are useful: using thresholds, only the separatrices connected to maxima are kept ( Separatrix = 1 ). Then the edges with the field SeparatrixFunctionMinimum below a certain value (here 2) are also discarded. This corresponds to the two green and yellow generators (bottom right view, above screenshot).","title":"Pipeline description"},{"location":"1manifoldLearningCircles/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/1manifoldLearningCircles.pvsm","title":"ParaView"},{"location":"1manifoldLearningCircles/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold2 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold3 = Threshold ( Input = threshold2 ) threshold3 . Scalars = [ 'CELLS' , 'SeparatrixFunctionMinimum' ] threshold3 . ThresholdRange = [ 2.0 , 999.0 ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the ouput SaveData ( 'Clustering.csv' , resampleWithDataset1 ) SaveData ( 'Generators.vtu' , threshold3 )","title":"Python code"},{"location":"1manifoldLearningCircles/#inputs","text":"clustering0.csv : a table containing 2D point coordinates arranged in concentric circles.","title":"Inputs"},{"location":"1manifoldLearningCircles/#outputs","text":"Clustering.csv : Resampled dataset to store the clustering (field AscendingManifold ). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. Generators.vtu : edges (or 1 dimensional elements) of the output Morse Smale Complex after passing through two thresholds in VTK file format (bottom right view, above screenshot). Only the edges connected to maximam with the field SeparatrixFunctionMinimum below 2 are saved in this file. You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"1manifoldLearningCircles/#cpython-api","text":"GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"2manifoldLearning/","text":"2-Manifold Learning \u00b6 Pipeline description \u00b6 This example first loads a point cloud from disk. In a pre-processing, the data is converted to a format understandable by Paraview using the TableToPoints filter. GaussianResampling is applied to the data (left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting scalar field is a density estimation (with a Gaussian kernel) of the input point cloud. Then, the PersistenceDiagram is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram. The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 4 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces, and dimension 3, which corresponds to pieces of volume that can be extracted from the Segmentation output. The \"S\" shape made by the point cloud is outlined by the maximal 1 and 2 dimension elements of the Morse-Smale Complex. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/2manifoldLearning.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' pointCloudcsv = CSVReader ( FileName = [ 'pointCloud.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = pointCloudcsv ) tableToPoints1 . XColumn = 'Points:0' tableToPoints1 . YColumn = 'Points:1' tableToPoints1 . ZColumn = 'Points:2' # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 64 , 64 , 128 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = gaussianResampling1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 9999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.01 , 0.999953171649318 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = gaussianResampling1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . ReturnSaddleConnectors = 1 tTKMorseSmaleComplex1 . SaddleConnectorsPersistenceThreshold = 0.01 # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = tetrahedralize1 ) tTKGeometrySmoother2 . IterationNumber = 20 tTKGeometrySmoother2 . InputMaskField = [ None , '' ] SaveData ( 'OutputSurface.vtu' , tTKGeometrySmoother2 ) Inputs \u00b6 pointCloud.csv : a table containing point coordinates. Outputs \u00b6 OutputSurface.vtu : surface (or 2 dimensional elements) of the output Morse Smale Complex in VTK file format (right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"2-Manifold Learning"},{"location":"2manifoldLearning/#2-manifold-learning","text":"","title":"2-Manifold Learning"},{"location":"2manifoldLearning/#pipeline-description","text":"This example first loads a point cloud from disk. In a pre-processing, the data is converted to a format understandable by Paraview using the TableToPoints filter. GaussianResampling is applied to the data (left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting scalar field is a density estimation (with a Gaussian kernel) of the input point cloud. Then, the PersistenceDiagram is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram. The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 4 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces, and dimension 3, which corresponds to pieces of volume that can be extracted from the Segmentation output. The \"S\" shape made by the point cloud is outlined by the maximal 1 and 2 dimension elements of the Morse-Smale Complex.","title":"Pipeline description"},{"location":"2manifoldLearning/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/2manifoldLearning.pvsm","title":"ParaView"},{"location":"2manifoldLearning/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' pointCloudcsv = CSVReader ( FileName = [ 'pointCloud.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = pointCloudcsv ) tableToPoints1 . XColumn = 'Points:0' tableToPoints1 . YColumn = 'Points:1' tableToPoints1 . ZColumn = 'Points:2' # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 64 , 64 , 128 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = gaussianResampling1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 9999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.01 , 0.999953171649318 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = gaussianResampling1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . ReturnSaddleConnectors = 1 tTKMorseSmaleComplex1 . SaddleConnectorsPersistenceThreshold = 0.01 # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = tetrahedralize1 ) tTKGeometrySmoother2 . IterationNumber = 20 tTKGeometrySmoother2 . InputMaskField = [ None , '' ] SaveData ( 'OutputSurface.vtu' , tTKGeometrySmoother2 )","title":"Python code"},{"location":"2manifoldLearning/#inputs","text":"pointCloud.csv : a table containing point coordinates.","title":"Inputs"},{"location":"2manifoldLearning/#outputs","text":"OutputSurface.vtu : surface (or 2 dimensional elements) of the output Morse Smale Complex in VTK file format (right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"2manifoldLearning/#cpython-api","text":"GeometrySmoother MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"BuiltInExample1/","text":"Built in example 1 \u00b6 Pipeline description \u00b6 This example computes minima, maxima and the persistence diagram for 2D flow data (von Karman vortex street). First, the data is transformed and preprocessed to estimate the vorticity of the flow (via the orthogonal component of the curl). Then, the PersistenceDiagram and PersistenceCurve are computed. To the persistence diagram, a threshold is applied to remove the diagonal. The output are the persistence pairs. These pairs are filtered based on persistence to maintain only the most persistent features. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification and the 2D domain is embedded into 3D space based on the scalar values. Finally, the Critical Points of the simplified and warped data are computed. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/BuiltInExample1.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample1.vti' ]) # create a new 'Transform' transform1 = Transform ( Input = builtInExamplevti ) transform1 . Transform = 'Transform' # init the 'Transform' selected for 'Transform' transform1 . Transform . Rotate = [ 0.0 , 0.0 , - 90.0 ] # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = transform1 ) #computeDerivatives1.Scalars = [None, ''] computeDerivatives1 . Vectors = [ 'POINTS' , 'Vectors_' ] computeDerivatives1 . OutputVectorType = 'Vorticity' # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = 'myVorticity' calculator1 . Function = 'Vorticity_Z' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = tTKScalarFieldNormalizer1 ) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tetrahedralize1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Threshold' persistencePairs = Threshold ( Input = tTKPersistenceDiagram1 ) persistencePairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] persistencePairs . ThresholdRange = [ - 0.1 , 957.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = persistencePairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.02 , 1.0 ] # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = tetrahedralize1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tetrahedralize1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = tTKTopologicalSimplification1 ) warpByScalar1 . Scalars = [ 'POINTS' , 'myVorticity' ] warpByScalar1 . ScaleFactor = 300.0 # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = warpByScalar1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # save the output SaveData ( 'warpedInput.vtu' , warpByScalar1 ) SaveData ( 'CriticalPoints.csv' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) Inputs \u00b6 BuiltInExample1.vti : a two-dimensional regular grid encoding flow magnitude of a K\u00e1rm\u00e1n vortex street. Outputs \u00b6 warpedInput.vtu : the warped and tetrahedralized scalar field in VTK file format (middle view, above screenshot). CriticalPoints.csv : the critical points of the warped scalar field in csv format (middle view, above screenshot). PersistenceCurve.csv : the output persistence curve (top right view, above screenshot). PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 PersistenceCurve PersistenceDiagram TopologicalSimplification Critical Points","title":"Built in example 1"},{"location":"BuiltInExample1/#built-in-example-1","text":"","title":"Built in example 1"},{"location":"BuiltInExample1/#pipeline-description","text":"This example computes minima, maxima and the persistence diagram for 2D flow data (von Karman vortex street). First, the data is transformed and preprocessed to estimate the vorticity of the flow (via the orthogonal component of the curl). Then, the PersistenceDiagram and PersistenceCurve are computed. To the persistence diagram, a threshold is applied to remove the diagonal. The output are the persistence pairs. These pairs are filtered based on persistence to maintain only the most persistent features. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification and the 2D domain is embedded into 3D space based on the scalar values. Finally, the Critical Points of the simplified and warped data are computed.","title":"Pipeline description"},{"location":"BuiltInExample1/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/BuiltInExample1.pvsm","title":"ParaView"},{"location":"BuiltInExample1/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample1.vti' ]) # create a new 'Transform' transform1 = Transform ( Input = builtInExamplevti ) transform1 . Transform = 'Transform' # init the 'Transform' selected for 'Transform' transform1 . Transform . Rotate = [ 0.0 , 0.0 , - 90.0 ] # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = transform1 ) #computeDerivatives1.Scalars = [None, ''] computeDerivatives1 . Vectors = [ 'POINTS' , 'Vectors_' ] computeDerivatives1 . OutputVectorType = 'Vorticity' # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = 'myVorticity' calculator1 . Function = 'Vorticity_Z' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = tTKScalarFieldNormalizer1 ) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tetrahedralize1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Threshold' persistencePairs = Threshold ( Input = tTKPersistenceDiagram1 ) persistencePairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] persistencePairs . ThresholdRange = [ - 0.1 , 957.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = persistencePairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.02 , 1.0 ] # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = tetrahedralize1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tetrahedralize1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = tTKTopologicalSimplification1 ) warpByScalar1 . Scalars = [ 'POINTS' , 'myVorticity' ] warpByScalar1 . ScaleFactor = 300.0 # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = warpByScalar1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # save the output SaveData ( 'warpedInput.vtu' , warpByScalar1 ) SaveData ( 'CriticalPoints.csv' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 ))","title":"Python code"},{"location":"BuiltInExample1/#inputs","text":"BuiltInExample1.vti : a two-dimensional regular grid encoding flow magnitude of a K\u00e1rm\u00e1n vortex street.","title":"Inputs"},{"location":"BuiltInExample1/#outputs","text":"warpedInput.vtu : the warped and tetrahedralized scalar field in VTK file format (middle view, above screenshot). CriticalPoints.csv : the critical points of the warped scalar field in csv format (middle view, above screenshot). PersistenceCurve.csv : the output persistence curve (top right view, above screenshot). PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"BuiltInExample1/#cpython-api","text":"PersistenceCurve PersistenceDiagram TopologicalSimplification Critical Points","title":"C++/Python API"},{"location":"cinemaIO/","text":"CinemaIO \u00b6 Pipeline description \u00b6 This example first loads a cinema database of a simulation from disk, consisting of three dimensional image files, using the CinemaReader . This outputs a vtkTable. The database is queried for a selection of images, using CinemaQuery , which supports SQL queries on vtkTables (bottom view shows query result in a spreadsheet view). Each selected entry in the database is read by the CinemaProductReader , which outputs a vtkMultiBlock of the images. The images are sliced with a plane, and each slice is visualized side-by-side using the GridLayout (top view in screenshot). ForEach is used to loop through all slices, and then the ArrayEditor is used to add a FieldData value to each slice. In this case, we add the interval SampleInterval between each queried entry. Each slice is then written to a new cinema database with the CinemaWriter . Finally, the for-loop is terminated using EndFor . ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/cinemaIO.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' viscousFingerscdb = TTKCinemaReader ( DatabasePath = 'ViscousFingers.cdb' ) # create a new 'TTK CinemaQuery' tTKCinemaQuery1 = TTKCinemaQuery ( InputTable = viscousFingerscdb ) tTKCinemaQuery1 . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE Sim='run01' AND Time%10=0 ORDER BY Time LIMIT 8 OFFSET 1\"\"\" # create a new 'TTK CinemaProductReader' tTKCinemaProductReader1 = TTKCinemaProductReader ( Input = tTKCinemaQuery1 ) # create a new 'Slice' slice1 = Slice ( Input = tTKCinemaProductReader1 ) slice1 . SliceType = 'Plane' slice1 . HyperTreeGridSlicer = 'Plane' slice1 . SliceOffsetValues = [ 0.0 ] # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Origin = [ 31.5 , 31.5 , 31.5 ] # create a new 'TTK GridLayout' tTKGridLayout1 = TTKGridLayout ( Input = slice1 ) tTKGridLayout1 . ColumnAxis = 'Y' tTKGridLayout1 . ColumnGap = 8.0 tTKGridLayout1 . RowAxis = 'Z' tTKGridLayout1 . NumberofRows = 1 # create a new 'TTK ForEach' tTKForEach1 = TTKForEach ( Input = tTKGridLayout1 ) tTKForEach1 . IterationMode = 'Block' tTKForEach1 . InputArray = [ 'POINTS' , 'ImageFile' ] tTKForEach1 . OutputType = 'vtkPolyData' # create a new 'TTK ArrayEditor' tTKArrayEditor1 = TTKArrayEditor ( Target = tTKForEach1 , Source = None ) tTKArrayEditor1 . TargetAttributeType = 'Field Data' tTKArrayEditor1 . DataString = 'SampleInterval, 10' tTKArrayEditor1 . TargetArray = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK CinemaWriter' tTKCinemaWriter1 = TTKCinemaWriter ( Input = tTKArrayEditor1 , DatabasePath = 'ViscousFingersSampled.cdb' ) tTKCinemaWriter1 . ScalarField = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK EndFor' tTKEndFor1 = TTKEndFor ( Data = tTKCinemaWriter1 , For = tTKForEach1 ) UpdatePipeline () Inputs \u00b6 ViscousFingers.cdb : a cinema database of VTK Image files from a simulation. Outputs \u00b6 ViscousFingersSampled.cdb : a cinema database containing the sampled slices of the input cinema database. C++/Python API \u00b6 CinemaReader CinemaQuery CinemaProductReader GridLayout ForEach ArrayEditor CinemaWriter EndFor","title":"CinemaIO"},{"location":"cinemaIO/#cinemaio","text":"","title":"CinemaIO"},{"location":"cinemaIO/#pipeline-description","text":"This example first loads a cinema database of a simulation from disk, consisting of three dimensional image files, using the CinemaReader . This outputs a vtkTable. The database is queried for a selection of images, using CinemaQuery , which supports SQL queries on vtkTables (bottom view shows query result in a spreadsheet view). Each selected entry in the database is read by the CinemaProductReader , which outputs a vtkMultiBlock of the images. The images are sliced with a plane, and each slice is visualized side-by-side using the GridLayout (top view in screenshot). ForEach is used to loop through all slices, and then the ArrayEditor is used to add a FieldData value to each slice. In this case, we add the interval SampleInterval between each queried entry. Each slice is then written to a new cinema database with the CinemaWriter . Finally, the for-loop is terminated using EndFor .","title":"Pipeline description"},{"location":"cinemaIO/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/cinemaIO.pvsm","title":"ParaView"},{"location":"cinemaIO/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' viscousFingerscdb = TTKCinemaReader ( DatabasePath = 'ViscousFingers.cdb' ) # create a new 'TTK CinemaQuery' tTKCinemaQuery1 = TTKCinemaQuery ( InputTable = viscousFingerscdb ) tTKCinemaQuery1 . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE Sim='run01' AND Time%10=0 ORDER BY Time LIMIT 8 OFFSET 1\"\"\" # create a new 'TTK CinemaProductReader' tTKCinemaProductReader1 = TTKCinemaProductReader ( Input = tTKCinemaQuery1 ) # create a new 'Slice' slice1 = Slice ( Input = tTKCinemaProductReader1 ) slice1 . SliceType = 'Plane' slice1 . HyperTreeGridSlicer = 'Plane' slice1 . SliceOffsetValues = [ 0.0 ] # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Origin = [ 31.5 , 31.5 , 31.5 ] # create a new 'TTK GridLayout' tTKGridLayout1 = TTKGridLayout ( Input = slice1 ) tTKGridLayout1 . ColumnAxis = 'Y' tTKGridLayout1 . ColumnGap = 8.0 tTKGridLayout1 . RowAxis = 'Z' tTKGridLayout1 . NumberofRows = 1 # create a new 'TTK ForEach' tTKForEach1 = TTKForEach ( Input = tTKGridLayout1 ) tTKForEach1 . IterationMode = 'Block' tTKForEach1 . InputArray = [ 'POINTS' , 'ImageFile' ] tTKForEach1 . OutputType = 'vtkPolyData' # create a new 'TTK ArrayEditor' tTKArrayEditor1 = TTKArrayEditor ( Target = tTKForEach1 , Source = None ) tTKArrayEditor1 . TargetAttributeType = 'Field Data' tTKArrayEditor1 . DataString = 'SampleInterval, 10' tTKArrayEditor1 . TargetArray = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK CinemaWriter' tTKCinemaWriter1 = TTKCinemaWriter ( Input = tTKArrayEditor1 , DatabasePath = 'ViscousFingersSampled.cdb' ) tTKCinemaWriter1 . ScalarField = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK EndFor' tTKEndFor1 = TTKEndFor ( Data = tTKCinemaWriter1 , For = tTKForEach1 ) UpdatePipeline ()","title":"Python code"},{"location":"cinemaIO/#inputs","text":"ViscousFingers.cdb : a cinema database of VTK Image files from a simulation.","title":"Inputs"},{"location":"cinemaIO/#outputs","text":"ViscousFingersSampled.cdb : a cinema database containing the sampled slices of the input cinema database.","title":"Outputs"},{"location":"cinemaIO/#cpython-api","text":"CinemaReader CinemaQuery CinemaProductReader GridLayout ForEach ArrayEditor CinemaWriter EndFor","title":"C++/Python API"},{"location":"contourTreeAlignment/","text":"Contour Tree Alignment \u00b6 Pipeline description \u00b6 This example first loads a scalar field ensemble from disk as a cinema data base. The ensemble consists of 23 time-dependent scalar fields with 10 time steps each. The ensemble is then filtered for the 23 scalar fields of one fixed time point and read as a vtkMultiBlockDataSet. Here we use the CinemaReader , CinemaQuery and CinemaProductReader filters. In a pre-processing, the scalar fields are topologically simplified by persistence using the TopologicalSimplificationByPersistence filter. The filter is automatically applied to each member of the MultiBlockDataSet. Then, for each simplified member field, the contour tree is computed using the FTMTree module. The resulting MultiBlock of contour trees is then used as input for the Contour Tree Alignment filter. This alignment is a super tree of all contour trees and can be seen as a representative of the topology of the whole ensemble. Unfortunately, the vtk object representing the alignment does not have any layout information attached. Therefore, we use the PlanarGraphLayout together with a paraview calculator to compute and apply the layout information. We now want to check which features of the original scalar fields have been matched onto each other. Therefore, we use the ExtractSeletion filter to extract one vertex and attach its segmentationIDs array to the multi block data set representing the segmentations of the contour trees. We also use a Grid Layout to render the multi block in a comparable fashion (right view, above screenshot). As a last step, we use the ForEach and EndFor filters to iterate the multi block of segmentations and in each iteration, we extract the region of the scalar field that corresponds to the segmentation id from the selected vertex. The extraction is done using the TTKExtract filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/contourTreeAlignment.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' ttkCinemaReader = TTKCinemaReader ( DatabasePath = './heatedCylinder/heatedCylinder_2D_raw.cdb' ) # create a new 'TTK CinemaQuery' ttkCinemaQuery = TTKCinemaQuery ( InputTable = ttkCinemaReader ) ttkCinemaQuery . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE time=4.2\"\"\" # create a new 'TTK CinemaProductReader' ttkCinemaProductReader = TTKCinemaProductReader ( Input = ttkCinemaQuery ) # create a new 'TTK TopologicalSimplificationByPersistence' ttkTopologicalSimplificationByPersistence = TTKTopologicalSimplificationByPersistence ( Input = ttkCinemaProductReader ) ttkTopologicalSimplificationByPersistence . InputArray = [ 'POINTS' , 'nrrd' ] ttkTopologicalSimplificationByPersistence . PersistenceThreshold = 0.05 # create a new 'TTK Merge and Contour Tree (FTM)' ttkMergeandContourTreeFTM = TTKMergeandContourTreeFTM ( Input = ttkTopologicalSimplificationByPersistence ) ttkMergeandContourTreeFTM . ScalarField = [ 'POINTS' , 'nrrd' ] # create a new 'TTK ContourTreeAlignment' contourTreeAlignment = TTKContourTreeAlignment ( Input = OutputPort ( ttkMergeandContourTreeFTM , 1 ), ExportPath = '' ) contourTreeAlignment . ScalarField = [ 'POINTS' , 'Scalar' ] contourTreeAlignment . Regionsizearray = [ 'CELLS' , 'RegionSize' ] contourTreeAlignment . SegmentationIDarrayforCT = [ 'CELLS' , 'SegmentationId' ] contourTreeAlignment . SegmentIDarrayforsegmentation = [ 'POINTS' , 'Scalar' ] # create a new 'TTK PlanarGraphLayout' alignmentLayout = TTKPlanarGraphLayout ( Input = contourTreeAlignment ) alignmentLayout . SequenceArray = [ 'POINTS' , 'Scalar' ] alignmentLayout . SizeArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . UseBranches = 1 alignmentLayout . BranchArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . LevelArray = [ 'POINTS' , 'BranchIDs' ] # create a new 'Calculator' alignmentEdges = Calculator ( Input = alignmentLayout ) alignmentEdges . CoordinateResults = 1 alignmentEdges . Function = 'iHat*Layout_Y+jHat*Scalar*3' # create a query selection QuerySelect ( QueryString = '(id == 16)' , Source = alignmentEdges , FieldType = 'POINT' , InsideOut = 0 ) # create a new 'Extract Selection' selectedVertex = ExtractSelection ( Input = alignmentEdges ) # create a new 'TTK GridLayout' segmentationsGrid = TTKGridLayout ( Input = OutputPort ( ttkMergeandContourTreeFTM , 2 )) segmentationsGrid . ColumnGap = 10.0 segmentationsGrid . RowGap = 10.0 # create a new 'TTK ForEach' ttkForEach = TTKForEach ( Input = segmentationsGrid ) ttkForEach . InputArray = [ 'POINTS' , 'SegmentationId' ] ttkForEach . ImageExtent = [ 0 , 127 , 0 , 255 , 0 , 0 ] # create a new 'Merge Blocks' mergeBlocks = MergeBlocks ( Input = ttkForEach ) # create a new 'TTK ArrayEditor' passSegmentationIDs = TTKArrayEditor ( Target = mergeBlocks , Source = selectedVertex ) passSegmentationIDs . EditorMode = 'Add Arrays from Source' passSegmentationIDs . TargetAttributeType = 'Field Data' passSegmentationIDs . SourcePointDataArrays = [ 'segmentationIDs' ] passSegmentationIDs . TargetArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK Extract' extractMatchedGeometry = TTKExtract ( Input = passSegmentationIDs ) extractMatchedGeometry . ExtractionMode = 'Geometry' extractMatchedGeometry . Expression = ' {segmentationIDs[{_ttk_IterationInfo[0]} ]}' extractMatchedGeometry . ImageExtent = [ 2147483647 , - 2147483647 , 2147483647 , - 2147483647 , 2147483647 , - 2147483647 ] extractMatchedGeometry . InputArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK BlockAggregator' ttkBlockAggregator = TTKBlockAggregator ( Input = extractMatchedGeometry ) # create a new 'TTK EndFor' ttkEndFor = TTKEndFor ( Data = ttkBlockAggregator , For = ttkForEach ) # save the output SaveData ( 'ContourTreeAlignment.vtu' , alignmentEdges ) SaveData ( 'Segmentations.vtm' , segmentationsGrid ) SaveData ( 'MatchedRegions.vtm' , ttkEndFor ) Inputs \u00b6 heatedCylinder/heatedCylinder_2D_raw.cdb : a cinema data base of 23x10 2D scalar fields. Outputs \u00b6 ContorTreeAlignment.vtu : the output alignment in VTK file format (left view, above screenshot). Segmentations.vtm : the segmentations of the input scalar fields in VTK multiblock format (right view, above screenshot). MatchedRegions.vtm : the regions of the original fields that are represented by a selected vertex in VTK multiblock format (right view, ab\u017fove screenshot). C++/Python API \u00b6 CinemaReader CinemaQuery CinemaProductReader TopologicalSimplificationByPersistence ContourTree (FTM) ContourTreeAlignment GridLayout GridLayout ForEach EndFor TTKExtract","title":"Contour Tree Alignment"},{"location":"contourTreeAlignment/#contour-tree-alignment","text":"","title":"Contour Tree Alignment"},{"location":"contourTreeAlignment/#pipeline-description","text":"This example first loads a scalar field ensemble from disk as a cinema data base. The ensemble consists of 23 time-dependent scalar fields with 10 time steps each. The ensemble is then filtered for the 23 scalar fields of one fixed time point and read as a vtkMultiBlockDataSet. Here we use the CinemaReader , CinemaQuery and CinemaProductReader filters. In a pre-processing, the scalar fields are topologically simplified by persistence using the TopologicalSimplificationByPersistence filter. The filter is automatically applied to each member of the MultiBlockDataSet. Then, for each simplified member field, the contour tree is computed using the FTMTree module. The resulting MultiBlock of contour trees is then used as input for the Contour Tree Alignment filter. This alignment is a super tree of all contour trees and can be seen as a representative of the topology of the whole ensemble. Unfortunately, the vtk object representing the alignment does not have any layout information attached. Therefore, we use the PlanarGraphLayout together with a paraview calculator to compute and apply the layout information. We now want to check which features of the original scalar fields have been matched onto each other. Therefore, we use the ExtractSeletion filter to extract one vertex and attach its segmentationIDs array to the multi block data set representing the segmentations of the contour trees. We also use a Grid Layout to render the multi block in a comparable fashion (right view, above screenshot). As a last step, we use the ForEach and EndFor filters to iterate the multi block of segmentations and in each iteration, we extract the region of the scalar field that corresponds to the segmentation id from the selected vertex. The extraction is done using the TTKExtract filter.","title":"Pipeline description"},{"location":"contourTreeAlignment/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/contourTreeAlignment.pvsm","title":"ParaView"},{"location":"contourTreeAlignment/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' ttkCinemaReader = TTKCinemaReader ( DatabasePath = './heatedCylinder/heatedCylinder_2D_raw.cdb' ) # create a new 'TTK CinemaQuery' ttkCinemaQuery = TTKCinemaQuery ( InputTable = ttkCinemaReader ) ttkCinemaQuery . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE time=4.2\"\"\" # create a new 'TTK CinemaProductReader' ttkCinemaProductReader = TTKCinemaProductReader ( Input = ttkCinemaQuery ) # create a new 'TTK TopologicalSimplificationByPersistence' ttkTopologicalSimplificationByPersistence = TTKTopologicalSimplificationByPersistence ( Input = ttkCinemaProductReader ) ttkTopologicalSimplificationByPersistence . InputArray = [ 'POINTS' , 'nrrd' ] ttkTopologicalSimplificationByPersistence . PersistenceThreshold = 0.05 # create a new 'TTK Merge and Contour Tree (FTM)' ttkMergeandContourTreeFTM = TTKMergeandContourTreeFTM ( Input = ttkTopologicalSimplificationByPersistence ) ttkMergeandContourTreeFTM . ScalarField = [ 'POINTS' , 'nrrd' ] # create a new 'TTK ContourTreeAlignment' contourTreeAlignment = TTKContourTreeAlignment ( Input = OutputPort ( ttkMergeandContourTreeFTM , 1 ), ExportPath = '' ) contourTreeAlignment . ScalarField = [ 'POINTS' , 'Scalar' ] contourTreeAlignment . Regionsizearray = [ 'CELLS' , 'RegionSize' ] contourTreeAlignment . SegmentationIDarrayforCT = [ 'CELLS' , 'SegmentationId' ] contourTreeAlignment . SegmentIDarrayforsegmentation = [ 'POINTS' , 'Scalar' ] # create a new 'TTK PlanarGraphLayout' alignmentLayout = TTKPlanarGraphLayout ( Input = contourTreeAlignment ) alignmentLayout . SequenceArray = [ 'POINTS' , 'Scalar' ] alignmentLayout . SizeArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . UseBranches = 1 alignmentLayout . BranchArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . LevelArray = [ 'POINTS' , 'BranchIDs' ] # create a new 'Calculator' alignmentEdges = Calculator ( Input = alignmentLayout ) alignmentEdges . CoordinateResults = 1 alignmentEdges . Function = 'iHat*Layout_Y+jHat*Scalar*3' # create a query selection QuerySelect ( QueryString = '(id == 16)' , Source = alignmentEdges , FieldType = 'POINT' , InsideOut = 0 ) # create a new 'Extract Selection' selectedVertex = ExtractSelection ( Input = alignmentEdges ) # create a new 'TTK GridLayout' segmentationsGrid = TTKGridLayout ( Input = OutputPort ( ttkMergeandContourTreeFTM , 2 )) segmentationsGrid . ColumnGap = 10.0 segmentationsGrid . RowGap = 10.0 # create a new 'TTK ForEach' ttkForEach = TTKForEach ( Input = segmentationsGrid ) ttkForEach . InputArray = [ 'POINTS' , 'SegmentationId' ] ttkForEach . ImageExtent = [ 0 , 127 , 0 , 255 , 0 , 0 ] # create a new 'Merge Blocks' mergeBlocks = MergeBlocks ( Input = ttkForEach ) # create a new 'TTK ArrayEditor' passSegmentationIDs = TTKArrayEditor ( Target = mergeBlocks , Source = selectedVertex ) passSegmentationIDs . EditorMode = 'Add Arrays from Source' passSegmentationIDs . TargetAttributeType = 'Field Data' passSegmentationIDs . SourcePointDataArrays = [ 'segmentationIDs' ] passSegmentationIDs . TargetArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK Extract' extractMatchedGeometry = TTKExtract ( Input = passSegmentationIDs ) extractMatchedGeometry . ExtractionMode = 'Geometry' extractMatchedGeometry . Expression = ' {segmentationIDs[{_ttk_IterationInfo[0]} ]}' extractMatchedGeometry . ImageExtent = [ 2147483647 , - 2147483647 , 2147483647 , - 2147483647 , 2147483647 , - 2147483647 ] extractMatchedGeometry . InputArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK BlockAggregator' ttkBlockAggregator = TTKBlockAggregator ( Input = extractMatchedGeometry ) # create a new 'TTK EndFor' ttkEndFor = TTKEndFor ( Data = ttkBlockAggregator , For = ttkForEach ) # save the output SaveData ( 'ContourTreeAlignment.vtu' , alignmentEdges ) SaveData ( 'Segmentations.vtm' , segmentationsGrid ) SaveData ( 'MatchedRegions.vtm' , ttkEndFor )","title":"Python code"},{"location":"contourTreeAlignment/#inputs","text":"heatedCylinder/heatedCylinder_2D_raw.cdb : a cinema data base of 23x10 2D scalar fields.","title":"Inputs"},{"location":"contourTreeAlignment/#outputs","text":"ContorTreeAlignment.vtu : the output alignment in VTK file format (left view, above screenshot). Segmentations.vtm : the segmentations of the input scalar fields in VTK multiblock format (right view, above screenshot). MatchedRegions.vtm : the regions of the original fields that are represented by a selected vertex in VTK multiblock format (right view, ab\u017fove screenshot).","title":"Outputs"},{"location":"contourTreeAlignment/#cpython-api","text":"CinemaReader CinemaQuery CinemaProductReader TopologicalSimplificationByPersistence ContourTree (FTM) ContourTreeAlignment GridLayout GridLayout ForEach EndFor TTKExtract","title":"C++/Python API"},{"location":"ctBones/","text":"CT bones \u00b6 Pipeline description \u00b6 This example segments medical image data based on topological persistence. First, the PersistenceDiagram of the data is computed (top right view, above screenshot). Then, only the 5 most persistent maxima are selected, corresponding to the toes of the foot. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification . Next, the Split tree of the simplified data is computed. Finally, the geometry of the bones of the toes is extracted by selecting the regions (in the 3D data) attached to the leaves ( RegionType equals 1) of the Split tree (center view, above screenshot). To get a refined segmentation, change the persistence threshold from 180 down to 150 . Each toe will be subdivided into two segments, precisely along the joints. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/ctBones.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' ctBonesvti = XMLImageDataReader ( FileName = [ 'ctBones.vti' ]) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = ctBonesvti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0 , 9999999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 180.0 , 255.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = ctBonesvti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , 'Scalars_' ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMergeandContourTreeFTM1 , 2 )) threshold3 . Scalars = [ 'POINTS' , 'RegionType' ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] SaveData ( \"CTBonesOutputSegmentation.vtu\" , threshold3 ) Inputs \u00b6 ctBones.vti : a three-dimensional regular grid encoding material density in a medical image (CT scan). Outputs \u00b6 CTBonesOutputSegmentation.vtu : the geometry of the volume of the bones of the toes, as extracted by the analysis pipeline (most persistent super-level set connected components). C++/Python API \u00b6 ContourTree (FTM) PersistenceDiagram TopologicalSimplification","title":"CT bones"},{"location":"ctBones/#ct-bones","text":"","title":"CT bones"},{"location":"ctBones/#pipeline-description","text":"This example segments medical image data based on topological persistence. First, the PersistenceDiagram of the data is computed (top right view, above screenshot). Then, only the 5 most persistent maxima are selected, corresponding to the toes of the foot. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification . Next, the Split tree of the simplified data is computed. Finally, the geometry of the bones of the toes is extracted by selecting the regions (in the 3D data) attached to the leaves ( RegionType equals 1) of the Split tree (center view, above screenshot). To get a refined segmentation, change the persistence threshold from 180 down to 150 . Each toe will be subdivided into two segments, precisely along the joints.","title":"Pipeline description"},{"location":"ctBones/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/ctBones.pvsm","title":"ParaView"},{"location":"ctBones/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' ctBonesvti = XMLImageDataReader ( FileName = [ 'ctBones.vti' ]) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = ctBonesvti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0 , 9999999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 180.0 , 255.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = ctBonesvti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , 'Scalars_' ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMergeandContourTreeFTM1 , 2 )) threshold3 . Scalars = [ 'POINTS' , 'RegionType' ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] SaveData ( \"CTBonesOutputSegmentation.vtu\" , threshold3 )","title":"Python code"},{"location":"ctBones/#inputs","text":"ctBones.vti : a three-dimensional regular grid encoding material density in a medical image (CT scan).","title":"Inputs"},{"location":"ctBones/#outputs","text":"CTBonesOutputSegmentation.vtu : the geometry of the volume of the bones of the toes, as extracted by the analysis pipeline (most persistent super-level set connected components).","title":"Outputs"},{"location":"ctBones/#cpython-api","text":"ContourTree (FTM) PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"dragon/","text":"Dragon \u00b6 Pipeline description \u00b6 This example first loads a triangle mesh from disk. In a pre-processing, the mesh is smoothed and an elevation function is computed on top of it. The elevation function will be considered as the input scalar data in the remainder. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of ScalarFieldCriticalPoints (top left view, above screenshot) and the ContourTree (FTM) (bottom left view, above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/dragon.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' dragonvtu = XMLUnstructuredGridReader ( FileName = [ 'dragon.vtu' ]) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = dragonvtu ) # create a new 'Calculator' elevation = Calculator ( Input = tTKGeometrySmoother1 ) elevation . ResultArrayName = 'Elevation' elevation . Function = 'coordsY' # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = elevation ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = elevation ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'Threshold' pairs = Threshold ( Input = tTKPersistenceDiagram1 ) pairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] pairs . ThresholdRange = [ 0.0 , 1000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = pairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 5.0 , 1000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = elevation , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = tTKTopologicalSimplification1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKContourTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKContourTree1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKContourTree1 . ArcSampling = 30 # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKContourTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 40 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube4 = Tube ( Input = extractSurface4 ) tube4 . NumberofSides = 12 tube4 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKContourTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # save the output SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'CriticalPoints.vtp' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'ContourTreeNodes.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'ContourTreeArcs.vtp' , tube4 ) Inputs \u00b6 dragon.vtu : a two-dimensional triangulation. Outputs \u00b6 PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. CriticalPoints.vtp : the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeNode.vtp : spheres, representing the nodes of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeArcs.vtp : cylinders, representing the arcs of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"Dragon"},{"location":"dragon/#dragon","text":"","title":"Dragon"},{"location":"dragon/#pipeline-description","text":"This example first loads a triangle mesh from disk. In a pre-processing, the mesh is smoothed and an elevation function is computed on top of it. The elevation function will be considered as the input scalar data in the remainder. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of ScalarFieldCriticalPoints (top left view, above screenshot) and the ContourTree (FTM) (bottom left view, above screenshot).","title":"Pipeline description"},{"location":"dragon/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/dragon.pvsm","title":"ParaView"},{"location":"dragon/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' dragonvtu = XMLUnstructuredGridReader ( FileName = [ 'dragon.vtu' ]) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = dragonvtu ) # create a new 'Calculator' elevation = Calculator ( Input = tTKGeometrySmoother1 ) elevation . ResultArrayName = 'Elevation' elevation . Function = 'coordsY' # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = elevation ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = elevation ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'Threshold' pairs = Threshold ( Input = tTKPersistenceDiagram1 ) pairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] pairs . ThresholdRange = [ 0.0 , 1000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = pairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 5.0 , 1000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = elevation , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = tTKTopologicalSimplification1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKContourTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKContourTree1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKContourTree1 . ArcSampling = 30 # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKContourTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 40 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube4 = Tube ( Input = extractSurface4 ) tube4 . NumberofSides = 12 tube4 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKContourTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # save the output SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'CriticalPoints.vtp' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'ContourTreeNodes.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'ContourTreeArcs.vtp' , tube4 )","title":"Python code"},{"location":"dragon/#inputs","text":"dragon.vtu : a two-dimensional triangulation.","title":"Inputs"},{"location":"dragon/#outputs","text":"PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. CriticalPoints.vtp : the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeNode.vtp : spheres, representing the nodes of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeArcs.vtp : cylinders, representing the arcs of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"dragon/#cpython-api","text":"ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"C++/Python API"},{"location":"harmonicSkeleton/","text":"Harmonic Skeleton \u00b6 Pipeline description \u00b6 This example first loads the pegasus triangle mesh from disk. For pre-processing, an elevation function is computed on the mesh, creating Ids for all vertices afterwards. From the created ids the bottom middle of the platform, both wing tips, the tip of the nose and the tip of the horn of pegasus are selected (right view shows them together with more vertices). Now, a HarmonicField is computed using these five points as extrema in the output field, helping to reduce noise in the dataset, creating a smooth field with defined extrema that can later be extracted. The harmonic field is then normalized using the ScalarFieldNormalizer . Then, the PersistenceDiagram is computed on the normalized field, extracting a threshold that is used to simplify the harmonic field using TopologicalSimplification . Finally, the ReebGraph is constructed, extracting its nodes and arcs afterwards (right view shows them). The arcs of the ReebGraph are smoothed with the GeometrySmoother to produce the final, output shape skeleton. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/harmonicSkeleton.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #!/usr/bin/env python #### import the simple module from the paraview from paraview.simple import * # load the pegasus dataset by creating a'XML Unstructured Grid Reader' pegasusvtu = XMLUnstructuredGridReader ( FileName = [ 'pegasus.vtu' ]) # create a new 'Elevation' on the dataset elevation1 = Elevation ( Input = pegasusvtu ) elevation1 . LowPoint = [ 55.58376886060912 , - 88.42696707641238 , - 1166.7651999539546 ] elevation1 . HighPoint = [ - 27.56680371810648 , 70.65296514617846 , - 1072.7592471929715 ] # create a new 'Generate Ids' generateIds1 = GenerateIds ( Input = elevation1 ) generateIds1 . PointIdsArrayName = 'ttkVertexScalarField' # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = elevation1 , DestinationMesh = generateIds1 ) resampleWithDataset1 . PassPointArrays = 1 resampleWithDataset1 . CellLocator = 'Static Cell Locator' # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 29019)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection1 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 171102)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection2 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 204530)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection3 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 216852)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection4 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 219572)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection5 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ extractSelection1 , extractSelection2 , extractSelection3 , extractSelection4 , extractSelection5 ]) # create a new 'TTK HarmonicField' tTKHarmonicField1 = TTKHarmonicField ( Domain = resampleWithDataset1 , Constraints = appendDatasets1 ) tTKHarmonicField1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKHarmonicField1 . ConstraintVerticesIdentifiers = [ 'POINTS' , 'Elevation' ] # create a new 'Calculator' calculator1 = Calculator ( Input = tTKHarmonicField1 ) calculator1 . ResultArrayName = 'ScaledHarmonic' calculator1 . Function = 'OutputHarmonicField^2.375' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tTKScalarFieldNormalizer1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] tTKPersistenceDiagram1 . EmbedinDomain = 1 # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 0.001 , 0.9999999999999999 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tTKScalarFieldNormalizer1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] # create a new 'TTK Reeb graph (FTR)' tTKReebgraphFTR1 = TTKReebgraphFTR ( Input = tTKTopologicalSimplification1 ) tTKReebgraphFTR1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] tTKReebgraphFTR1 . ArcSampling = 20 # create a new 'TTK GeometrySmoother' taking the reeb graph edges for input tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = OutputPort ( tTKReebgraphFTR1 , 1 )) tTKGeometrySmoother1 . IterationNumber = 20 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tTKGeometrySmoother1 ) # create a new 'Tube' representing the reep graph edges tube1 = Tube ( Input = extractSurface2 ) tube1 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' representing the reeb graph nodes tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKReebgraphFTR1 ) tTKIcospheresFromPoints1 . Radius = 2.0 SaveData ( 'ReebGraphNodes.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'ReebGraphArcs.vtp' , tube1 ) Inputs \u00b6 pegasus.vtu : a two-dimensional triangulation. Outputs \u00b6 ReebGraphNodes.vtp : spheres, representing the nodes of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ReebGraphArcs.vtp : cylinders (the output skeleton of the input shape), representing the arcs of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 FTRGraph GeometrySmoother HarmonicField PersistenceDiagram ScalarFieldNormalizer TopologicalSimplification","title":"Harmonic Skeleton"},{"location":"harmonicSkeleton/#harmonic-skeleton","text":"","title":"Harmonic Skeleton"},{"location":"harmonicSkeleton/#pipeline-description","text":"This example first loads the pegasus triangle mesh from disk. For pre-processing, an elevation function is computed on the mesh, creating Ids for all vertices afterwards. From the created ids the bottom middle of the platform, both wing tips, the tip of the nose and the tip of the horn of pegasus are selected (right view shows them together with more vertices). Now, a HarmonicField is computed using these five points as extrema in the output field, helping to reduce noise in the dataset, creating a smooth field with defined extrema that can later be extracted. The harmonic field is then normalized using the ScalarFieldNormalizer . Then, the PersistenceDiagram is computed on the normalized field, extracting a threshold that is used to simplify the harmonic field using TopologicalSimplification . Finally, the ReebGraph is constructed, extracting its nodes and arcs afterwards (right view shows them). The arcs of the ReebGraph are smoothed with the GeometrySmoother to produce the final, output shape skeleton.","title":"Pipeline description"},{"location":"harmonicSkeleton/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/harmonicSkeleton.pvsm","title":"ParaView"},{"location":"harmonicSkeleton/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #!/usr/bin/env python #### import the simple module from the paraview from paraview.simple import * # load the pegasus dataset by creating a'XML Unstructured Grid Reader' pegasusvtu = XMLUnstructuredGridReader ( FileName = [ 'pegasus.vtu' ]) # create a new 'Elevation' on the dataset elevation1 = Elevation ( Input = pegasusvtu ) elevation1 . LowPoint = [ 55.58376886060912 , - 88.42696707641238 , - 1166.7651999539546 ] elevation1 . HighPoint = [ - 27.56680371810648 , 70.65296514617846 , - 1072.7592471929715 ] # create a new 'Generate Ids' generateIds1 = GenerateIds ( Input = elevation1 ) generateIds1 . PointIdsArrayName = 'ttkVertexScalarField' # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = elevation1 , DestinationMesh = generateIds1 ) resampleWithDataset1 . PassPointArrays = 1 resampleWithDataset1 . CellLocator = 'Static Cell Locator' # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 29019)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection1 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 171102)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection2 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 204530)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection3 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 216852)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection4 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Extract Selection', creating its query first and clearing it afterwards QuerySelect ( QueryString = '(ttkVertexScalarField == 219572)' , FieldType = 'POINT' , InsideOut = 0 , Source = resampleWithDataset1 ) extractSelection5 = ExtractSelection ( Input = resampleWithDataset1 ) ClearSelection () # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ extractSelection1 , extractSelection2 , extractSelection3 , extractSelection4 , extractSelection5 ]) # create a new 'TTK HarmonicField' tTKHarmonicField1 = TTKHarmonicField ( Domain = resampleWithDataset1 , Constraints = appendDatasets1 ) tTKHarmonicField1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKHarmonicField1 . ConstraintVerticesIdentifiers = [ 'POINTS' , 'Elevation' ] # create a new 'Calculator' calculator1 = Calculator ( Input = tTKHarmonicField1 ) calculator1 . ResultArrayName = 'ScaledHarmonic' calculator1 . Function = 'OutputHarmonicField^2.375' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tTKScalarFieldNormalizer1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] tTKPersistenceDiagram1 . EmbedinDomain = 1 # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 0.001 , 0.9999999999999999 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tTKScalarFieldNormalizer1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] # create a new 'TTK Reeb graph (FTR)' tTKReebgraphFTR1 = TTKReebgraphFTR ( Input = tTKTopologicalSimplification1 ) tTKReebgraphFTR1 . ScalarField = [ 'POINTS' , 'ScaledHarmonic' ] tTKReebgraphFTR1 . ArcSampling = 20 # create a new 'TTK GeometrySmoother' taking the reeb graph edges for input tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = OutputPort ( tTKReebgraphFTR1 , 1 )) tTKGeometrySmoother1 . IterationNumber = 20 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tTKGeometrySmoother1 ) # create a new 'Tube' representing the reep graph edges tube1 = Tube ( Input = extractSurface2 ) tube1 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' representing the reeb graph nodes tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKReebgraphFTR1 ) tTKIcospheresFromPoints1 . Radius = 2.0 SaveData ( 'ReebGraphNodes.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'ReebGraphArcs.vtp' , tube1 )","title":"Python code"},{"location":"harmonicSkeleton/#inputs","text":"pegasus.vtu : a two-dimensional triangulation.","title":"Inputs"},{"location":"harmonicSkeleton/#outputs","text":"ReebGraphNodes.vtp : spheres, representing the nodes of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ReebGraphArcs.vtp : cylinders (the output skeleton of the input shape), representing the arcs of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"harmonicSkeleton/#cpython-api","text":"FTRGraph GeometrySmoother HarmonicField PersistenceDiagram ScalarFieldNormalizer TopologicalSimplification","title":"C++/Python API"},{"location":"imageProcessing/","text":"Image Processing \u00b6 Pipeline description \u00b6 This example processes a grayscale image (top left view on the above screenshot) to generate a segmentation. We will construct the segmentation from the image gradient. First, the image is loaded from disk. The gradient is computed with ParaView's ComputeDerivatives or Gradient filters. Since TTK only works on scalar field, a Calculator is used to compute the gradient magnitude. From the gradient magnitude, a simplification step involving PersistenceDiagram (bottom left view) and TopologicalSimplification helps removing the noise in the gradient (top right view). To segment the image, we use the MorseSmaleComplex filter. Since in the input image the objects correspond to low values in the gradient and their edges to high values, we are interested in the DescendingManifold scalar field of the Segmentation output, whose cells represent regions of low scalar field values. The IdentifierRandomizer filter is eventually used in order to color neighbor cells with a distinct color (bottom right view on the above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/imageProcessing.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env python from paraview.simple import * naturalImagepng = PNGSeriesReader ( FileNames = [ \"naturalImage.png\" ]) # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = naturalImagepng ) computeDerivatives1 . Scalars = [ \"POINTS\" , \"PNGImage\" ] # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = \"gradient\" calculator1 . Function = \"mag(ScalarGradient)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 59608.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 6.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold , ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold3 . Scalars = [ \"CELLS\" , \"SeparatrixType\" ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 ), ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"DescendingManifold\" ] SaveData ( \"Segmentation.vti\" , tTKIdentifierRandomizer1 ) Inputs \u00b6 naturalImage.png : a grayscale PNG picture. Outputs \u00b6 Segmentation.vti : the image segmentation output. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"Image Processing"},{"location":"imageProcessing/#image-processing","text":"","title":"Image Processing"},{"location":"imageProcessing/#pipeline-description","text":"This example processes a grayscale image (top left view on the above screenshot) to generate a segmentation. We will construct the segmentation from the image gradient. First, the image is loaded from disk. The gradient is computed with ParaView's ComputeDerivatives or Gradient filters. Since TTK only works on scalar field, a Calculator is used to compute the gradient magnitude. From the gradient magnitude, a simplification step involving PersistenceDiagram (bottom left view) and TopologicalSimplification helps removing the noise in the gradient (top right view). To segment the image, we use the MorseSmaleComplex filter. Since in the input image the objects correspond to low values in the gradient and their edges to high values, we are interested in the DescendingManifold scalar field of the Segmentation output, whose cells represent regions of low scalar field values. The IdentifierRandomizer filter is eventually used in order to color neighbor cells with a distinct color (bottom right view on the above screenshot).","title":"Pipeline description"},{"location":"imageProcessing/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/imageProcessing.pvsm","title":"ParaView"},{"location":"imageProcessing/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env python from paraview.simple import * naturalImagepng = PNGSeriesReader ( FileNames = [ \"naturalImage.png\" ]) # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = naturalImagepng ) computeDerivatives1 . Scalars = [ \"POINTS\" , \"PNGImage\" ] # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = \"gradient\" calculator1 . Function = \"mag(ScalarGradient)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 59608.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 6.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold , ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold3 . Scalars = [ \"CELLS\" , \"SeparatrixType\" ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 ), ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"DescendingManifold\" ] SaveData ( \"Segmentation.vti\" , tTKIdentifierRandomizer1 )","title":"Python code"},{"location":"imageProcessing/#inputs","text":"naturalImage.png : a grayscale PNG picture.","title":"Inputs"},{"location":"imageProcessing/#outputs","text":"Segmentation.vti : the image segmentation output.","title":"Outputs"},{"location":"imageProcessing/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"C++/Python API"},{"location":"interactionSites/","text":"Interaction sites \u00b6 Pipeline description \u00b6 This example demostrates how topological analysis can be used to identify interaction sites i.e. different kind of chemical bonds in molecules. Using simulations and experiments, the electron density field denoted as Rho can be estimated for a molecule. Topological analysis of this scalar field can reveal important features in the data. For example, the maxima of this field correspond to the atom locations while saddles occur along the covalent bonds. However, for identification of non-covalent interactions like ionic bonds, analysis of the density field Rho is not enough. A derived scalar field from Rho called reduced density gradeint denoted by s is suggested in literature which can reveal non-covalent interation sites in a molecule. In this example, we will extract and compare the critical points for the Rho and s scalar fields for a simple molecule 1,2-ethanediol. First a VTI file is loaded which contains two scalar fields namely log(Rho) and log(s) . Then using ScalarFieldCriticalPoints , the critical points for log(Rho) are computed which are then converted into spheres using IcospheresFromPoints . They are shown as bigger transluscent green and white spheres in the screenshot above. Note that these critical points identify the atoms and covalent bonds in the molecule. Next, we analyse log(s) , the reduced gradient scalar field. Here, the PersistenceCurve is computed (top right view in the above screenshot). Then, the PersistenceDiagram for log(s) is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. The simplified data is then used as input to ContourTree (FTM) to compute the join tree for the data. The join tree captures the topological changes in sub-level sets of the scalar field and therefore consists of leaves corresponding to minima and internal nodes corresponding to saddles, the points where sublevel sets merge. The nodes of this join tree are selected and highlighted as smaller opaque blue and white spheres using IcospheresFromPoints . Similarly, the arcs of the join tree are also extracted and shown as thin grey tubes in the screenshot above. Using topological analysis of log(s) , we identify an outlying minimum which is not close to the atom locations. This corresponds to a non-covalent interaction site in the molecule which is not identifiable using direct toplogical analysis of electron density field Rho . Lastly, we extract the segmented region corresponding to this particular minimum (shown as transluscent blue surface in the screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/interactionSites.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 #### import the simple module from the paraview from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) #### Topological analysis of 'log(Rho)' # extract the critical points using 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = builtInExamplevti ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] # covert these points to spheres using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints3 = TTKIcospheresFromPoints ( Input = tTKScalarFieldCriticalPoints1 ) tTKIcospheresFromPoints3 . Radius = 3.0 #### Topological analysis of 'log(s)' # compute the 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = builtInExamplevti ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'log(s)' ] # compute the 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = builtInExamplevti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'log(s)' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 117.0 ] # remove low persistence critical points using 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.5 , 3.62385640499735 ] # simplify the field using 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = builtInExamplevti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'log(s)' ] # create a new 'TTK Merge and Contour Tree (FTM)' to compute the join tree tTKJoinTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKJoinTree1 . ScalarField = [ 'POINTS' , 'log(s)' ] tTKJoinTree1 . TreeType = 'Join Tree' tTKJoinTree1 . ArcSampling = 30 # covert the critical points to spheres using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKJoinTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # extract the join tree arcs and save them as tubes tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKJoinTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 300 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube5 = Tube ( Input = extractSurface4 ) tube5 . Radius = 0.25 # Extract the segmentation region corresponding to the interaction site threshold6 = Threshold ( Input = OutputPort ( tTKJoinTree1 , 2 )) threshold6 . Scalars = [ 'POINTS' , 'RegionType' ] # create a new 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'POINTS' , 'SegmentationId' ] threshold7 . ThresholdRange = [ 13.0 , 13.0 ] # create a new 'Extract Surface' extractSurface5 = ExtractSurface ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = extractSurface5 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize1 ) tTKGeometrySmoother3 . IterationNumber = 10 # save the output SaveData ( 'logRhoCriticalPoints.vtp' , tTKIcospheresFromPoints3 ) SaveData ( 'logSPersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 0 )) SaveData ( 'logSPersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'logSJoinTreeCriticalPoints.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'logSJoinTreeArcs.vtp' , tube5 ) SaveData ( 'NonCovalentInteractionSite.vtu' , tTKGeometrySmoother3 ) Inputs \u00b6 BuiltInExample2.vti : 3D scalar fields corresponding to electron density distribution Rho and the reduced density gradient s around a simple molecule 1,2-ethanediol. Outputs \u00b6 logRhoCriticalPoints.vtp : All the scalar field critical points computed for log(Rho) . logSPersistenceCurve.csv : The output persistence curve for log(s) . logSPersistenceDiagram.vtu : The output persistence diagram for log(s) . logSJoinTreeCriticalPoints.vtp : The critical points in the join tree of log(s) . logSJoinTreeArcs.vtp : The arcs of the join tree of log(s) . NonCovalentInteractionSite.vtp : The non-covalent interaction site region identified using the join tree of log(s) . Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"Interaction sites"},{"location":"interactionSites/#interaction-sites","text":"","title":"Interaction sites"},{"location":"interactionSites/#pipeline-description","text":"This example demostrates how topological analysis can be used to identify interaction sites i.e. different kind of chemical bonds in molecules. Using simulations and experiments, the electron density field denoted as Rho can be estimated for a molecule. Topological analysis of this scalar field can reveal important features in the data. For example, the maxima of this field correspond to the atom locations while saddles occur along the covalent bonds. However, for identification of non-covalent interactions like ionic bonds, analysis of the density field Rho is not enough. A derived scalar field from Rho called reduced density gradeint denoted by s is suggested in literature which can reveal non-covalent interation sites in a molecule. In this example, we will extract and compare the critical points for the Rho and s scalar fields for a simple molecule 1,2-ethanediol. First a VTI file is loaded which contains two scalar fields namely log(Rho) and log(s) . Then using ScalarFieldCriticalPoints , the critical points for log(Rho) are computed which are then converted into spheres using IcospheresFromPoints . They are shown as bigger transluscent green and white spheres in the screenshot above. Note that these critical points identify the atoms and covalent bonds in the molecule. Next, we analyse log(s) , the reduced gradient scalar field. Here, the PersistenceCurve is computed (top right view in the above screenshot). Then, the PersistenceDiagram for log(s) is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. The simplified data is then used as input to ContourTree (FTM) to compute the join tree for the data. The join tree captures the topological changes in sub-level sets of the scalar field and therefore consists of leaves corresponding to minima and internal nodes corresponding to saddles, the points where sublevel sets merge. The nodes of this join tree are selected and highlighted as smaller opaque blue and white spheres using IcospheresFromPoints . Similarly, the arcs of the join tree are also extracted and shown as thin grey tubes in the screenshot above. Using topological analysis of log(s) , we identify an outlying minimum which is not close to the atom locations. This corresponds to a non-covalent interaction site in the molecule which is not identifiable using direct toplogical analysis of electron density field Rho . Lastly, we extract the segmented region corresponding to this particular minimum (shown as transluscent blue surface in the screenshot).","title":"Pipeline description"},{"location":"interactionSites/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/interactionSites.pvsm","title":"ParaView"},{"location":"interactionSites/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 #### import the simple module from the paraview from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) #### Topological analysis of 'log(Rho)' # extract the critical points using 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = builtInExamplevti ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] # covert these points to spheres using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints3 = TTKIcospheresFromPoints ( Input = tTKScalarFieldCriticalPoints1 ) tTKIcospheresFromPoints3 . Radius = 3.0 #### Topological analysis of 'log(s)' # compute the 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = builtInExamplevti ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'log(s)' ] # compute the 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = builtInExamplevti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'log(s)' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 117.0 ] # remove low persistence critical points using 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.5 , 3.62385640499735 ] # simplify the field using 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = builtInExamplevti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'log(s)' ] # create a new 'TTK Merge and Contour Tree (FTM)' to compute the join tree tTKJoinTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKJoinTree1 . ScalarField = [ 'POINTS' , 'log(s)' ] tTKJoinTree1 . TreeType = 'Join Tree' tTKJoinTree1 . ArcSampling = 30 # covert the critical points to spheres using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKJoinTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # extract the join tree arcs and save them as tubes tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKJoinTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 300 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube5 = Tube ( Input = extractSurface4 ) tube5 . Radius = 0.25 # Extract the segmentation region corresponding to the interaction site threshold6 = Threshold ( Input = OutputPort ( tTKJoinTree1 , 2 )) threshold6 . Scalars = [ 'POINTS' , 'RegionType' ] # create a new 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'POINTS' , 'SegmentationId' ] threshold7 . ThresholdRange = [ 13.0 , 13.0 ] # create a new 'Extract Surface' extractSurface5 = ExtractSurface ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = extractSurface5 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize1 ) tTKGeometrySmoother3 . IterationNumber = 10 # save the output SaveData ( 'logRhoCriticalPoints.vtp' , tTKIcospheresFromPoints3 ) SaveData ( 'logSPersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 0 )) SaveData ( 'logSPersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'logSJoinTreeCriticalPoints.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'logSJoinTreeArcs.vtp' , tube5 ) SaveData ( 'NonCovalentInteractionSite.vtu' , tTKGeometrySmoother3 )","title":"Python code"},{"location":"interactionSites/#inputs","text":"BuiltInExample2.vti : 3D scalar fields corresponding to electron density distribution Rho and the reduced density gradient s around a simple molecule 1,2-ethanediol.","title":"Inputs"},{"location":"interactionSites/#outputs","text":"logRhoCriticalPoints.vtp : All the scalar field critical points computed for log(Rho) . logSPersistenceCurve.csv : The output persistence curve for log(s) . logSPersistenceDiagram.vtu : The output persistence diagram for log(s) . logSJoinTreeCriticalPoints.vtp : The critical points in the join tree of log(s) . logSJoinTreeArcs.vtp : The arcs of the join tree of log(s) . NonCovalentInteractionSite.vtp : The non-covalent interaction site region identified using the join tree of log(s) . Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"interactionSites/#cpython-api","text":"ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"C++/Python API"},{"location":"karhunenLoveDigits64Dimensions/","text":"Karhunen-Love Digits 64-Dimensions \u00b6 Pipeline description \u00b6 This example performs a persistence driven clustering of a high-dimensional data set, specifically a collection of 2000 images representing hand written digits . Each image is encoded by its Karhunen-Love coefficients, a 64-dimensional vector. This results in a point cloud of 2000 points (2000 rows), living in 64 dimensions (64 columns). The ground truth classification for each point is provided by the column Field0 (point color in the bottom right view, above screenshot), which indicates the digit represented by the corresponding image. The pipeline starts by using DimensionReduction (with tSNE) to project the data down to 2D. Next, the density of the projected 2D point cloud is estimated with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 10 most persistent density maxima are selected (corresponding to the 10 classes, one per digit, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field. The simplified density field then contains only 10 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/karhunenLoveDigits64Dimensions.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' karhunenLoveDigits64Dimensionscsv = CSVReader ( FileName = [ 'karhunenLoveDigits64Dimensions.csv' ]) karhunenLoveDigits64Dimensionscsv . HaveHeaders = 0 # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = karhunenLoveDigits64Dimensionscsv ) tTKDimensionReduction1 . InputColumns = [ 'Field 1' , 'Field 10' , 'Field 11' , 'Field 12' , 'Field 13' , 'Field 14' , 'Field 15' , 'Field 16' , 'Field 17' , 'Field 18' , 'Field 19' , 'Field 2' , 'Field 20' , 'Field 21' , 'Field 22' , 'Field 23' , 'Field 24' , 'Field 25' , 'Field 26' , 'Field 27' , 'Field 28' , 'Field 29' , 'Field 3' , 'Field 30' , 'Field 31' , 'Field 32' , 'Field 33' , 'Field 34' , 'Field 35' , 'Field 36' , 'Field 37' , 'Field 38' , 'Field 39' , 'Field 4' , 'Field 40' , 'Field 41' , 'Field 42' , 'Field 43' , 'Field 44' , 'Field 45' , 'Field 46' , 'Field 47' , 'Field 48' , 'Field 49' , 'Field 5' , 'Field 50' , 'Field 51' , 'Field 52' , 'Field 53' , 'Field 54' , 'Field 55' , 'Field 56' , 'Field 57' , 'Field 58' , 'Field 59' , 'Field 6' , 'Field 60' , 'Field 61' , 'Field 62' , 'Field 63' , 'Field 64' , 'Field 7' , 'Field 8' , 'Field 9' ] tTKDimensionReduction1 . Method = 't-distributed Stochastic Neighbor Embedding' # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 10.0 , 99999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 )) tTKIdentifierRandomizer1 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = tTKIdentifierRandomizer1 , DestinationMesh = tableToPoints1 ) resampleWithDataset1 . PassPointArrays = 1 SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 ) Inputs \u00b6 karhunenLoveDigits64Dimensions.csv : an input high dimensional point cloud (2000 points in 64 dimensions). Outputs \u00b6 OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column, ground truth: Field0 ) C++/Python API \u00b6 DimensionReduction Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"Karhunen-Love Digits 64-Dimensions"},{"location":"karhunenLoveDigits64Dimensions/#karhunen-love-digits-64-dimensions","text":"","title":"Karhunen-Love Digits 64-Dimensions"},{"location":"karhunenLoveDigits64Dimensions/#pipeline-description","text":"This example performs a persistence driven clustering of a high-dimensional data set, specifically a collection of 2000 images representing hand written digits . Each image is encoded by its Karhunen-Love coefficients, a 64-dimensional vector. This results in a point cloud of 2000 points (2000 rows), living in 64 dimensions (64 columns). The ground truth classification for each point is provided by the column Field0 (point color in the bottom right view, above screenshot), which indicates the digit represented by the corresponding image. The pipeline starts by using DimensionReduction (with tSNE) to project the data down to 2D. Next, the density of the projected 2D point cloud is estimated with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 10 most persistent density maxima are selected (corresponding to the 10 classes, one per digit, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field. The simplified density field then contains only 10 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter.","title":"Pipeline description"},{"location":"karhunenLoveDigits64Dimensions/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/karhunenLoveDigits64Dimensions.pvsm","title":"ParaView"},{"location":"karhunenLoveDigits64Dimensions/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' karhunenLoveDigits64Dimensionscsv = CSVReader ( FileName = [ 'karhunenLoveDigits64Dimensions.csv' ]) karhunenLoveDigits64Dimensionscsv . HaveHeaders = 0 # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = karhunenLoveDigits64Dimensionscsv ) tTKDimensionReduction1 . InputColumns = [ 'Field 1' , 'Field 10' , 'Field 11' , 'Field 12' , 'Field 13' , 'Field 14' , 'Field 15' , 'Field 16' , 'Field 17' , 'Field 18' , 'Field 19' , 'Field 2' , 'Field 20' , 'Field 21' , 'Field 22' , 'Field 23' , 'Field 24' , 'Field 25' , 'Field 26' , 'Field 27' , 'Field 28' , 'Field 29' , 'Field 3' , 'Field 30' , 'Field 31' , 'Field 32' , 'Field 33' , 'Field 34' , 'Field 35' , 'Field 36' , 'Field 37' , 'Field 38' , 'Field 39' , 'Field 4' , 'Field 40' , 'Field 41' , 'Field 42' , 'Field 43' , 'Field 44' , 'Field 45' , 'Field 46' , 'Field 47' , 'Field 48' , 'Field 49' , 'Field 5' , 'Field 50' , 'Field 51' , 'Field 52' , 'Field 53' , 'Field 54' , 'Field 55' , 'Field 56' , 'Field 57' , 'Field 58' , 'Field 59' , 'Field 6' , 'Field 60' , 'Field 61' , 'Field 62' , 'Field 63' , 'Field 64' , 'Field 7' , 'Field 8' , 'Field 9' ] tTKDimensionReduction1 . Method = 't-distributed Stochastic Neighbor Embedding' # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 10.0 , 99999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 )) tTKIdentifierRandomizer1 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = tTKIdentifierRandomizer1 , DestinationMesh = tableToPoints1 ) resampleWithDataset1 . PassPointArrays = 1 SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 )","title":"Python code"},{"location":"karhunenLoveDigits64Dimensions/#inputs","text":"karhunenLoveDigits64Dimensions.csv : an input high dimensional point cloud (2000 points in 64 dimensions).","title":"Inputs"},{"location":"karhunenLoveDigits64Dimensions/#outputs","text":"OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column, ground truth: Field0 )","title":"Outputs"},{"location":"karhunenLoveDigits64Dimensions/#cpython-api","text":"DimensionReduction Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"manifoldCheck/","text":"Manifold Check \u00b6 Pipeline description \u00b6 This example loads three different hexahedral geometry files from disk. In a pre-processing, each geometry is tetrahedralized, which is used as input data. On each of the three geometries, ManifoldCheck is executed. This filters adds link numbers to vertices and cells, which can be used to detect and extract non-manifold vertices (left), edges (middle), and faces (right). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/manifoldChecks.pvsm Python code \u00b6 Non-manifold Vertices \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck0vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck0.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = manifoldCheck0vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck1 = TTKManifoldCheck ( Input = tetrahedralize1 ) # create a new 'Mask Points' maskPoints1 = MaskPoints ( Input = tTKManifoldCheck1 ) maskPoints1 . OnRatio = 1 maskPoints1 . MaximumNumberofPoints = 1000 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' # this extracts non-manifold vertices threshold1 = Threshold ( Input = maskPoints1 ) threshold1 . Scalars = [ 'POINTS' , 'VertexLinkComponentNumber' ] threshold1 . LowerThreshold = 2.0 threshold1 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck0_check.vtu' , tTKManifoldCheck1 ) SaveData ( 'manifoldCheck0_non_manifold.vtu' , threshold1 ) Non-manifold Edges \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck1vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck1.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = manifoldCheck1vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck2 = TTKManifoldCheck ( Input = tetrahedralize2 ) # create a new 'Extract Edges' extractEdges2 = ExtractEdges ( Input = tTKManifoldCheck2 ) # create a new 'Threshold' # this extracts non-manifold edges threshold2 = Threshold ( Input = extractEdges2 ) threshold2 . Scalars = [ 'POINTS' , 'EdgeLinkComponentNumber' ] threshold2 . LowerThreshold = 2.0 threshold2 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck1_check.vtu' , tTKManifoldCheck2 ) SaveData ( 'manifoldCheck1_non_manifold.vtu' , threshold2 ) Non-manifold Faces \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck2vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck2.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize3 = Tetrahedralize ( registrationName = 'Tetrahedralize3' , Input = manifoldCheck2vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck3 = TTKManifoldCheck ( registrationName = 'TTKManifoldCheck3' , Input = tetrahedralize3 ) # create a new 'Threshold' # this extracts tetrahedra that contain non-manifold faces threshold3 = Threshold ( registrationName = 'Threshold3' , Input = tTKManifoldCheck3 ) threshold3 . Scalars = [ 'CELLS' , 'TriangleLinkComponentNumber' ] threshold3 . LowerThreshold = 3.0 threshold3 . UpperThreshold = 3.0 # create a new 'Generate Ids' generateIds1 = GenerateIds ( registrationName = 'GenerateIds1' , Input = threshold3 ) generateIds1 . PointIdsArrayName = 'VertexIdentifiers' generateIds1 . CellIdsArrayName = 'CellIdentifiers' # create a new 'Threshold' # select two of the tetrahedra threshold4 = Threshold ( registrationName = 'Threshold4' , Input = generateIds1 ) threshold4 . Scalars = [ 'CELLS' , 'CellIdentifiers' ] threshold4 . UpperThreshold = 1.0 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( registrationName = 'ExtractSurface2' , Input = threshold4 ) # create a new 'Threshold' # this extracts non-manifold faces threshold5 = Threshold ( registrationName = 'Threshold5' , Input = extractSurface2 ) threshold5 . Scalars = [ 'POINTS' , 'TriangleLinkComponentNumber' ] threshold5 . LowerThreshold = 3.0 threshold5 . UpperThreshold = 3.0 # save the output SaveData ( 'manifoldCheck2_check.vtu' , tTKManifoldCheck3 ) SaveData ( 'manifoldCheck2_non_manifold.vtu' , threshold5 ) Inputs \u00b6 manifoldCheck0.vtu : example mesh with non-manifold vertices manifoldCheck1.vtu : example mesh with non-manifold edges manifoldCheck2.vtu : example mesh with non-manifold faces Outputs \u00b6 manifoldCheck0_check.vtu , manifoldCheck1_check.vtu , manifoldCheck2_check.vtu : tetrhedralized geometry with link numbers manifoldCheck0_non_manifold.vtu : non-manifold vertices in manifoldCheck0.vtu manifoldCheck1_non_manifold.vtu : non-manifold edges in manifoldCheck1.vtu manifoldCheck2_non_manifold.vtu : non-manifold faces in manifoldCheck2.vtu C++/Python API \u00b6 ManifoldCheck","title":"Manifold Check"},{"location":"manifoldCheck/#manifold-check","text":"","title":"Manifold Check"},{"location":"manifoldCheck/#pipeline-description","text":"This example loads three different hexahedral geometry files from disk. In a pre-processing, each geometry is tetrahedralized, which is used as input data. On each of the three geometries, ManifoldCheck is executed. This filters adds link numbers to vertices and cells, which can be used to detect and extract non-manifold vertices (left), edges (middle), and faces (right).","title":"Pipeline description"},{"location":"manifoldCheck/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/manifoldChecks.pvsm","title":"ParaView"},{"location":"manifoldCheck/#python-code","text":"","title":"Python code"},{"location":"manifoldCheck/#non-manifold-vertices","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck0vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck0.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = manifoldCheck0vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck1 = TTKManifoldCheck ( Input = tetrahedralize1 ) # create a new 'Mask Points' maskPoints1 = MaskPoints ( Input = tTKManifoldCheck1 ) maskPoints1 . OnRatio = 1 maskPoints1 . MaximumNumberofPoints = 1000 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' # this extracts non-manifold vertices threshold1 = Threshold ( Input = maskPoints1 ) threshold1 . Scalars = [ 'POINTS' , 'VertexLinkComponentNumber' ] threshold1 . LowerThreshold = 2.0 threshold1 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck0_check.vtu' , tTKManifoldCheck1 ) SaveData ( 'manifoldCheck0_non_manifold.vtu' , threshold1 )","title":"Non-manifold Vertices"},{"location":"manifoldCheck/#non-manifold-edges","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck1vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck1.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = manifoldCheck1vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck2 = TTKManifoldCheck ( Input = tetrahedralize2 ) # create a new 'Extract Edges' extractEdges2 = ExtractEdges ( Input = tTKManifoldCheck2 ) # create a new 'Threshold' # this extracts non-manifold edges threshold2 = Threshold ( Input = extractEdges2 ) threshold2 . Scalars = [ 'POINTS' , 'EdgeLinkComponentNumber' ] threshold2 . LowerThreshold = 2.0 threshold2 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck1_check.vtu' , tTKManifoldCheck2 ) SaveData ( 'manifoldCheck1_non_manifold.vtu' , threshold2 )","title":"Non-manifold Edges"},{"location":"manifoldCheck/#non-manifold-faces","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck2vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck2.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize3 = Tetrahedralize ( registrationName = 'Tetrahedralize3' , Input = manifoldCheck2vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck3 = TTKManifoldCheck ( registrationName = 'TTKManifoldCheck3' , Input = tetrahedralize3 ) # create a new 'Threshold' # this extracts tetrahedra that contain non-manifold faces threshold3 = Threshold ( registrationName = 'Threshold3' , Input = tTKManifoldCheck3 ) threshold3 . Scalars = [ 'CELLS' , 'TriangleLinkComponentNumber' ] threshold3 . LowerThreshold = 3.0 threshold3 . UpperThreshold = 3.0 # create a new 'Generate Ids' generateIds1 = GenerateIds ( registrationName = 'GenerateIds1' , Input = threshold3 ) generateIds1 . PointIdsArrayName = 'VertexIdentifiers' generateIds1 . CellIdsArrayName = 'CellIdentifiers' # create a new 'Threshold' # select two of the tetrahedra threshold4 = Threshold ( registrationName = 'Threshold4' , Input = generateIds1 ) threshold4 . Scalars = [ 'CELLS' , 'CellIdentifiers' ] threshold4 . UpperThreshold = 1.0 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( registrationName = 'ExtractSurface2' , Input = threshold4 ) # create a new 'Threshold' # this extracts non-manifold faces threshold5 = Threshold ( registrationName = 'Threshold5' , Input = extractSurface2 ) threshold5 . Scalars = [ 'POINTS' , 'TriangleLinkComponentNumber' ] threshold5 . LowerThreshold = 3.0 threshold5 . UpperThreshold = 3.0 # save the output SaveData ( 'manifoldCheck2_check.vtu' , tTKManifoldCheck3 ) SaveData ( 'manifoldCheck2_non_manifold.vtu' , threshold5 )","title":"Non-manifold Faces"},{"location":"manifoldCheck/#inputs","text":"manifoldCheck0.vtu : example mesh with non-manifold vertices manifoldCheck1.vtu : example mesh with non-manifold edges manifoldCheck2.vtu : example mesh with non-manifold faces","title":"Inputs"},{"location":"manifoldCheck/#outputs","text":"manifoldCheck0_check.vtu , manifoldCheck1_check.vtu , manifoldCheck2_check.vtu : tetrhedralized geometry with link numbers manifoldCheck0_non_manifold.vtu : non-manifold vertices in manifoldCheck0.vtu manifoldCheck1_non_manifold.vtu : non-manifold edges in manifoldCheck1.vtu manifoldCheck2_non_manifold.vtu : non-manifold faces in manifoldCheck2.vtu","title":"Outputs"},{"location":"manifoldCheck/#cpython-api","text":"ManifoldCheck","title":"C++/Python API"},{"location":"mergeTreeClustering/","text":"Merge Tree Clustering \u00b6 Pipeline description \u00b6 This example first loads an ensemble of scalar fields inside a single file from disk. Then, the FTMTree is computed on each scalar field for the Join Tree and the Split Tree. All these trees are passed to MergeTreeClustering to compute a clustering in the metric space of merge trees. Each input is considered as a tuple consisting of the Join Tree and the Split Tree of the corresponding scalar field. Each centroid is also a tuple of this kind and a distance between two tuples is the distance between their Join Tree plus the distance between their Split Trees. Then, a distance matrix is computed with MergeTreeDistanceMatrix with the input trees and the 3 centroids. This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 2D respecting the most the input distance matrix. In terms of visualisation, the MDS result is visualized and colored by clustering assignment. The split trees centroids are visualized with a planar layout and also some fields of each cluster. In the second layout, the star clustering is visualized, consisting of the input split trees grouped by cluster, with the centroid of the cluster in the middle. The python script computes the MDS and saves the resulting 2D points (for input trees and centroids). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeClustering.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_JT_group = [] all_ST_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Join Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_JT_group . append ( groupDatasets1 ) # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM2 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM2 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM2 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets2 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM2 , OutputPort ( tTKMergeandContourTreeFTM2 , 1 ), OutputPort ( tTKMergeandContourTreeFTM2 , 2 )]) all_ST_group . append ( groupDatasets2 ) # create a new 'Group Datasets' mt_JT_all = GroupDatasets ( Input = all_JT_group ) # create a new 'Group Datasets' mT_all = GroupDatasets ( Input = all_ST_group ) # create a new 'TTK MergeTreeClustering' tTKMergeTreeClustering1 = TTKMergeTreeClustering ( Input = mT_all , OptionalInputclustering = mt_JT_all ) tTKMergeTreeClustering1 . ComputeBarycenter = 1 tTKMergeTreeClustering1 . NumberOfClusters = 3 tTKMergeTreeClustering1 . Deterministic = 1 tTKMergeTreeClustering1 . DimensionSpacing = 0.1 tTKMergeTreeClustering1 . PersistenceThreshold = 2.0 tTKMergeTreeClustering1 . ImportantPairs = 34.0 tTKMergeTreeClustering1 . MaximumNumberofImportantPairs = 3 tTKMergeTreeClustering1 . MinimumNumberofImportantPairs = 2 tTKMergeTreeClustering1 . ImportantPairsSpacing = 15.0 tTKMergeTreeClustering1 . NonImportantPairsProximity = 0.15 # create a new 'Group Datasets' groupDatasets14 = GroupDatasets ( Input = [ tTKMergeTreeClustering1 , OutputPort ( tTKMergeTreeClustering1 , 1 )]) # create a new 'TTK FlattenMultiBlock' tTKFlattenMultiBlock2 = TTKFlattenMultiBlock ( Input = groupDatasets14 ) # create a new 'TTK MergeTreeDistanceMatrix' tTKMergeTreeDistanceMatrix2 = TTKMergeTreeDistanceMatrix ( Input = tTKFlattenMultiBlock2 ) tTKMergeTreeDistanceMatrix2 . PersistenceThreshold = 2.0 # create a new 'TTK DimensionReduction' tTKDimensionReduction2 = TTKDimensionReduction ( Input = tTKMergeTreeDistanceMatrix2 , ModulePath = 'default' ) tTKDimensionReduction2 . InputColumns = [ 'Tree00' , 'Tree01' , 'Tree02' , 'Tree03' , 'Tree04' , 'Tree05' , 'Tree06' , 'Tree07' , 'Tree08' , 'Tree09' , 'Tree10' , 'Tree11' , 'Tree12' , 'Tree13' , 'Tree14' ] tTKDimensionReduction2 . InputIsaDistanceMatrix = 1 tTKDimensionReduction2 . UseAllCores = 0 # MDS is unstable in parallel mode # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction2 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Mask Points' (to threshold on points) maskPoints1 = MaskPoints ( Input = tableToPoints1 ) maskPoints1 . OnRatio = 0 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' threshold33 = Threshold ( Input = maskPoints1 ) threshold33 . Scalars = [ 'POINTS' , 'treeID' ] threshold33 . ThresholdRange = [ 0.0 , 11.0 ] # create a new 'Threshold' threshold34 = Threshold ( Input = maskPoints1 ) threshold34 . Scalars = [ 'POINTS' , 'treeID' ] threshold34 . ThresholdRange = [ 12.0 , 14.0 ] # save the output SaveData ( 'MDS_trees.csv' , threshold33 ) SaveData ( 'MDS_centroids.csv' , threshold34 ) Inputs \u00b6 isabel.vti : a three-dimensional regular grid with 12 scalar fields. Outputs \u00b6 MDS_trees.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the input trees. The 'ClusterAssignment' array contains the clustering assignments. MDS_centroids.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the centroids. C++/Python API \u00b6 FTMTree MergeTreeClustering MergeTreeDistanceMatrix DimensionReduction","title":"Merge Tree Clustering"},{"location":"mergeTreeClustering/#merge-tree-clustering","text":"","title":"Merge Tree Clustering"},{"location":"mergeTreeClustering/#pipeline-description","text":"This example first loads an ensemble of scalar fields inside a single file from disk. Then, the FTMTree is computed on each scalar field for the Join Tree and the Split Tree. All these trees are passed to MergeTreeClustering to compute a clustering in the metric space of merge trees. Each input is considered as a tuple consisting of the Join Tree and the Split Tree of the corresponding scalar field. Each centroid is also a tuple of this kind and a distance between two tuples is the distance between their Join Tree plus the distance between their Split Trees. Then, a distance matrix is computed with MergeTreeDistanceMatrix with the input trees and the 3 centroids. This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 2D respecting the most the input distance matrix. In terms of visualisation, the MDS result is visualized and colored by clustering assignment. The split trees centroids are visualized with a planar layout and also some fields of each cluster. In the second layout, the star clustering is visualized, consisting of the input split trees grouped by cluster, with the centroid of the cluster in the middle. The python script computes the MDS and saves the resulting 2D points (for input trees and centroids).","title":"Pipeline description"},{"location":"mergeTreeClustering/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeClustering.pvsm","title":"ParaView"},{"location":"mergeTreeClustering/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_JT_group = [] all_ST_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Join Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_JT_group . append ( groupDatasets1 ) # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM2 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM2 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM2 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets2 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM2 , OutputPort ( tTKMergeandContourTreeFTM2 , 1 ), OutputPort ( tTKMergeandContourTreeFTM2 , 2 )]) all_ST_group . append ( groupDatasets2 ) # create a new 'Group Datasets' mt_JT_all = GroupDatasets ( Input = all_JT_group ) # create a new 'Group Datasets' mT_all = GroupDatasets ( Input = all_ST_group ) # create a new 'TTK MergeTreeClustering' tTKMergeTreeClustering1 = TTKMergeTreeClustering ( Input = mT_all , OptionalInputclustering = mt_JT_all ) tTKMergeTreeClustering1 . ComputeBarycenter = 1 tTKMergeTreeClustering1 . NumberOfClusters = 3 tTKMergeTreeClustering1 . Deterministic = 1 tTKMergeTreeClustering1 . DimensionSpacing = 0.1 tTKMergeTreeClustering1 . PersistenceThreshold = 2.0 tTKMergeTreeClustering1 . ImportantPairs = 34.0 tTKMergeTreeClustering1 . MaximumNumberofImportantPairs = 3 tTKMergeTreeClustering1 . MinimumNumberofImportantPairs = 2 tTKMergeTreeClustering1 . ImportantPairsSpacing = 15.0 tTKMergeTreeClustering1 . NonImportantPairsProximity = 0.15 # create a new 'Group Datasets' groupDatasets14 = GroupDatasets ( Input = [ tTKMergeTreeClustering1 , OutputPort ( tTKMergeTreeClustering1 , 1 )]) # create a new 'TTK FlattenMultiBlock' tTKFlattenMultiBlock2 = TTKFlattenMultiBlock ( Input = groupDatasets14 ) # create a new 'TTK MergeTreeDistanceMatrix' tTKMergeTreeDistanceMatrix2 = TTKMergeTreeDistanceMatrix ( Input = tTKFlattenMultiBlock2 ) tTKMergeTreeDistanceMatrix2 . PersistenceThreshold = 2.0 # create a new 'TTK DimensionReduction' tTKDimensionReduction2 = TTKDimensionReduction ( Input = tTKMergeTreeDistanceMatrix2 , ModulePath = 'default' ) tTKDimensionReduction2 . InputColumns = [ 'Tree00' , 'Tree01' , 'Tree02' , 'Tree03' , 'Tree04' , 'Tree05' , 'Tree06' , 'Tree07' , 'Tree08' , 'Tree09' , 'Tree10' , 'Tree11' , 'Tree12' , 'Tree13' , 'Tree14' ] tTKDimensionReduction2 . InputIsaDistanceMatrix = 1 tTKDimensionReduction2 . UseAllCores = 0 # MDS is unstable in parallel mode # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction2 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Mask Points' (to threshold on points) maskPoints1 = MaskPoints ( Input = tableToPoints1 ) maskPoints1 . OnRatio = 0 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' threshold33 = Threshold ( Input = maskPoints1 ) threshold33 . Scalars = [ 'POINTS' , 'treeID' ] threshold33 . ThresholdRange = [ 0.0 , 11.0 ] # create a new 'Threshold' threshold34 = Threshold ( Input = maskPoints1 ) threshold34 . Scalars = [ 'POINTS' , 'treeID' ] threshold34 . ThresholdRange = [ 12.0 , 14.0 ] # save the output SaveData ( 'MDS_trees.csv' , threshold33 ) SaveData ( 'MDS_centroids.csv' , threshold34 )","title":"Python code"},{"location":"mergeTreeClustering/#inputs","text":"isabel.vti : a three-dimensional regular grid with 12 scalar fields.","title":"Inputs"},{"location":"mergeTreeClustering/#outputs","text":"MDS_trees.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the input trees. The 'ClusterAssignment' array contains the clustering assignments. MDS_centroids.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the centroids.","title":"Outputs"},{"location":"mergeTreeClustering/#cpython-api","text":"FTMTree MergeTreeClustering MergeTreeDistanceMatrix DimensionReduction","title":"C++/Python API"},{"location":"mergeTreeTemporalReduction/","text":"Merge Tree Temporal Reduction \u00b6 Pipeline description \u00b6 This example first loads an ensemble of scalar fields inside a single file from disk. Then, the Split Tree is computed on each scalar field. All these trees are passed to MergeTreeTemporalReductionEncoding to compute a subsampling of a sequence of merge trees. The algorithm greedily removes trees in the sequence that can be accurately reconstructed by the geodesic computation. The remaining trees are called the key frames. In terms of visualisation, the three key frames trees and two reconstructed trees are visualized with a planar layout along with their corresponding scalar fields. The python script saves the information needed to reconstruct the trees removed in the sequence. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeTemporalReduction.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_MT_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_MT_group . append ( groupDatasets1 ) # create a new 'Group Datasets' all_MT = GroupDatasets ( Input = all_MT_group ) # create a new 'TTK MergeTreeTemporalReductionEncoding' tTKMergeTreeTemporalReductionEncoding1 = TTKMergeTreeTemporalReductionEncoding ( Input = all_MT ) tTKMergeTreeTemporalReductionEncoding1 . RemovalPercentage = 75.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon1 = 0.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon2 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon3 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . PersistenceThreshold = 3.0 SaveData ( 'ReductionCoefficients.csv' , OutputPort ( tTKMergeTreeTemporalReductionEncoding1 , 1 )) Inputs \u00b6 isabel.vti : a three-dimensional regular grid with 12 scalar fields. Outputs \u00b6 ReductionCoefficients.csv : a table containing information needed to reconstruct removed trees. For each removed tree we have the id of the two key frames needed to reconstruct it ('Index1' and 'Index2'), along with the interpolation parameter ('Alpha'). C++/Python API \u00b6 FTMTree MergeTreeTemporalReductionEncoding","title":"Merge Tree Temporal Reduction"},{"location":"mergeTreeTemporalReduction/#merge-tree-temporal-reduction","text":"","title":"Merge Tree Temporal Reduction"},{"location":"mergeTreeTemporalReduction/#pipeline-description","text":"This example first loads an ensemble of scalar fields inside a single file from disk. Then, the Split Tree is computed on each scalar field. All these trees are passed to MergeTreeTemporalReductionEncoding to compute a subsampling of a sequence of merge trees. The algorithm greedily removes trees in the sequence that can be accurately reconstructed by the geodesic computation. The remaining trees are called the key frames. In terms of visualisation, the three key frames trees and two reconstructed trees are visualized with a planar layout along with their corresponding scalar fields. The python script saves the information needed to reconstruct the trees removed in the sequence.","title":"Pipeline description"},{"location":"mergeTreeTemporalReduction/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeTemporalReduction.pvsm","title":"ParaView"},{"location":"mergeTreeTemporalReduction/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_MT_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_MT_group . append ( groupDatasets1 ) # create a new 'Group Datasets' all_MT = GroupDatasets ( Input = all_MT_group ) # create a new 'TTK MergeTreeTemporalReductionEncoding' tTKMergeTreeTemporalReductionEncoding1 = TTKMergeTreeTemporalReductionEncoding ( Input = all_MT ) tTKMergeTreeTemporalReductionEncoding1 . RemovalPercentage = 75.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon1 = 0.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon2 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon3 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . PersistenceThreshold = 3.0 SaveData ( 'ReductionCoefficients.csv' , OutputPort ( tTKMergeTreeTemporalReductionEncoding1 , 1 ))","title":"Python code"},{"location":"mergeTreeTemporalReduction/#inputs","text":"isabel.vti : a three-dimensional regular grid with 12 scalar fields.","title":"Inputs"},{"location":"mergeTreeTemporalReduction/#outputs","text":"ReductionCoefficients.csv : a table containing information needed to reconstruct removed trees. For each removed tree we have the id of the two key frames needed to reconstruct it ('Index1' and 'Index2'), along with the interpolation parameter ('Alpha').","title":"Outputs"},{"location":"mergeTreeTemporalReduction/#cpython-api","text":"FTMTree MergeTreeTemporalReductionEncoding","title":"C++/Python API"},{"location":"morseMolecule/","text":"Morse molecule \u00b6 Pipeline description \u00b6 This example first loads a VTI file on the disk. The VTI file contains three scalar fields namely Rho , log(Rho) , and log(s) . We are interested in topological analysis of the log(Rho) scalar field which corresponds to the electron density distribution around a simple molecule. The MorseSmaleComplex is computed for this scalar field. The reason for computing Morse-Smale complex is that many chemically relevant concepts, for example, covalent bonds can be directly translated to topological structures computed using the Morse-Smale complex. The critical points of this scalar field also have chemical relevance. The maxima correspond to the atom locations and 2-saddles occur along chemical bonds. Then the critical points are then converted into spheres using IcospheresFromPoints . The maxima are selected and highlighted as bigger spheres. Then using appropriate filtering, the 1-separatrices corresponding to the covalent bonds are selected. The criteria used is to select the 1-sepatrices which have no critical points on the boundary and for which SeparatrixType = 2 , that is they connect a 2-saddle to a maximum. Also, GeometrySmoother is used to make the jagged lines generated by the Morse-Smale complex a little smoother. Then, another type of 1-separatrix is extracted which connects a 2-saddle on a covalent bond to its neighbouring 1-saddles on the boundary. Lastly, 2-separatrices incident on the covalent bonds (of SeparatrixType = 1 ) are extracted which correspond to separating walls between adjacent atoms. Another type ( SeparatrixType = 2 ) of separating wall is also extracted. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseMolecule.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = builtInExamplevti ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . Descending2Separatrices = 1 # Generate spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints1 . Radius = 1.5 # Generate bigger spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 3.0 # Then select critical points of CellDimension 3 using 'Threshold' to select maxima threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ 'POINTS' , 'CellDimension' ] threshold3 . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Threshold' threshold1 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold1 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold1 . ThresholdRange = [ 0.0 , 0.0 ] # create a new 'Threshold' threshold2 = Threshold ( Input = threshold1 ) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold2 ) tTKGeometrySmoother1 . IterationNumber = 50 # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = tTKGeometrySmoother1 ) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = cleantoGrid1 ) # create a new 'Tube' tube1 = Tube ( Input = extractSurface1 ) tube1 . Scalars = [ 'POINTS' , 'CellDimension' ] tube1 . Radius = 1.25 # create a new 'Threshold' threshold8 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold8 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold8 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold9 = Threshold ( Input = threshold8 ) threshold9 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold9 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold11 = Threshold ( Input = threshold9 ) threshold11 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold11 . ThresholdRange = [ 75.0 , 76.0 ] # create a new 'Threshold' threshold10 = Threshold ( Input = threshold9 ) threshold10 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold10 . ThresholdRange = [ 73.0 , 74.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ threshold10 , threshold11 ]) # create a new 'Clean to Grid' cleantoGrid4 = CleantoGrid ( Input = appendDatasets1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother4 = TTKGeometrySmoother ( Input = cleantoGrid4 ) tTKGeometrySmoother4 . IterationNumber = 10 # create a new 'Extract Surface' extractSurface3 = ExtractSurface ( Input = tTKGeometrySmoother4 ) # create a new 'Tube' tube2 = Tube ( Input = extractSurface3 ) tube2 . Scalars = [ 'POINTS' , 'CellDimension' ] tube2 . Radius = 0.75 # create a new 'Threshold' threshold4 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold4 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold4 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Clean to Grid' cleantoGrid2 = CleantoGrid ( Input = threshold4 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid2 ) # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tetrahedralize1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = extractSurface2 ) tTKGeometrySmoother2 . IterationNumber = 20 # select 2-separatrices using 'Threshold' threshold5 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold5 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold5 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' threshold6 = Threshold ( Input = threshold5 ) threshold6 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold6 . ThresholdRange = [ 4.0 , 4.0 ] # select a particular 2-separatrix using 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold7 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Clean to Grid' cleantoGrid3 = CleantoGrid ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = cleantoGrid3 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize2 ) tTKGeometrySmoother3 . IterationNumber = 20 # save the output SaveData ( 'CriticalPoints.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'Maxima.vtu' , threshold3 ) SaveData ( 'CovalentBonds.vtp' , tube1 ) SaveData ( 'Selected2saddle1saddleConnectors.vtp' , tube2 ) SaveData ( 'CovalentBondSeparatrixWalls.vtp' , tTKGeometrySmoother2 ) SaveData ( 'SelectedType2SeparatrixWall.vtu' , tTKGeometrySmoother3 ) Inputs \u00b6 BuiltInExample2.vti : 3D scalar field corresponding to electron density distribution around a simple molecule. Outputs \u00b6 CriticalPoints.vtp : All the output critical points in VTK file format (small spheres in the above screenshot). Maxima.vtu : The computed maxima which also correspond to atom locations in VTK file format (bigger green spheres). CovalentBonds.vtp : Selected 1-separatrices corresponding to the covalent bonds in the molecule (the thick white tubes) Selected2saddle1saddleConnectors.vtp : Geometry of selected separatrices connecting a 2-saddle on a covalent bond to its neighbouring 1-saddles (the dark grey tubes in the screenshot above). CovalentBondSeparatrixWalls.vtp : Surface corresponding to 2-separatrices (walls) incident on the covalent bonds (the translucent blue surfaces in the above screenshot) SelectedType2SeparatrixWall.vtu : Surface corresponding to another type of wall (the green surface). Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 MorseSmaleComplex GeometrySmoother IcospheresFromPoints","title":"Morse molecule"},{"location":"morseMolecule/#morse-molecule","text":"","title":"Morse molecule"},{"location":"morseMolecule/#pipeline-description","text":"This example first loads a VTI file on the disk. The VTI file contains three scalar fields namely Rho , log(Rho) , and log(s) . We are interested in topological analysis of the log(Rho) scalar field which corresponds to the electron density distribution around a simple molecule. The MorseSmaleComplex is computed for this scalar field. The reason for computing Morse-Smale complex is that many chemically relevant concepts, for example, covalent bonds can be directly translated to topological structures computed using the Morse-Smale complex. The critical points of this scalar field also have chemical relevance. The maxima correspond to the atom locations and 2-saddles occur along chemical bonds. Then the critical points are then converted into spheres using IcospheresFromPoints . The maxima are selected and highlighted as bigger spheres. Then using appropriate filtering, the 1-separatrices corresponding to the covalent bonds are selected. The criteria used is to select the 1-sepatrices which have no critical points on the boundary and for which SeparatrixType = 2 , that is they connect a 2-saddle to a maximum. Also, GeometrySmoother is used to make the jagged lines generated by the Morse-Smale complex a little smoother. Then, another type of 1-separatrix is extracted which connects a 2-saddle on a covalent bond to its neighbouring 1-saddles on the boundary. Lastly, 2-separatrices incident on the covalent bonds (of SeparatrixType = 1 ) are extracted which correspond to separating walls between adjacent atoms. Another type ( SeparatrixType = 2 ) of separating wall is also extracted.","title":"Pipeline description"},{"location":"morseMolecule/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseMolecule.pvsm","title":"ParaView"},{"location":"morseMolecule/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = builtInExamplevti ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . Descending2Separatrices = 1 # Generate spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints1 . Radius = 1.5 # Generate bigger spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 3.0 # Then select critical points of CellDimension 3 using 'Threshold' to select maxima threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ 'POINTS' , 'CellDimension' ] threshold3 . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Threshold' threshold1 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold1 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold1 . ThresholdRange = [ 0.0 , 0.0 ] # create a new 'Threshold' threshold2 = Threshold ( Input = threshold1 ) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold2 ) tTKGeometrySmoother1 . IterationNumber = 50 # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = tTKGeometrySmoother1 ) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = cleantoGrid1 ) # create a new 'Tube' tube1 = Tube ( Input = extractSurface1 ) tube1 . Scalars = [ 'POINTS' , 'CellDimension' ] tube1 . Radius = 1.25 # create a new 'Threshold' threshold8 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold8 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold8 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold9 = Threshold ( Input = threshold8 ) threshold9 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold9 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold11 = Threshold ( Input = threshold9 ) threshold11 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold11 . ThresholdRange = [ 75.0 , 76.0 ] # create a new 'Threshold' threshold10 = Threshold ( Input = threshold9 ) threshold10 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold10 . ThresholdRange = [ 73.0 , 74.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ threshold10 , threshold11 ]) # create a new 'Clean to Grid' cleantoGrid4 = CleantoGrid ( Input = appendDatasets1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother4 = TTKGeometrySmoother ( Input = cleantoGrid4 ) tTKGeometrySmoother4 . IterationNumber = 10 # create a new 'Extract Surface' extractSurface3 = ExtractSurface ( Input = tTKGeometrySmoother4 ) # create a new 'Tube' tube2 = Tube ( Input = extractSurface3 ) tube2 . Scalars = [ 'POINTS' , 'CellDimension' ] tube2 . Radius = 0.75 # create a new 'Threshold' threshold4 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold4 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold4 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Clean to Grid' cleantoGrid2 = CleantoGrid ( Input = threshold4 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid2 ) # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tetrahedralize1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = extractSurface2 ) tTKGeometrySmoother2 . IterationNumber = 20 # select 2-separatrices using 'Threshold' threshold5 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold5 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold5 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' threshold6 = Threshold ( Input = threshold5 ) threshold6 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold6 . ThresholdRange = [ 4.0 , 4.0 ] # select a particular 2-separatrix using 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold7 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Clean to Grid' cleantoGrid3 = CleantoGrid ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = cleantoGrid3 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize2 ) tTKGeometrySmoother3 . IterationNumber = 20 # save the output SaveData ( 'CriticalPoints.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'Maxima.vtu' , threshold3 ) SaveData ( 'CovalentBonds.vtp' , tube1 ) SaveData ( 'Selected2saddle1saddleConnectors.vtp' , tube2 ) SaveData ( 'CovalentBondSeparatrixWalls.vtp' , tTKGeometrySmoother2 ) SaveData ( 'SelectedType2SeparatrixWall.vtu' , tTKGeometrySmoother3 )","title":"Python code"},{"location":"morseMolecule/#inputs","text":"BuiltInExample2.vti : 3D scalar field corresponding to electron density distribution around a simple molecule.","title":"Inputs"},{"location":"morseMolecule/#outputs","text":"CriticalPoints.vtp : All the output critical points in VTK file format (small spheres in the above screenshot). Maxima.vtu : The computed maxima which also correspond to atom locations in VTK file format (bigger green spheres). CovalentBonds.vtp : Selected 1-separatrices corresponding to the covalent bonds in the molecule (the thick white tubes) Selected2saddle1saddleConnectors.vtp : Geometry of selected separatrices connecting a 2-saddle on a covalent bond to its neighbouring 1-saddles (the dark grey tubes in the screenshot above). CovalentBondSeparatrixWalls.vtp : Surface corresponding to 2-separatrices (walls) incident on the covalent bonds (the translucent blue surfaces in the above screenshot) SelectedType2SeparatrixWall.vtu : Surface corresponding to another type of wall (the green surface). Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"morseMolecule/#cpython-api","text":"MorseSmaleComplex GeometrySmoother IcospheresFromPoints","title":"C++/Python API"},{"location":"morsePersistence/","text":"Morse persistence \u00b6 Pipeline description \u00b6 The first step is to create the data for our example. A plane is created to which we add random scalar values to create noise. The obtained scalar field is smoothed using the ScalarFieldSmoother . A sum of sine as scalar values is also added to create the nine main hills. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (center view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morsePersistence.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 #!/usr/bin/env python from paraview.simple import * # create a new 'Plane' plane1 = Plane () plane1 . XResolution = 300 plane1 . YResolution = 300 # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = plane1 ) # create a new 'Random Attributes' randomAttributes1 = RandomAttributes ( Input = tetrahedralize2 ) randomAttributes1 . DataType = 'Float' randomAttributes1 . ComponentRange = [ 0.0 , 1.0 ] randomAttributes1 . GeneratePointScalars = 1 # create a new 'TTK ScalarFieldSmoother' tTKScalarFieldSmoother1 = TTKScalarFieldSmoother ( Input = randomAttributes1 ) tTKScalarFieldSmoother1 . ScalarField = [ 'POINTS' , 'RandomPointScalars' ] tTKScalarFieldSmoother1 . IterationNumber = 6 # create a new 'Calculator' sine = Calculator ( Input = tTKScalarFieldSmoother1 ) sine . ResultArrayName = 'Sine' sine . Function = 'sin(20*coordsX+1.5)+sin(20*coordsY+1.5)' # create a new 'Calculator' distanceField = Calculator ( Input = sine ) distanceField . ResultArrayName = 'DistanceField' distanceField . Function = '-sqrt(coordsX*coordsX+coordsY*coordsY)' # create a new 'Calculator' calculator1 = Calculator ( Input = distanceField ) calculator1 . ResultArrayName = 'Blend' calculator1 . Function = 'Sine+5*DistanceField+5*RandomPointScalars' # create a new 'Extract Surface' extractSurface6 = ExtractSurface ( Input = calculator1 ) # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = extractSurface6 ) warpByScalar1 . Scalars = [ 'POINTS' , 'Blend' ] warpByScalar1 . ScaleFactor = 0.05 # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = warpByScalar1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = warpByScalar1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0.0 , 100000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.7 , 10000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = warpByScalar1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'Blend' ] # save the ouput SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'MorseComplexeCriticalPoints.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 0 )) SaveData ( 'MorseComplexe1Separatrices.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 1 )) SaveData ( 'MorseComplexeSegmentation.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 3 )) Inputs \u00b6 None Outputs \u00b6 PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. MorseComplexeCriticalPoints.vtp : the output critical points (or 0 dimensional elements) of the Morse Smale Complex in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexe1Separatrices.vtp : cylinders, representing the edges (or 1 dimensional elements) of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexeSegmentation.vtp : surfaces, representing the segmentation of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 ScalarFieldSmoother MorseSmaleComplex PersistenceCurve PersistenceDiagram TopologicalSimplification","title":"Morse persistence"},{"location":"morsePersistence/#morse-persistence","text":"","title":"Morse persistence"},{"location":"morsePersistence/#pipeline-description","text":"The first step is to create the data for our example. A plane is created to which we add random scalar values to create noise. The obtained scalar field is smoothed using the ScalarFieldSmoother . A sum of sine as scalar values is also added to create the nine main hills. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (center view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces.","title":"Pipeline description"},{"location":"morsePersistence/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morsePersistence.pvsm","title":"ParaView"},{"location":"morsePersistence/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 #!/usr/bin/env python from paraview.simple import * # create a new 'Plane' plane1 = Plane () plane1 . XResolution = 300 plane1 . YResolution = 300 # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = plane1 ) # create a new 'Random Attributes' randomAttributes1 = RandomAttributes ( Input = tetrahedralize2 ) randomAttributes1 . DataType = 'Float' randomAttributes1 . ComponentRange = [ 0.0 , 1.0 ] randomAttributes1 . GeneratePointScalars = 1 # create a new 'TTK ScalarFieldSmoother' tTKScalarFieldSmoother1 = TTKScalarFieldSmoother ( Input = randomAttributes1 ) tTKScalarFieldSmoother1 . ScalarField = [ 'POINTS' , 'RandomPointScalars' ] tTKScalarFieldSmoother1 . IterationNumber = 6 # create a new 'Calculator' sine = Calculator ( Input = tTKScalarFieldSmoother1 ) sine . ResultArrayName = 'Sine' sine . Function = 'sin(20*coordsX+1.5)+sin(20*coordsY+1.5)' # create a new 'Calculator' distanceField = Calculator ( Input = sine ) distanceField . ResultArrayName = 'DistanceField' distanceField . Function = '-sqrt(coordsX*coordsX+coordsY*coordsY)' # create a new 'Calculator' calculator1 = Calculator ( Input = distanceField ) calculator1 . ResultArrayName = 'Blend' calculator1 . Function = 'Sine+5*DistanceField+5*RandomPointScalars' # create a new 'Extract Surface' extractSurface6 = ExtractSurface ( Input = calculator1 ) # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = extractSurface6 ) warpByScalar1 . Scalars = [ 'POINTS' , 'Blend' ] warpByScalar1 . ScaleFactor = 0.05 # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = warpByScalar1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = warpByScalar1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0.0 , 100000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.7 , 10000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = warpByScalar1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'Blend' ] # save the ouput SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'MorseComplexeCriticalPoints.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 0 )) SaveData ( 'MorseComplexe1Separatrices.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 1 )) SaveData ( 'MorseComplexeSegmentation.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 3 ))","title":"Python code"},{"location":"morsePersistence/#inputs","text":"None","title":"Inputs"},{"location":"morsePersistence/#outputs","text":"PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. MorseComplexeCriticalPoints.vtp : the output critical points (or 0 dimensional elements) of the Morse Smale Complex in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexe1Separatrices.vtp : cylinders, representing the edges (or 1 dimensional elements) of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexeSegmentation.vtp : surfaces, representing the segmentation of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"morsePersistence/#cpython-api","text":"ScalarFieldSmoother MorseSmaleComplex PersistenceCurve PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"morseSmaleQuadrangulation/","text":"Morse-Smale Quandrangulation \u00b6 Pipeline description \u00b6 This example first loads a mecanical model as a 2D triangle mesh from disk. This mechanical model embeds a collection of scalar fields that corresponds to the output of the EigenField module. This module generated a family of functions that are coupled to the form of the dataset (basically, they are eigenfunctions of the laplacian matrix of the triangulation, sorted by decreasing eigenvalue magnitude). In a pre-processing step, the 83rd EigenFunction is extracted and normalized with ScalarFieldNormalizer then simplified using PersistenceDiagram and TopologicalSimplification . We then compute the MorseSmaleComplex of the simplified scalar field. The critical points are evenly spread onto the 2D surface and the 1-separatrices will form the base of the quadrangulation (left view on the above screenshot). The filter MorseSmaleQuadrangulation creates a coarse quadrangulation of the input mesh using the Morse-Smale complex critical points and 1-separatrices. This coarse quadrangulation is eventually refined with the QuadrangulationSubdivision filter (right view on the above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseSmaleQuadrangulation.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' rockerArmvtu = XMLUnstructuredGridReader ( FileName = [ \"rockerArm.vtu\" ]) # create a new 'Extract Component' extractComponent1 = ExtractComponent ( Input = rockerArmvtu ) extractComponent1 . InputArray = [ \"POINTS\" , \"OutputEigenFunctions\" ] extractComponent1 . Component = 83 # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = extractComponent1 ) tTKScalarFieldNormalizer1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tTKScalarFieldNormalizer1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"Result\" ] tTKPersistenceDiagram1 . EmbedinDomain = 1 # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"Persistence\" ] threshold1 . ThresholdRange = [ 0.001 , 0.9999999403953552 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tTKScalarFieldNormalizer1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK MorseSmaleQuadrangulation' tTKMorseSmaleQuadrangulation1 = TTKMorseSmaleQuadrangulation ( Triangulatedsurface = OutputPort ( tTKMorseSmaleComplex1 , 3 ), MorseSmalecriticalpoints = tTKMorseSmaleComplex1 , MorseSmale1separatrices = OutputPort ( tTKMorseSmaleComplex1 , 1 ), ) tTKMorseSmaleQuadrangulation1 . DualQuadrangulation = 1 # create a new 'TTK QuadrangulationSubdivision' tTKQuadrangulationSubdivision1 = TTKQuadrangulationSubdivision ( Triangulatedsurface = OutputPort ( tTKMorseSmaleComplex1 , 3 ), Coarsequadrangulation = tTKMorseSmaleQuadrangulation1 , ) tTKQuadrangulationSubdivision1 . Levelofsubdivisions = 3 tTKQuadrangulationSubdivision1 . Numberofrelaxationiterations = 100 # save the output SaveData ( \"Quadrangulation.vtp\" , tTKQuadrangulationSubdivision1 ) Inputs \u00b6 rockerArm.vtu : a two-dimensional triangulated mechanical model. Outputs \u00b6 Quadrangulation.vtp : the output quadrangulated surface. C++/Python API \u00b6 EigenField ScalarFieldNormalizer PersistenceDiagram TopologicalSimplification MorseSmaleComplex MorseSmaleQuadrangulation QuadrangulationSubdivision","title":"Morse-Smale Quandrangulation"},{"location":"morseSmaleQuadrangulation/#morse-smale-quandrangulation","text":"","title":"Morse-Smale Quandrangulation"},{"location":"morseSmaleQuadrangulation/#pipeline-description","text":"This example first loads a mecanical model as a 2D triangle mesh from disk. This mechanical model embeds a collection of scalar fields that corresponds to the output of the EigenField module. This module generated a family of functions that are coupled to the form of the dataset (basically, they are eigenfunctions of the laplacian matrix of the triangulation, sorted by decreasing eigenvalue magnitude). In a pre-processing step, the 83rd EigenFunction is extracted and normalized with ScalarFieldNormalizer then simplified using PersistenceDiagram and TopologicalSimplification . We then compute the MorseSmaleComplex of the simplified scalar field. The critical points are evenly spread onto the 2D surface and the 1-separatrices will form the base of the quadrangulation (left view on the above screenshot). The filter MorseSmaleQuadrangulation creates a coarse quadrangulation of the input mesh using the Morse-Smale complex critical points and 1-separatrices. This coarse quadrangulation is eventually refined with the QuadrangulationSubdivision filter (right view on the above screenshot).","title":"Pipeline description"},{"location":"morseSmaleQuadrangulation/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseSmaleQuadrangulation.pvsm","title":"ParaView"},{"location":"morseSmaleQuadrangulation/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' rockerArmvtu = XMLUnstructuredGridReader ( FileName = [ \"rockerArm.vtu\" ]) # create a new 'Extract Component' extractComponent1 = ExtractComponent ( Input = rockerArmvtu ) extractComponent1 . InputArray = [ \"POINTS\" , \"OutputEigenFunctions\" ] extractComponent1 . Component = 83 # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = extractComponent1 ) tTKScalarFieldNormalizer1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tTKScalarFieldNormalizer1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"Result\" ] tTKPersistenceDiagram1 . EmbedinDomain = 1 # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"Persistence\" ] threshold1 . ThresholdRange = [ 0.001 , 0.9999999403953552 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tTKScalarFieldNormalizer1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"Result\" ] # create a new 'TTK MorseSmaleQuadrangulation' tTKMorseSmaleQuadrangulation1 = TTKMorseSmaleQuadrangulation ( Triangulatedsurface = OutputPort ( tTKMorseSmaleComplex1 , 3 ), MorseSmalecriticalpoints = tTKMorseSmaleComplex1 , MorseSmale1separatrices = OutputPort ( tTKMorseSmaleComplex1 , 1 ), ) tTKMorseSmaleQuadrangulation1 . DualQuadrangulation = 1 # create a new 'TTK QuadrangulationSubdivision' tTKQuadrangulationSubdivision1 = TTKQuadrangulationSubdivision ( Triangulatedsurface = OutputPort ( tTKMorseSmaleComplex1 , 3 ), Coarsequadrangulation = tTKMorseSmaleQuadrangulation1 , ) tTKQuadrangulationSubdivision1 . Levelofsubdivisions = 3 tTKQuadrangulationSubdivision1 . Numberofrelaxationiterations = 100 # save the output SaveData ( \"Quadrangulation.vtp\" , tTKQuadrangulationSubdivision1 )","title":"Python code"},{"location":"morseSmaleQuadrangulation/#inputs","text":"rockerArm.vtu : a two-dimensional triangulated mechanical model.","title":"Inputs"},{"location":"morseSmaleQuadrangulation/#outputs","text":"Quadrangulation.vtp : the output quadrangulated surface.","title":"Outputs"},{"location":"morseSmaleQuadrangulation/#cpython-api","text":"EigenField ScalarFieldNormalizer PersistenceDiagram TopologicalSimplification MorseSmaleComplex MorseSmaleQuadrangulation QuadrangulationSubdivision","title":"C++/Python API"},{"location":"persistenceClustering0/","text":"Persistence Clustering 0 \u00b6 Pipeline description \u00b6 This example performs a persistence driven clustering of a 2D toy data set, taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline to a real-life, high-dimensional, data set. The pipeline starts by estimating the density of the input point cloud with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 2 most persistent density maxima are selected (corresponding to the desired 2 output clusters, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field (top right view, above screenshot). The simplified density field then contains only 2 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering0.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = tTKPersistenceDiagram1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) resampleWithDataset1 . CellLocator = 'Static Cell Locator' SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 ) Inputs \u00b6 clustering0.csv : a 2D point cloud taken from the scikit-learn examples . Outputs \u00b6 OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column) C++/Python API \u00b6 Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"Persistence Clustering 0"},{"location":"persistenceClustering0/#persistence-clustering-0","text":"","title":"Persistence Clustering 0"},{"location":"persistenceClustering0/#pipeline-description","text":"This example performs a persistence driven clustering of a 2D toy data set, taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline to a real-life, high-dimensional, data set. The pipeline starts by estimating the density of the input point cloud with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 2 most persistent density maxima are selected (corresponding to the desired 2 output clusters, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field (top right view, above screenshot). The simplified density field then contains only 2 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter.","title":"Pipeline description"},{"location":"persistenceClustering0/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering0.pvsm","title":"ParaView"},{"location":"persistenceClustering0/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = tTKPersistenceDiagram1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) resampleWithDataset1 . CellLocator = 'Static Cell Locator' SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering0/#inputs","text":"clustering0.csv : a 2D point cloud taken from the scikit-learn examples .","title":"Inputs"},{"location":"persistenceClustering0/#outputs","text":"OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column)","title":"Outputs"},{"location":"persistenceClustering0/#cpython-api","text":"Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"persistenceClustering1/","text":"Persistence Clustering 1 \u00b6 Pipeline description \u00b6 This pipeline performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering1.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ \"clustering1.csv\" ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = \"X\" tableToPoints1 . YColumn = \"Y\" tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ \"POINTS\" , \"ignore arrays\" ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = \"Sum\" # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = \"Plane\" # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 , ) # save the output(s) SaveData ( 'data1Resampled.csv' , resampleWithDataset1 ) Inputs \u00b6 clustering1.csv : a table of 2 dimension points. Outputs \u00b6 data1Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"Persistence Clustering 1"},{"location":"persistenceClustering1/#persistence-clustering-1","text":"","title":"Persistence Clustering 1"},{"location":"persistenceClustering1/#pipeline-description","text":"This pipeline performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.","title":"Pipeline description"},{"location":"persistenceClustering1/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering1.pvsm","title":"ParaView"},{"location":"persistenceClustering1/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ \"clustering1.csv\" ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = \"X\" tableToPoints1 . YColumn = \"Y\" tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ \"POINTS\" , \"ignore arrays\" ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = \"Sum\" # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = \"Plane\" # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"SplatterValues\" ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 , ) # save the output(s) SaveData ( 'data1Resampled.csv' , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering1/#inputs","text":"clustering1.csv : a table of 2 dimension points.","title":"Inputs"},{"location":"persistenceClustering1/#outputs","text":"data1Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.","title":"Outputs"},{"location":"persistenceClustering1/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"C++/Python API"},{"location":"persistenceClustering2/","text":"Persistence Clustering 2 \u00b6 Pipeline description \u00b6 This pipeline is similar to the previous examples of persistence clustering and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering2.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering2.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . GaussianSplatRadius = 0.05 gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 5.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data2Resampled.csv' , resampleWithDataset1 ) Inputs \u00b6 clustering2.csv : a table of 2 dimension points. Outputs \u00b6 data2Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"Persistence Clustering 2"},{"location":"persistenceClustering2/#persistence-clustering-2","text":"","title":"Persistence Clustering 2"},{"location":"persistenceClustering2/#pipeline-description","text":"This pipeline is similar to the previous examples of persistence clustering and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.","title":"Pipeline description"},{"location":"persistenceClustering2/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering2.pvsm","title":"ParaView"},{"location":"persistenceClustering2/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering2.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . GaussianSplatRadius = 0.05 gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 5.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data2Resampled.csv' , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering2/#inputs","text":"clustering2.csv : a table of 2 dimension points.","title":"Inputs"},{"location":"persistenceClustering2/#outputs","text":"data2Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.","title":"Outputs"},{"location":"persistenceClustering2/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"C++/Python API"},{"location":"persistenceClustering3/","text":"Persistence Clustering 3 \u00b6 Pipeline description \u00b6 This pipeline is similar to the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering3.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering3.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . GaussianSplatRadius = 0.05 gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data1Resampled.csv' , resampleWithDataset1 ) Inputs \u00b6 clustering3.csv : a table of 2 dimension points. Outputs \u00b6 data3Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"Persistence Clustering 3"},{"location":"persistenceClustering3/#persistence-clustering-3","text":"","title":"Persistence Clustering 3"},{"location":"persistenceClustering3/#pipeline-description","text":"This pipeline is similar to the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.","title":"Pipeline description"},{"location":"persistenceClustering3/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering3.pvsm","title":"ParaView"},{"location":"persistenceClustering3/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering3.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . GaussianSplatRadius = 0.05 gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data1Resampled.csv' , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering3/#inputs","text":"clustering3.csv : a table of 2 dimension points.","title":"Inputs"},{"location":"persistenceClustering3/#outputs","text":"data3Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.","title":"Outputs"},{"location":"persistenceClustering3/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"C++/Python API"},{"location":"persistenceClustering4/","text":"Persistence Clustering 4 \u00b6 Pipeline description \u00b6 This pipeline is the same as the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering4.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering4.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data4Resampled.csv' , resampleWithDataset1 ) Inputs \u00b6 clustering4.csv : a table of 2 dimension points. Outputs \u00b6 data4Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"Persistence Clustering 4"},{"location":"persistenceClustering4/#persistence-clustering-4","text":"","title":"Persistence Clustering 4"},{"location":"persistenceClustering4/#pipeline-description","text":"This pipeline is the same as the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.. First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data. Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data. From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.","title":"Pipeline description"},{"location":"persistenceClustering4/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering4.pvsm","title":"ParaView"},{"location":"persistenceClustering4/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 from paraview.simple import * # create a new 'CSV Reader' clusteringcsv = CSVReader ( FileName = [ 'clustering4.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clusteringcsv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999.0 ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = threshold1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) # save the output(s) SaveData ( 'data4Resampled.csv' , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering4/#inputs","text":"clustering4.csv : a table of 2 dimension points.","title":"Inputs"},{"location":"persistenceClustering4/#outputs","text":"data4Resampled.csv : the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.","title":"Outputs"},{"location":"persistenceClustering4/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex","title":"C++/Python API"},{"location":"persistenceDrivenCompression/","text":"Persistence-Driven Compression \u00b6 Pipeline description \u00b6 This example helps comparing three outputs of the TopologicalCompression filter to the original input grayscale image (top-left view in the above screenshot), with the following parameters: ZFP relative error tolerance set to 50%, no topological compression (bottom-left view in the above screenshot), Topological loss set to 10%, no ZFP extra compression (top-right view), Topological loss set to 10% and ZFP relative error tolerance set to 50% (bottom-right view). Those files have been generated from the original VTI image using the TopologicalCompressionWriter filter. To read them, Paraview uses its counterpart, TopologicalCompressionReader . ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceDrivenCompression.pvsm Python code \u00b6 This script loads the uncompressed naturalImage_original.vti input file, saves it as in the TTK Topological Compressed Image Data file format, using TopologicalCompressionWriter under the hood. The produced file is then loaded with TopologicalCompressionReader and saved back to VTI. This demonstrates the use of the TopologicalCompression I/O modules. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/usr/bin/env python from paraview.simple import * # read input VTI with 'XML Image Data Reader' naturalImage = XMLImageDataReader ( FileName = [ \"naturalImage_original.vti\" ]) # compress & save to TTK Topological Compression format SaveData ( \"naturalImage_persistence10_zfp50.ttk\" , proxy = naturalImage , ScalarField = [ \"POINTS\" , \"PNGImage\" ], Topologicallosspersistencepercentage = 10 , # Topological loss ZFPRelativeErrorToleranceextra = 50 , # ZFP Relative Error Tolerance ) # read the compressed file with 'TTK TopologicalCompressionReader' naturalImage_compressed = TTKTopologicalCompressionReader ( FileName = \"naturalImage_persistence10_zfp50.ttk\" , ) # write compressed data-set to VTI SaveData ( \"uncompressed_naturalImage_persistence10_zfp50.vti\" , naturalImage_compressed , ) Inputs \u00b6 naturalImage_original.vti : a grayscale picture converted to the VTI format naturalImage_zpf50.ttk : the previous image, compressed using TopologicalCompressionWriter with ZFP compressor only (no topological compression). ZFP relative error tolerance was set to 50%. naturalImage_persistence10.ttk : the first input image, compressed using TopologicalCompressionWriter with a Topological loss of 10% and without ZFP (ZFP relative error tolerance set to a negative value). naturalImage_persistence10_zpf50.ttk : the first input image, compressed using TopologicalCompressionWriter with a Topological loss of 10% and a ZFP relative error tolerance set to 50%. Outputs \u00b6 uncompressed_naturalImage_persistence10_zfp50.vti : the first input, compressed and saved as a VTI file. C++/Python API \u00b6 TopologicalCompression TopologicalCompressionReader TopologicalCompressionWriter","title":"Persistence-Driven Compression"},{"location":"persistenceDrivenCompression/#persistence-driven-compression","text":"","title":"Persistence-Driven Compression"},{"location":"persistenceDrivenCompression/#pipeline-description","text":"This example helps comparing three outputs of the TopologicalCompression filter to the original input grayscale image (top-left view in the above screenshot), with the following parameters: ZFP relative error tolerance set to 50%, no topological compression (bottom-left view in the above screenshot), Topological loss set to 10%, no ZFP extra compression (top-right view), Topological loss set to 10% and ZFP relative error tolerance set to 50% (bottom-right view). Those files have been generated from the original VTI image using the TopologicalCompressionWriter filter. To read them, Paraview uses its counterpart, TopologicalCompressionReader .","title":"Pipeline description"},{"location":"persistenceDrivenCompression/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceDrivenCompression.pvsm","title":"ParaView"},{"location":"persistenceDrivenCompression/#python-code","text":"This script loads the uncompressed naturalImage_original.vti input file, saves it as in the TTK Topological Compressed Image Data file format, using TopologicalCompressionWriter under the hood. The produced file is then loaded with TopologicalCompressionReader and saved back to VTI. This demonstrates the use of the TopologicalCompression I/O modules. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/usr/bin/env python from paraview.simple import * # read input VTI with 'XML Image Data Reader' naturalImage = XMLImageDataReader ( FileName = [ \"naturalImage_original.vti\" ]) # compress & save to TTK Topological Compression format SaveData ( \"naturalImage_persistence10_zfp50.ttk\" , proxy = naturalImage , ScalarField = [ \"POINTS\" , \"PNGImage\" ], Topologicallosspersistencepercentage = 10 , # Topological loss ZFPRelativeErrorToleranceextra = 50 , # ZFP Relative Error Tolerance ) # read the compressed file with 'TTK TopologicalCompressionReader' naturalImage_compressed = TTKTopologicalCompressionReader ( FileName = \"naturalImage_persistence10_zfp50.ttk\" , ) # write compressed data-set to VTI SaveData ( \"uncompressed_naturalImage_persistence10_zfp50.vti\" , naturalImage_compressed , )","title":"Python code"},{"location":"persistenceDrivenCompression/#inputs","text":"naturalImage_original.vti : a grayscale picture converted to the VTI format naturalImage_zpf50.ttk : the previous image, compressed using TopologicalCompressionWriter with ZFP compressor only (no topological compression). ZFP relative error tolerance was set to 50%. naturalImage_persistence10.ttk : the first input image, compressed using TopologicalCompressionWriter with a Topological loss of 10% and without ZFP (ZFP relative error tolerance set to a negative value). naturalImage_persistence10_zpf50.ttk : the first input image, compressed using TopologicalCompressionWriter with a Topological loss of 10% and a ZFP relative error tolerance set to 50%.","title":"Inputs"},{"location":"persistenceDrivenCompression/#outputs","text":"uncompressed_naturalImage_persistence10_zfp50.vti : the first input, compressed and saved as a VTI file.","title":"Outputs"},{"location":"persistenceDrivenCompression/#cpython-api","text":"TopologicalCompression TopologicalCompressionReader TopologicalCompressionWriter","title":"C++/Python API"},{"location":"tectonicPuzzle/","text":"Tectonic Puzzle \u00b6 Pipeline description \u00b6 This example processes a two-dimensional geophysics model of the Earth surface to segment it according to the tectonic plates. The outer surface of the data-set is first extracted with a combination of ParaView's Connectivity and Threshold . Then, the log10 of the Viscosity scalar field is computed with a Calculator (bottom-right view on the above screenshot). Several passes of topological simplification are then combined, using PersistenceDiagram , TopologicalSimplification and MorseSmaleComplex to further clean the scalar field. The Persistence Diagram of the scalar field at the end of this cleaning step is represented in the bottom-right view on the above screenshot. Once this is done, since the low values of the scalar field represent the plates borders and the regions of high values the plates themselves, the Descending 1-Separatrices of the Morse-Smale Complex follow the plates borders and the AscendingManifold Segmentation of the Morse-Smale Complex gives us the expected segmentation of the tectonic plates (top-right view on the above screenshot). Finally, the IdentifierRandomizer filter is used to color neighbor cells with a distinct color (top right view on the above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/tectonicPuzzle.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' tectonicPuzzlevtu = XMLUnstructuredGridReader ( FileName = [ \"tectonicPuzzle.vtu\" ]) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tectonicPuzzlevtu ) # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = extractSurface1 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid1 ) # create a new 'Connectivity' connectivity1 = Connectivity ( Input = tetrahedralize1 ) # create a new 'Threshold' threshold1 = Threshold ( Input = connectivity1 ) threshold1 . Scalars = [ \"POINTS\" , \"RegionId\" ] threshold1 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator1 = Calculator ( Input = threshold1 ) calculator1 . ResultArrayName = \"logViscosity\" calculator1 . Function = \"log10(Viscosity)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'Threshold' threshold2 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold2 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold2 . ThresholdRange = [ - 0.1 , 1269.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold2 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 0.5 , 99.0 ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = persistenceThreshold ) tTKIcospheresFromPoints1 . Radius = 0.5 # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 0.1 # create a new 'Threshold' threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ \"POINTS\" , \"CellDimension\" ] threshold3 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' lARGE_MAXIMA_THRESHOLD = Threshold ( Input = threshold3 ) lARGE_MAXIMA_THRESHOLD . Scalars = [ \"POINTS\" , \"ManifoldSize\" ] lARGE_MAXIMA_THRESHOLD . ThresholdRange = [ 75.0 , 9999.0 ] # create a new 'Threshold' pERSISTENT_MINIMA = Threshold ( Input = tTKIcospheresFromPoints1 ) pERSISTENT_MINIMA . Scalars = [ \"POINTS\" , \"CriticalType\" ] # create a new 'Append Datasets' pERSISTENT_MINIMA_AND_LARGE_MAXIMA = AppendDatasets ( Input = [ pERSISTENT_MINIMA , lARGE_MAXIMA_THRESHOLD ] ) # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification2 = TTKTopologicalSimplification ( Domain = tTKTopologicalSimplification1 , Constraints = pERSISTENT_MINIMA_AND_LARGE_MAXIMA ) tTKTopologicalSimplification2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram2 = TTKPersistenceDiagram ( Input = tTKTopologicalSimplification2 ) tTKPersistenceDiagram2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'Threshold' threshold4 = Threshold ( Input = tTKPersistenceDiagram2 ) threshold4 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold4 . ThresholdRange = [ - 0.1 , 101.0 ] # create a new 'Threshold' threshold5 = Threshold ( Input = threshold4 ) threshold5 . Scalars = [ \"CELLS\" , \"PairType\" ] threshold5 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator2 = Calculator ( Input = threshold5 ) calculator2 . ResultArrayName = \"SaddleValue\" calculator2 . Function = \"coordsX\" # create a new 'Threshold' sADDLE_VALUE_THRESHOLD = Threshold ( Input = calculator2 ) sADDLE_VALUE_THRESHOLD . Scalars = [ \"POINTS\" , \"SaddleValue\" ] sADDLE_VALUE_THRESHOLD . ThresholdRange = [ - 0.2 , 1.75 ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints3 = TTKIcospheresFromPoints ( Input = sADDLE_VALUE_THRESHOLD ) tTKIcospheresFromPoints3 . Radius = 0.5 # create a new 'Threshold' lARGE_MAXIMA_LOW_SADDLE = Threshold ( Input = tTKIcospheresFromPoints3 ) lARGE_MAXIMA_LOW_SADDLE . Scalars = [ \"POINTS\" , \"CriticalType\" ] lARGE_MAXIMA_LOW_SADDLE . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Append Datasets' lARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA = AppendDatasets ( Input = [ pERSISTENT_MINIMA , lARGE_MAXIMA_LOW_SADDLE ] ) # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification3 = TTKTopologicalSimplification ( Domain = tTKTopologicalSimplification2 , Constraints = lARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA , ) tTKTopologicalSimplification3 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex2 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification3 ) tTKMorseSmaleComplex2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex2 , 3 ) ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"AscendingManifold\" ] SaveData ( \"Segmentation.vtu\" , tTKIdentifierRandomizer1 ) Inputs \u00b6 tectonicPuzzle.vtu : two 2-dimensional spheres (one around the other) made up of a triangular mesh. There are several point data arrays attached to it. Those scalar fields represent geophysics measures on the earth surface (and at a certain depth under it); only the Viscosity field will be used in the current example. Outputs \u00b6 Segmentation.vtu : the output segmentation in VTK file format (top right view, above screenshot). This corresponds to a segmentation of the tectonic plates from the Viscosity scalar field. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"Tectonic Puzzle"},{"location":"tectonicPuzzle/#tectonic-puzzle","text":"","title":"Tectonic Puzzle"},{"location":"tectonicPuzzle/#pipeline-description","text":"This example processes a two-dimensional geophysics model of the Earth surface to segment it according to the tectonic plates. The outer surface of the data-set is first extracted with a combination of ParaView's Connectivity and Threshold . Then, the log10 of the Viscosity scalar field is computed with a Calculator (bottom-right view on the above screenshot). Several passes of topological simplification are then combined, using PersistenceDiagram , TopologicalSimplification and MorseSmaleComplex to further clean the scalar field. The Persistence Diagram of the scalar field at the end of this cleaning step is represented in the bottom-right view on the above screenshot. Once this is done, since the low values of the scalar field represent the plates borders and the regions of high values the plates themselves, the Descending 1-Separatrices of the Morse-Smale Complex follow the plates borders and the AscendingManifold Segmentation of the Morse-Smale Complex gives us the expected segmentation of the tectonic plates (top-right view on the above screenshot). Finally, the IdentifierRandomizer filter is used to color neighbor cells with a distinct color (top right view on the above screenshot).","title":"Pipeline description"},{"location":"tectonicPuzzle/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/tectonicPuzzle.pvsm","title":"ParaView"},{"location":"tectonicPuzzle/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' tectonicPuzzlevtu = XMLUnstructuredGridReader ( FileName = [ \"tectonicPuzzle.vtu\" ]) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tectonicPuzzlevtu ) # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = extractSurface1 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid1 ) # create a new 'Connectivity' connectivity1 = Connectivity ( Input = tetrahedralize1 ) # create a new 'Threshold' threshold1 = Threshold ( Input = connectivity1 ) threshold1 . Scalars = [ \"POINTS\" , \"RegionId\" ] threshold1 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator1 = Calculator ( Input = threshold1 ) calculator1 . ResultArrayName = \"logViscosity\" calculator1 . Function = \"log10(Viscosity)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'Threshold' threshold2 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold2 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold2 . ThresholdRange = [ - 0.1 , 1269.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold2 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 0.5 , 99.0 ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = persistenceThreshold ) tTKIcospheresFromPoints1 . Radius = 0.5 # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 0.1 # create a new 'Threshold' threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ \"POINTS\" , \"CellDimension\" ] threshold3 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' lARGE_MAXIMA_THRESHOLD = Threshold ( Input = threshold3 ) lARGE_MAXIMA_THRESHOLD . Scalars = [ \"POINTS\" , \"ManifoldSize\" ] lARGE_MAXIMA_THRESHOLD . ThresholdRange = [ 75.0 , 9999.0 ] # create a new 'Threshold' pERSISTENT_MINIMA = Threshold ( Input = tTKIcospheresFromPoints1 ) pERSISTENT_MINIMA . Scalars = [ \"POINTS\" , \"CriticalType\" ] # create a new 'Append Datasets' pERSISTENT_MINIMA_AND_LARGE_MAXIMA = AppendDatasets ( Input = [ pERSISTENT_MINIMA , lARGE_MAXIMA_THRESHOLD ] ) # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification2 = TTKTopologicalSimplification ( Domain = tTKTopologicalSimplification1 , Constraints = pERSISTENT_MINIMA_AND_LARGE_MAXIMA ) tTKTopologicalSimplification2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram2 = TTKPersistenceDiagram ( Input = tTKTopologicalSimplification2 ) tTKPersistenceDiagram2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'Threshold' threshold4 = Threshold ( Input = tTKPersistenceDiagram2 ) threshold4 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold4 . ThresholdRange = [ - 0.1 , 101.0 ] # create a new 'Threshold' threshold5 = Threshold ( Input = threshold4 ) threshold5 . Scalars = [ \"CELLS\" , \"PairType\" ] threshold5 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator2 = Calculator ( Input = threshold5 ) calculator2 . ResultArrayName = \"SaddleValue\" calculator2 . Function = \"coordsX\" # create a new 'Threshold' sADDLE_VALUE_THRESHOLD = Threshold ( Input = calculator2 ) sADDLE_VALUE_THRESHOLD . Scalars = [ \"POINTS\" , \"SaddleValue\" ] sADDLE_VALUE_THRESHOLD . ThresholdRange = [ - 0.2 , 1.75 ] # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints3 = TTKIcospheresFromPoints ( Input = sADDLE_VALUE_THRESHOLD ) tTKIcospheresFromPoints3 . Radius = 0.5 # create a new 'Threshold' lARGE_MAXIMA_LOW_SADDLE = Threshold ( Input = tTKIcospheresFromPoints3 ) lARGE_MAXIMA_LOW_SADDLE . Scalars = [ \"POINTS\" , \"CriticalType\" ] lARGE_MAXIMA_LOW_SADDLE . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Append Datasets' lARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA = AppendDatasets ( Input = [ pERSISTENT_MINIMA , lARGE_MAXIMA_LOW_SADDLE ] ) # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification3 = TTKTopologicalSimplification ( Domain = tTKTopologicalSimplification2 , Constraints = lARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA , ) tTKTopologicalSimplification3 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex2 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification3 ) tTKMorseSmaleComplex2 . ScalarField = [ \"POINTS\" , \"logViscosity\" ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex2 , 3 ) ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"AscendingManifold\" ] SaveData ( \"Segmentation.vtu\" , tTKIdentifierRandomizer1 )","title":"Python code"},{"location":"tectonicPuzzle/#inputs","text":"tectonicPuzzle.vtu : two 2-dimensional spheres (one around the other) made up of a triangular mesh. There are several point data arrays attached to it. Those scalar fields represent geophysics measures on the earth surface (and at a certain depth under it); only the Viscosity field will be used in the current example.","title":"Inputs"},{"location":"tectonicPuzzle/#outputs","text":"Segmentation.vtu : the output segmentation in VTK file format (top right view, above screenshot). This corresponds to a segmentation of the tectonic plates from the Viscosity scalar field.","title":"Outputs"},{"location":"tectonicPuzzle/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"C++/Python API"},{"location":"timeTracking/","text":"Time Tracking \u00b6 Pipeline description \u00b6 This example loads a 2D time-dependent scalar field, where time steps are stored as a sequence of data arrays. Using TrackingFromFields , a tracking mesh for the temporal evolution of critical points is computed. This filter computes an optimal matching between persistence diagrams (with respect to Wasserstein metric), and discards critical point pairs below a persistence of 1% by default (parameter Tolerance ). The state file further contains an animation of the critical points over time. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/timeTracking.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' timeTrackingvti = XMLImageDataReader ( FileName = [ 'timeTracking.vti' ]) timeTrackingvti . CellArrayStatus = [] # select data arrays 000, 002, 004, ..., 118 timeTrackingvti . PointArrayStatus = [ ' {:0>3} ' . format ( i ) for i in range ( 0 , 120 , 2 )] # create a new 'TTK TrackingFromFields' tTKTrackingFromFields1 = TTKTrackingFromFields ( Input = timeTrackingvti ) tTKTrackingFromFields1 . ForceZtranslation = 1 tTKTrackingFromFields1 . ZTranslation = 0.125 # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tTKTrackingFromFields1 ) # save the output SaveData ( 'timeTracking.vtp' , extractSurface1 ) Inputs \u00b6 timeTracking.vti : time-dependent vorticity of a 2D vortex street, with time steps represented by data arrays '000', '002', ..., '118' Outputs \u00b6 timeTracking.vtp : tracking mesh of critical points C++/Python API \u00b6 TrackingFromFields","title":"Time Tracking"},{"location":"timeTracking/#time-tracking","text":"","title":"Time Tracking"},{"location":"timeTracking/#pipeline-description","text":"This example loads a 2D time-dependent scalar field, where time steps are stored as a sequence of data arrays. Using TrackingFromFields , a tracking mesh for the temporal evolution of critical points is computed. This filter computes an optimal matching between persistence diagrams (with respect to Wasserstein metric), and discards critical point pairs below a persistence of 1% by default (parameter Tolerance ). The state file further contains an animation of the critical points over time.","title":"Pipeline description"},{"location":"timeTracking/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/timeTracking.pvsm","title":"ParaView"},{"location":"timeTracking/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' timeTrackingvti = XMLImageDataReader ( FileName = [ 'timeTracking.vti' ]) timeTrackingvti . CellArrayStatus = [] # select data arrays 000, 002, 004, ..., 118 timeTrackingvti . PointArrayStatus = [ ' {:0>3} ' . format ( i ) for i in range ( 0 , 120 , 2 )] # create a new 'TTK TrackingFromFields' tTKTrackingFromFields1 = TTKTrackingFromFields ( Input = timeTrackingvti ) tTKTrackingFromFields1 . ForceZtranslation = 1 tTKTrackingFromFields1 . ZTranslation = 0.125 # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tTKTrackingFromFields1 ) # save the output SaveData ( 'timeTracking.vtp' , extractSurface1 )","title":"Python code"},{"location":"timeTracking/#inputs","text":"timeTracking.vti : time-dependent vorticity of a 2D vortex street, with time steps represented by data arrays '000', '002', ..., '118'","title":"Inputs"},{"location":"timeTracking/#outputs","text":"timeTracking.vtp : tracking mesh of critical points","title":"Outputs"},{"location":"timeTracking/#cpython-api","text":"TrackingFromFields","title":"C++/Python API"},{"location":"tribute/","text":"Tribute to Edelsbrunner and Harer's book \u00b6 Pipeline description \u00b6 This example loads a PNG microscopy image from disk, from which gray-scale scalar values are created. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (top right; non-simplified persistence diagram shown in gray). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of the MorseSmaleComplex . Its ascending manifolds, separatrices and critical points are shown in the bottom views (with scalar value mapped to height in the bottom right view). The separatrices are also shown, as overlay over the original scalar data, in the top left view. In this example, the MorseSmaleComplex segments the input microscopy data into biological cells. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/tribute.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #!/usr/bin/env python from paraview.simple import * # create a new 'PNG Series Reader' tributepng = PNGSeriesReader ( FileNames = [ 'tribute.png' ]) # create a new 'Calculator' calculator1 = Calculator ( Input = tributepng ) calculator1 . ResultArrayName = 'originalData' calculator1 . Function = 'sqrt(PNGImage_X*PNGImage_X+PNGImage_Y*PNGImage_Y)' # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999999.0 ] # create a new 'Threshold' minimumPairs = Threshold ( Input = threshold1 ) minimumPairs . Scalars = [ 'CELLS' , 'PairType' ] minimumPairs . ThresholdRange = [ - 1.0 , 0.0 ] # create a new 'Threshold' maximumPairs = Threshold ( Input = threshold1 ) maximumPairs . Scalars = [ 'CELLS' , 'PairType' ] maximumPairs . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator2 = Calculator ( Input = maximumPairs ) calculator2 . ResultArrayName = 'Birth' calculator2 . Function = 'coordsX' # create a new 'Threshold' birthThreshold = Threshold ( Input = calculator2 ) birthThreshold . Scalars = [ 'POINTS' , 'Birth' ] birthThreshold . ThresholdRange = [ 257.390747070312 , 297.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ minimumPairs , birthThreshold ]) # create a new 'Threshold' persistenceThreshold = Threshold ( Input = appendDatasets1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 8.5 , 9999 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex2 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex2 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer2 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex2 , 3 )) tTKIdentifierRandomizer2 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # save the output SaveData ( 'tribute_segmentation.vti' , tTKIdentifierRandomizer2 ) Inputs \u00b6 tribute.png : PNG image of a microscopy of cell sheet morphogenesis (from Edelsbrunner & Harer's book, page 217) Outputs \u00b6 triubute_segmentation.vtu : segmentation of tribute.png into cells (Morse\u2013Smale complex; data array AscendingManifold ) C++/Python API \u00b6 IdentifierRandomizer MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"Tribute to Edelsbrunner and Harer's book"},{"location":"tribute/#tribute-to-edelsbrunner-and-harers-book","text":"","title":"Tribute to Edelsbrunner and Harer's book"},{"location":"tribute/#pipeline-description","text":"This example loads a PNG microscopy image from disk, from which gray-scale scalar values are created. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (top right; non-simplified persistence diagram shown in gray). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of the MorseSmaleComplex . Its ascending manifolds, separatrices and critical points are shown in the bottom views (with scalar value mapped to height in the bottom right view). The separatrices are also shown, as overlay over the original scalar data, in the top left view. In this example, the MorseSmaleComplex segments the input microscopy data into biological cells.","title":"Pipeline description"},{"location":"tribute/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/tribute.pvsm","title":"ParaView"},{"location":"tribute/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #!/usr/bin/env python from paraview.simple import * # create a new 'PNG Series Reader' tributepng = PNGSeriesReader ( FileNames = [ 'tribute.png' ]) # create a new 'Calculator' calculator1 = Calculator ( Input = tributepng ) calculator1 . ResultArrayName = 'originalData' calculator1 . Function = 'sqrt(PNGImage_X*PNGImage_X+PNGImage_Y*PNGImage_Y)' # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ - 0.1 , 999999.0 ] # create a new 'Threshold' minimumPairs = Threshold ( Input = threshold1 ) minimumPairs . Scalars = [ 'CELLS' , 'PairType' ] minimumPairs . ThresholdRange = [ - 1.0 , 0.0 ] # create a new 'Threshold' maximumPairs = Threshold ( Input = threshold1 ) maximumPairs . Scalars = [ 'CELLS' , 'PairType' ] maximumPairs . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Calculator' calculator2 = Calculator ( Input = maximumPairs ) calculator2 . ResultArrayName = 'Birth' calculator2 . Function = 'coordsX' # create a new 'Threshold' birthThreshold = Threshold ( Input = calculator2 ) birthThreshold . Scalars = [ 'POINTS' , 'Birth' ] birthThreshold . ThresholdRange = [ 257.390747070312 , 297.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ minimumPairs , birthThreshold ]) # create a new 'Threshold' persistenceThreshold = Threshold ( Input = appendDatasets1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 8.5 , 9999 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex2 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex2 . ScalarField = [ 'POINTS' , 'originalData' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer2 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex2 , 3 )) tTKIdentifierRandomizer2 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # save the output SaveData ( 'tribute_segmentation.vti' , tTKIdentifierRandomizer2 )","title":"Python code"},{"location":"tribute/#inputs","text":"tribute.png : PNG image of a microscopy of cell sheet morphogenesis (from Edelsbrunner & Harer's book, page 217)","title":"Inputs"},{"location":"tribute/#outputs","text":"triubute_segmentation.vtu : segmentation of tribute.png into cells (Morse\u2013Smale complex; data array AscendingManifold )","title":"Outputs"},{"location":"tribute/#cpython-api","text":"IdentifierRandomizer MorseSmaleComplex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"}]}