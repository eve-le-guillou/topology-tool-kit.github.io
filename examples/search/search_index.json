{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the TTK Examples! \u00b6 This website hosts a list of data analysis pipelines exemplifying the usage of TTK with ParaView and its Python API pvpython . This website is targeting novice users who are not power users of ParaView but who would like to get started with topological data analysis with TTK in Python. Each example includes: a screenshot (or a tutorial video) a short description the command line to reproduce the example with ParaView the corresponding Python code, to: load the input data execute the analysis pipeline store the output to disk (for later analysis or visualization, e.g. with ParaView ) a description of the inputs and outputs pointers to the corresponding C++/Python documentation This documentation assumes a default TTK installation (with the pvpython API support enabled) and that the repository ttk-data has been downloaded locally. If you have any questions regarding these examples, please let us know by sending an email to the TTK user mailing list ! Scalar data \u00b6 Name Screenshot Dragon Morse persistence Built-in example 1 Interaction site Viscous fingering Morse molecule Tectonic puzzle Ocean vortices ! Contour around point CT bones Tribute Image processing Persistence driven compression Morse-Smale quadrangulation Bivariate scalar data \u00b6 Name Screenshot Built-in example 2 Bivariate toy Bivariate toy CSP peeling Mechanical Uncertain scalar data \u00b6 Name Screenshot Built-in example 3 Uncertain starting vortex Time-varying scalar data \u00b6 Name Screenshot Time tracking Merge tree feature tracking Merge tree temporal reduction Nested tracking graph Ensemble scalar data \u00b6 Name Screenshot Persistence diagram distance Persistence diagram clustering Merge tree clustering Contour tree alignment High-dimensional / point cloud data \u00b6 Name Screenshot Persistence clustering gallery Persistence clustering0 Persistence clustering1 Persistence clustering2 Persistence clustering3 Persistence clustering4 Karhunen-Love Digits 64-Dimensions 1-manifold learning 1-manifold learning circles 2-manifold learning In-situ features \u00b6 Name Screenshot Geometry approximation Cinema darkroom Misc features \u00b6 Name Screenshot Cinema IO Manifold checks","title":"Welcome to the TTK Examples!"},{"location":"#welcome-to-the-ttk-examples","text":"This website hosts a list of data analysis pipelines exemplifying the usage of TTK with ParaView and its Python API pvpython . This website is targeting novice users who are not power users of ParaView but who would like to get started with topological data analysis with TTK in Python. Each example includes: a screenshot (or a tutorial video) a short description the command line to reproduce the example with ParaView the corresponding Python code, to: load the input data execute the analysis pipeline store the output to disk (for later analysis or visualization, e.g. with ParaView ) a description of the inputs and outputs pointers to the corresponding C++/Python documentation This documentation assumes a default TTK installation (with the pvpython API support enabled) and that the repository ttk-data has been downloaded locally. If you have any questions regarding these examples, please let us know by sending an email to the TTK user mailing list !","title":"Welcome to the TTK Examples!"},{"location":"#scalar-data","text":"Name Screenshot Dragon Morse persistence Built-in example 1 Interaction site Viscous fingering Morse molecule Tectonic puzzle Ocean vortices ! Contour around point CT bones Tribute Image processing Persistence driven compression Morse-Smale quadrangulation","title":"Scalar data"},{"location":"#bivariate-scalar-data","text":"Name Screenshot Built-in example 2 Bivariate toy Bivariate toy CSP peeling Mechanical","title":"Bivariate scalar data"},{"location":"#uncertain-scalar-data","text":"Name Screenshot Built-in example 3 Uncertain starting vortex","title":"Uncertain scalar data"},{"location":"#time-varying-scalar-data","text":"Name Screenshot Time tracking Merge tree feature tracking Merge tree temporal reduction Nested tracking graph","title":"Time-varying scalar data"},{"location":"#ensemble-scalar-data","text":"Name Screenshot Persistence diagram distance Persistence diagram clustering Merge tree clustering Contour tree alignment","title":"Ensemble scalar data"},{"location":"#high-dimensional-point-cloud-data","text":"Name Screenshot Persistence clustering gallery Persistence clustering0 Persistence clustering1 Persistence clustering2 Persistence clustering3 Persistence clustering4 Karhunen-Love Digits 64-Dimensions 1-manifold learning 1-manifold learning circles 2-manifold learning","title":"High-dimensional / point cloud data"},{"location":"#in-situ-features","text":"Name Screenshot Geometry approximation Cinema darkroom","title":"In-situ features"},{"location":"#misc-features","text":"Name Screenshot Cinema IO Manifold checks","title":"Misc features"},{"location":"BuiltInExample1/","text":"Built in example 1 \u00b6 Pipeline description \u00b6 This example computes minima, maxima and the persistence diagram for 2D flow data (von Karman vortex street). First, the data is transformed and preprocessed to estimate the vorticity of the flow (via the orthogonal component of the curl). Then, the PersistenceDiagram and PersistenceCurve are computed. To the persistence diagram, a threshold is applied to remove the diagonal. The output are the persistence pairs. These pairs are filtered based on persistence to maintain only the most persistent features. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification and the 2D domain is embedded into 3D space based on the scalar values. Finally, the Critical Points of the simplified and warped data are computed. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/BuiltInExample1.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample1.vti' ]) # create a new 'Transform' transform1 = Transform ( Input = builtInExamplevti ) transform1 . Transform = 'Transform' # init the 'Transform' selected for 'Transform' transform1 . Transform . Rotate = [ 0.0 , 0.0 , - 90.0 ] # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = transform1 ) #computeDerivatives1.Scalars = [None, ''] computeDerivatives1 . Vectors = [ 'POINTS' , 'Vectors_' ] computeDerivatives1 . OutputVectorType = 'Vorticity' # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = 'myVorticity' calculator1 . Function = 'Vorticity_Z' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = tTKScalarFieldNormalizer1 ) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tetrahedralize1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Threshold' persistencePairs = Threshold ( Input = tTKPersistenceDiagram1 ) persistencePairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] persistencePairs . ThresholdRange = [ - 0.1 , 957.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = persistencePairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.02 , 1.0 ] # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = tetrahedralize1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tetrahedralize1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = tTKTopologicalSimplification1 ) warpByScalar1 . Scalars = [ 'POINTS' , 'myVorticity' ] warpByScalar1 . ScaleFactor = 300.0 # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = warpByScalar1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # save the output SaveData ( 'warpedInput.vtu' , warpByScalar1 ) SaveData ( 'CriticalPoints.csv' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) Inputs \u00b6 BuiltInExample1.vti : a two-dimensional regular grid encoding flow magnitude of a K\u00e1rm\u00e1n vortex street. Outputs \u00b6 warpedInput.vtu : the warped and tetrahedralized scalar field in VTK file format (middle view, above screenshot). CriticalPoints.csv : the critical points of the warped scalar field in csv format (middle view, above screenshot). PersistenceCurve.csv : the output persistence curve (top right view, above screenshot). PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 PersistenceCurve PersistenceDiagram TopologicalSimplification Critical Points","title":"Built in example 1"},{"location":"BuiltInExample1/#built-in-example-1","text":"","title":"Built in example 1"},{"location":"BuiltInExample1/#pipeline-description","text":"This example computes minima, maxima and the persistence diagram for 2D flow data (von Karman vortex street). First, the data is transformed and preprocessed to estimate the vorticity of the flow (via the orthogonal component of the curl). Then, the PersistenceDiagram and PersistenceCurve are computed. To the persistence diagram, a threshold is applied to remove the diagonal. The output are the persistence pairs. These pairs are filtered based on persistence to maintain only the most persistent features. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification and the 2D domain is embedded into 3D space based on the scalar values. Finally, the Critical Points of the simplified and warped data are computed.","title":"Pipeline description"},{"location":"BuiltInExample1/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/BuiltInExample1.pvsm","title":"ParaView"},{"location":"BuiltInExample1/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample1.vti' ]) # create a new 'Transform' transform1 = Transform ( Input = builtInExamplevti ) transform1 . Transform = 'Transform' # init the 'Transform' selected for 'Transform' transform1 . Transform . Rotate = [ 0.0 , 0.0 , - 90.0 ] # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = transform1 ) #computeDerivatives1.Scalars = [None, ''] computeDerivatives1 . Vectors = [ 'POINTS' , 'Vectors_' ] computeDerivatives1 . OutputVectorType = 'Vorticity' # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = 'myVorticity' calculator1 . Function = 'Vorticity_Z' # create a new 'TTK ScalarFieldNormalizer' tTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer ( Input = calculator1 ) tTKScalarFieldNormalizer1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = tTKScalarFieldNormalizer1 ) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = tetrahedralize1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Threshold' persistencePairs = Threshold ( Input = tTKPersistenceDiagram1 ) persistencePairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] persistencePairs . ThresholdRange = [ - 0.1 , 957.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = persistencePairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.02 , 1.0 ] # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = tetrahedralize1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = tetrahedralize1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = tTKTopologicalSimplification1 ) warpByScalar1 . Scalars = [ 'POINTS' , 'myVorticity' ] warpByScalar1 . ScaleFactor = 300.0 # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = warpByScalar1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'myVorticity' ] # save the output SaveData ( 'warpedInput.vtu' , warpByScalar1 ) SaveData ( 'CriticalPoints.csv' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 ))","title":"Python code"},{"location":"BuiltInExample1/#inputs","text":"BuiltInExample1.vti : a two-dimensional regular grid encoding flow magnitude of a K\u00e1rm\u00e1n vortex street.","title":"Inputs"},{"location":"BuiltInExample1/#outputs","text":"warpedInput.vtu : the warped and tetrahedralized scalar field in VTK file format (middle view, above screenshot). CriticalPoints.csv : the critical points of the warped scalar field in csv format (middle view, above screenshot). PersistenceCurve.csv : the output persistence curve (top right view, above screenshot). PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"BuiltInExample1/#cpython-api","text":"PersistenceCurve PersistenceDiagram TopologicalSimplification Critical Points","title":"C++/Python API"},{"location":"cinemaIO/","text":"CinemaIO example \u00b6 Pipeline description \u00b6 This example first loads a cinema database of a simulation from disk, consisting of three dimensional image files, using the CinemaReader . This outputs a vtkTable. The database is queried for a selection of images, using CinemaQuery , which supports SQL queries on vtkTables (bottom view shows query result in a spreadsheet view). Each selected entry in the database is read by the CinemaProductReader , which outputs a vtkMultiBlock of the images. The images are sliced with a plane, and each slice is visualized side-by-side using the GridLayout (top view in screenshot). ForEach is used to loop through all slices, and then the ArrayEditor is used to add a FieldData value to each slice. In this case, we add the interval SampleInterval between each queried entry. Each slice is then written to a new cinema database with the CinemaWriter . Finally, the for-loop is terminated using EndFor . ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/cinemaIO.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' viscousFingerscdb = TTKCinemaReader ( DatabasePath = 'ViscousFingers.cdb' ) # create a new 'TTK CinemaQuery' tTKCinemaQuery1 = TTKCinemaQuery ( InputTable = viscousFingerscdb ) tTKCinemaQuery1 . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE Sim='run01' AND Time%10=0 ORDER BY Time LIMIT 8 OFFSET 1\"\"\" # create a new 'TTK CinemaProductReader' tTKCinemaProductReader1 = TTKCinemaProductReader ( Input = tTKCinemaQuery1 ) # create a new 'Slice' slice1 = Slice ( Input = tTKCinemaProductReader1 ) slice1 . SliceType = 'Plane' slice1 . HyperTreeGridSlicer = 'Plane' slice1 . SliceOffsetValues = [ 0.0 ] # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Origin = [ 31.5 , 31.5 , 31.5 ] # create a new 'TTK GridLayout' tTKGridLayout1 = TTKGridLayout ( Input = slice1 ) tTKGridLayout1 . ColumnAxis = 'Y' tTKGridLayout1 . ColumnGap = 8.0 tTKGridLayout1 . RowAxis = 'Z' tTKGridLayout1 . NumberofRows = 1 # create a new 'TTK ForEach' tTKForEach1 = TTKForEach ( Input = tTKGridLayout1 ) tTKForEach1 . IterationMode = 'Block' tTKForEach1 . InputArray = [ 'POINTS' , 'ImageFile' ] tTKForEach1 . OutputType = 'vtkPolyData' # create a new 'TTK ArrayEditor' tTKArrayEditor1 = TTKArrayEditor ( Target = tTKForEach1 , Source = None ) tTKArrayEditor1 . TargetAttributeType = 'Field Data' tTKArrayEditor1 . DataString = 'SampleInterval, 10' tTKArrayEditor1 . TargetArray = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK CinemaWriter' tTKCinemaWriter1 = TTKCinemaWriter ( Input = tTKArrayEditor1 , DatabasePath = 'ViscousFingersSampled.cdb' ) tTKCinemaWriter1 . ScalarField = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK EndFor' tTKEndFor1 = TTKEndFor ( Data = tTKCinemaWriter1 , For = tTKForEach1 ) UpdatePipeline () Inputs \u00b6 ViscousFingers.cdb : a cinema database of VTK Image files from a simulation. Outputs \u00b6 ViscousFingersSampled.cdb : a cinema database containing the sampled slices of the input cinema database. C++/Python API \u00b6 CinemaReader CinemaQuery CinemaProductReader GridLayout ForEach ArrayEditor CinemaWriter EndFor","title":"CinemaIO example"},{"location":"cinemaIO/#cinemaio-example","text":"","title":"CinemaIO example"},{"location":"cinemaIO/#pipeline-description","text":"This example first loads a cinema database of a simulation from disk, consisting of three dimensional image files, using the CinemaReader . This outputs a vtkTable. The database is queried for a selection of images, using CinemaQuery , which supports SQL queries on vtkTables (bottom view shows query result in a spreadsheet view). Each selected entry in the database is read by the CinemaProductReader , which outputs a vtkMultiBlock of the images. The images are sliced with a plane, and each slice is visualized side-by-side using the GridLayout (top view in screenshot). ForEach is used to loop through all slices, and then the ArrayEditor is used to add a FieldData value to each slice. In this case, we add the interval SampleInterval between each queried entry. Each slice is then written to a new cinema database with the CinemaWriter . Finally, the for-loop is terminated using EndFor .","title":"Pipeline description"},{"location":"cinemaIO/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/cinemaIO.pvsm","title":"ParaView"},{"location":"cinemaIO/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' viscousFingerscdb = TTKCinemaReader ( DatabasePath = 'ViscousFingers.cdb' ) # create a new 'TTK CinemaQuery' tTKCinemaQuery1 = TTKCinemaQuery ( InputTable = viscousFingerscdb ) tTKCinemaQuery1 . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE Sim='run01' AND Time%10=0 ORDER BY Time LIMIT 8 OFFSET 1\"\"\" # create a new 'TTK CinemaProductReader' tTKCinemaProductReader1 = TTKCinemaProductReader ( Input = tTKCinemaQuery1 ) # create a new 'Slice' slice1 = Slice ( Input = tTKCinemaProductReader1 ) slice1 . SliceType = 'Plane' slice1 . HyperTreeGridSlicer = 'Plane' slice1 . SliceOffsetValues = [ 0.0 ] # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Origin = [ 31.5 , 31.5 , 31.5 ] # create a new 'TTK GridLayout' tTKGridLayout1 = TTKGridLayout ( Input = slice1 ) tTKGridLayout1 . ColumnAxis = 'Y' tTKGridLayout1 . ColumnGap = 8.0 tTKGridLayout1 . RowAxis = 'Z' tTKGridLayout1 . NumberofRows = 1 # create a new 'TTK ForEach' tTKForEach1 = TTKForEach ( Input = tTKGridLayout1 ) tTKForEach1 . IterationMode = 'Block' tTKForEach1 . InputArray = [ 'POINTS' , 'ImageFile' ] tTKForEach1 . OutputType = 'vtkPolyData' # create a new 'TTK ArrayEditor' tTKArrayEditor1 = TTKArrayEditor ( Target = tTKForEach1 , Source = None ) tTKArrayEditor1 . TargetAttributeType = 'Field Data' tTKArrayEditor1 . DataString = 'SampleInterval, 10' tTKArrayEditor1 . TargetArray = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK CinemaWriter' tTKCinemaWriter1 = TTKCinemaWriter ( Input = tTKArrayEditor1 , DatabasePath = 'ViscousFingersSampled.cdb' ) tTKCinemaWriter1 . ScalarField = [ 'POINTS' , 'ImageFile' ] # create a new 'TTK EndFor' tTKEndFor1 = TTKEndFor ( Data = tTKCinemaWriter1 , For = tTKForEach1 ) UpdatePipeline ()","title":"Python code"},{"location":"cinemaIO/#inputs","text":"ViscousFingers.cdb : a cinema database of VTK Image files from a simulation.","title":"Inputs"},{"location":"cinemaIO/#outputs","text":"ViscousFingersSampled.cdb : a cinema database containing the sampled slices of the input cinema database.","title":"Outputs"},{"location":"cinemaIO/#cpython-api","text":"CinemaReader CinemaQuery CinemaProductReader GridLayout ForEach ArrayEditor CinemaWriter EndFor","title":"C++/Python API"},{"location":"contourTreeAlignment/","text":"Contour Tree Alignment \u00b6 Pipeline description \u00b6 This example first loads a scalar field ensemble from disk as a cinema data base. The ensemble consists of 23 time-dependent scalar fields with 10 time steps each. The ensemble is then filtered for the 23 scalar fields of one fixed time point and read as a vtkMultiBlockDataSet. Here we use the CinemaReader , CinemaQuery and CinemaProductReader filters. In a pre-processing, the scalar fields are topologically simplified by persistence using the TopologicalSimplificationByPersistence filter. The filter is automatically applied to each member of the MultiBlockDataSet. Then, for each simplified member field, the contour tree is computed using the FTMTree module. The resulting MultiBlock of contour trees is then used as input for the Contour Tree Alignment filter. This alignment is a super tree of all contour trees and can be seen as a representative of the topology of the whole ensemble. Unfortunately, the vtk object representing the alignment does not have any layout information attached. Therefore, we use the PlanarGraphLayout together with a paraview calculator to compute and apply the layout information. We now want to check which features of the original scalar fields have been matched onto each other. Therefore, we use the ExtractSeletion filter to extract one vertex and attach its segmentationIDs array to the multi block data set representing the segmentations of the contour trees. We also use a Grid Layout to render the multi block in a comparable fashion (right view, above screenshot). As a last step, we use the ForEach and EndFor filters to iterate the multi block of segmentations and in each iteration, we extract the region of the scalar field that corresponds to the segmentation id from the selected vertex. The extraction is done using the TTKExtract filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/contourTreeAlignment.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' ttkCinemaReader = TTKCinemaReader ( DatabasePath = './heatedCylinder/heatedCylinder_2D_raw.cdb' ) # create a new 'TTK CinemaQuery' ttkCinemaQuery = TTKCinemaQuery ( InputTable = ttkCinemaReader ) ttkCinemaQuery . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE time=4.2\"\"\" # create a new 'TTK CinemaProductReader' ttkCinemaProductReader = TTKCinemaProductReader ( Input = ttkCinemaQuery ) # create a new 'TTK TopologicalSimplificationByPersistence' ttkTopologicalSimplificationByPersistence = TTKTopologicalSimplificationByPersistence ( Input = ttkCinemaProductReader ) ttkTopologicalSimplificationByPersistence . InputArray = [ 'POINTS' , 'nrrd' ] ttkTopologicalSimplificationByPersistence . PersistenceThreshold = 0.05 # create a new 'TTK Merge and Contour Tree (FTM)' ttkMergeandContourTreeFTM = TTKMergeandContourTreeFTM ( Input = ttkTopologicalSimplificationByPersistence ) ttkMergeandContourTreeFTM . ScalarField = [ 'POINTS' , 'nrrd' ] # create a new 'TTK ContourTreeAlignment' contourTreeAlignment = TTKContourTreeAlignment ( Input = OutputPort ( ttkMergeandContourTreeFTM , 1 ), ExportPath = '' ) contourTreeAlignment . ScalarField = [ 'POINTS' , 'Scalar' ] contourTreeAlignment . Regionsizearray = [ 'CELLS' , 'RegionSize' ] contourTreeAlignment . SegmentationIDarrayforCT = [ 'CELLS' , 'SegmentationId' ] contourTreeAlignment . SegmentIDarrayforsegmentation = [ 'POINTS' , 'Scalar' ] # create a new 'TTK PlanarGraphLayout' alignmentLayout = TTKPlanarGraphLayout ( Input = contourTreeAlignment ) alignmentLayout . SequenceArray = [ 'POINTS' , 'Scalar' ] alignmentLayout . SizeArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . UseBranches = 1 alignmentLayout . BranchArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . LevelArray = [ 'POINTS' , 'BranchIDs' ] # create a new 'Calculator' alignmentEdges = Calculator ( Input = alignmentLayout ) alignmentEdges . CoordinateResults = 1 alignmentEdges . Function = 'iHat*Layout_Y+jHat*Scalar*3' # create a query selection QuerySelect ( QueryString = '(id == 16)' , Source = alignmentEdges , FieldType = 'POINT' , InsideOut = 0 ) # create a new 'Extract Selection' selectedVertex = ExtractSelection ( Input = alignmentEdges ) # create a new 'TTK GridLayout' segmentationsGrid = TTKGridLayout ( Input = OutputPort ( ttkMergeandContourTreeFTM , 2 )) segmentationsGrid . ColumnGap = 10.0 segmentationsGrid . RowGap = 10.0 # create a new 'TTK ForEach' ttkForEach = TTKForEach ( Input = segmentationsGrid ) ttkForEach . InputArray = [ 'POINTS' , 'SegmentationId' ] ttkForEach . ImageExtent = [ 0 , 127 , 0 , 255 , 0 , 0 ] # create a new 'Merge Blocks' mergeBlocks = MergeBlocks ( Input = ttkForEach ) # create a new 'TTK ArrayEditor' passSegmentationIDs = TTKArrayEditor ( Target = mergeBlocks , Source = selectedVertex ) passSegmentationIDs . EditorMode = 'Add Arrays from Source' passSegmentationIDs . TargetAttributeType = 'Field Data' passSegmentationIDs . SourcePointDataArrays = [ 'segmentationIDs' ] passSegmentationIDs . TargetArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK Extract' extractMatchedGeometry = TTKExtract ( Input = passSegmentationIDs ) extractMatchedGeometry . ExtractionMode = 'Geometry' extractMatchedGeometry . Expression = ' {segmentationIDs[{_ttk_IterationInfo[0]} ]}' extractMatchedGeometry . ImageExtent = [ 2147483647 , - 2147483647 , 2147483647 , - 2147483647 , 2147483647 , - 2147483647 ] extractMatchedGeometry . InputArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK BlockAggregator' ttkBlockAggregator = TTKBlockAggregator ( Input = extractMatchedGeometry ) # create a new 'TTK EndFor' ttkEndFor = TTKEndFor ( Data = ttkBlockAggregator , For = ttkForEach ) # save the output SaveData ( 'ContourTreeAlignment.vtu' , alignmentEdges ) SaveData ( 'Segmentations.vtm' , segmentationsGrid ) SaveData ( 'MatchedRegions.vtm' , ttkEndFor ) Inputs \u00b6 heatedCylinder/heatedCylinder_2D_raw.cdb : a cinema data base of 23x10 2D scalar fields. Outputs \u00b6 ContorTreeAlignment.vtu : the output alignment in VTK file format (left view, above screenshot). Segmentations.vtm : the segmentations of the input scalar fields in VTK multiblock format (right view, above screenshot). MatchedRegions.vtm : the regions of the original fields that are represented by a selected vertex in VTK multiblock format (right view, ab\u017fove screenshot). C++/Python API \u00b6 CinemaReader CinemaQuery CinemaProductReader TopologicalSimplificationByPersistence ContourTree (FTM) ContourTreeAlignment GridLayout GridLayout ForEach EndFor TTKExtract","title":"Contour Tree Alignment"},{"location":"contourTreeAlignment/#contour-tree-alignment","text":"","title":"Contour Tree Alignment"},{"location":"contourTreeAlignment/#pipeline-description","text":"This example first loads a scalar field ensemble from disk as a cinema data base. The ensemble consists of 23 time-dependent scalar fields with 10 time steps each. The ensemble is then filtered for the 23 scalar fields of one fixed time point and read as a vtkMultiBlockDataSet. Here we use the CinemaReader , CinemaQuery and CinemaProductReader filters. In a pre-processing, the scalar fields are topologically simplified by persistence using the TopologicalSimplificationByPersistence filter. The filter is automatically applied to each member of the MultiBlockDataSet. Then, for each simplified member field, the contour tree is computed using the FTMTree module. The resulting MultiBlock of contour trees is then used as input for the Contour Tree Alignment filter. This alignment is a super tree of all contour trees and can be seen as a representative of the topology of the whole ensemble. Unfortunately, the vtk object representing the alignment does not have any layout information attached. Therefore, we use the PlanarGraphLayout together with a paraview calculator to compute and apply the layout information. We now want to check which features of the original scalar fields have been matched onto each other. Therefore, we use the ExtractSeletion filter to extract one vertex and attach its segmentationIDs array to the multi block data set representing the segmentations of the contour trees. We also use a Grid Layout to render the multi block in a comparable fashion (right view, above screenshot). As a last step, we use the ForEach and EndFor filters to iterate the multi block of segmentations and in each iteration, we extract the region of the scalar field that corresponds to the segmentation id from the selected vertex. The extraction is done using the TTKExtract filter.","title":"Pipeline description"},{"location":"contourTreeAlignment/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/contourTreeAlignment.pvsm","title":"ParaView"},{"location":"contourTreeAlignment/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python from paraview.simple import * # create a new 'TTK CinemaReader' ttkCinemaReader = TTKCinemaReader ( DatabasePath = './heatedCylinder/heatedCylinder_2D_raw.cdb' ) # create a new 'TTK CinemaQuery' ttkCinemaQuery = TTKCinemaQuery ( InputTable = ttkCinemaReader ) ttkCinemaQuery . SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE time=4.2\"\"\" # create a new 'TTK CinemaProductReader' ttkCinemaProductReader = TTKCinemaProductReader ( Input = ttkCinemaQuery ) # create a new 'TTK TopologicalSimplificationByPersistence' ttkTopologicalSimplificationByPersistence = TTKTopologicalSimplificationByPersistence ( Input = ttkCinemaProductReader ) ttkTopologicalSimplificationByPersistence . InputArray = [ 'POINTS' , 'nrrd' ] ttkTopologicalSimplificationByPersistence . PersistenceThreshold = 0.05 # create a new 'TTK Merge and Contour Tree (FTM)' ttkMergeandContourTreeFTM = TTKMergeandContourTreeFTM ( Input = ttkTopologicalSimplificationByPersistence ) ttkMergeandContourTreeFTM . ScalarField = [ 'POINTS' , 'nrrd' ] # create a new 'TTK ContourTreeAlignment' contourTreeAlignment = TTKContourTreeAlignment ( Input = OutputPort ( ttkMergeandContourTreeFTM , 1 ), ExportPath = '' ) contourTreeAlignment . ScalarField = [ 'POINTS' , 'Scalar' ] contourTreeAlignment . Regionsizearray = [ 'CELLS' , 'RegionSize' ] contourTreeAlignment . SegmentationIDarrayforCT = [ 'CELLS' , 'SegmentationId' ] contourTreeAlignment . SegmentIDarrayforsegmentation = [ 'POINTS' , 'Scalar' ] # create a new 'TTK PlanarGraphLayout' alignmentLayout = TTKPlanarGraphLayout ( Input = contourTreeAlignment ) alignmentLayout . SequenceArray = [ 'POINTS' , 'Scalar' ] alignmentLayout . SizeArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . UseBranches = 1 alignmentLayout . BranchArray = [ 'POINTS' , 'BranchIDs' ] alignmentLayout . LevelArray = [ 'POINTS' , 'BranchIDs' ] # create a new 'Calculator' alignmentEdges = Calculator ( Input = alignmentLayout ) alignmentEdges . CoordinateResults = 1 alignmentEdges . Function = 'iHat*Layout_Y+jHat*Scalar*3' # create a query selection QuerySelect ( QueryString = '(id == 16)' , Source = alignmentEdges , FieldType = 'POINT' , InsideOut = 0 ) # create a new 'Extract Selection' selectedVertex = ExtractSelection ( Input = alignmentEdges ) # create a new 'TTK GridLayout' segmentationsGrid = TTKGridLayout ( Input = OutputPort ( ttkMergeandContourTreeFTM , 2 )) segmentationsGrid . ColumnGap = 10.0 segmentationsGrid . RowGap = 10.0 # create a new 'TTK ForEach' ttkForEach = TTKForEach ( Input = segmentationsGrid ) ttkForEach . InputArray = [ 'POINTS' , 'SegmentationId' ] ttkForEach . ImageExtent = [ 0 , 127 , 0 , 255 , 0 , 0 ] # create a new 'Merge Blocks' mergeBlocks = MergeBlocks ( Input = ttkForEach ) # create a new 'TTK ArrayEditor' passSegmentationIDs = TTKArrayEditor ( Target = mergeBlocks , Source = selectedVertex ) passSegmentationIDs . EditorMode = 'Add Arrays from Source' passSegmentationIDs . TargetAttributeType = 'Field Data' passSegmentationIDs . SourcePointDataArrays = [ 'segmentationIDs' ] passSegmentationIDs . TargetArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK Extract' extractMatchedGeometry = TTKExtract ( Input = passSegmentationIDs ) extractMatchedGeometry . ExtractionMode = 'Geometry' extractMatchedGeometry . Expression = ' {segmentationIDs[{_ttk_IterationInfo[0]} ]}' extractMatchedGeometry . ImageExtent = [ 2147483647 , - 2147483647 , 2147483647 , - 2147483647 , 2147483647 , - 2147483647 ] extractMatchedGeometry . InputArray = [ 'POINTS' , 'SegmentationId' ] # create a new 'TTK BlockAggregator' ttkBlockAggregator = TTKBlockAggregator ( Input = extractMatchedGeometry ) # create a new 'TTK EndFor' ttkEndFor = TTKEndFor ( Data = ttkBlockAggregator , For = ttkForEach ) # save the output SaveData ( 'ContourTreeAlignment.vtu' , alignmentEdges ) SaveData ( 'Segmentations.vtm' , segmentationsGrid ) SaveData ( 'MatchedRegions.vtm' , ttkEndFor )","title":"Python code"},{"location":"contourTreeAlignment/#inputs","text":"heatedCylinder/heatedCylinder_2D_raw.cdb : a cinema data base of 23x10 2D scalar fields.","title":"Inputs"},{"location":"contourTreeAlignment/#outputs","text":"ContorTreeAlignment.vtu : the output alignment in VTK file format (left view, above screenshot). Segmentations.vtm : the segmentations of the input scalar fields in VTK multiblock format (right view, above screenshot). MatchedRegions.vtm : the regions of the original fields that are represented by a selected vertex in VTK multiblock format (right view, ab\u017fove screenshot).","title":"Outputs"},{"location":"contourTreeAlignment/#cpython-api","text":"CinemaReader CinemaQuery CinemaProductReader TopologicalSimplificationByPersistence ContourTree (FTM) ContourTreeAlignment GridLayout GridLayout ForEach EndFor TTKExtract","title":"C++/Python API"},{"location":"ctBones/","text":"CT bones \u00b6 Pipeline description \u00b6 This example segments medical image data based on topological persistence. First, the PersistenceDiagram of the data is computed (top right view, above screenshot). Then, only the 5 most persistent maxima are selected, corresponding to the toes of the foot. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification . Next, the Split tree of the simplified data is computed. Finally, the geometry of the bones of the toes is extracted by selecting the regions (in the 3D data) attached to the leaves ( RegionType equals 1) of the Split tree (center view, above screenshot). To get a refined segmentation, change the persistence threshold from 180 down to 150 . Each toe will be subdivided into two segments, precisely along the joints. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/ctBones.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' ctBonesvti = XMLImageDataReader ( FileName = [ 'ctBones.vti' ]) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = ctBonesvti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0 , 9999999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 180.0 , 255.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = ctBonesvti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , 'Scalars_' ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMergeandContourTreeFTM1 , 2 )) threshold3 . Scalars = [ 'POINTS' , 'RegionType' ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] SaveData ( \"CTBonesOutputSegmentation.vtu\" , threshold3 ) Inputs \u00b6 ctBones.vti : a three-dimensional regular grid encoding material density in a medical image (CT scan). Outputs \u00b6 CTBonesOutputSegmentation.vtu : the geometry of the volume of the bones of the toes, as extracted by the analysis pipeline (most persistent super-level set connected components). C++/Python API \u00b6 ContourTree (FTM) PersistenceDiagram TopologicalSimplification","title":"CT bones"},{"location":"ctBones/#ct-bones","text":"","title":"CT bones"},{"location":"ctBones/#pipeline-description","text":"This example segments medical image data based on topological persistence. First, the PersistenceDiagram of the data is computed (top right view, above screenshot). Then, only the 5 most persistent maxima are selected, corresponding to the toes of the foot. Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification . Next, the Split tree of the simplified data is computed. Finally, the geometry of the bones of the toes is extracted by selecting the regions (in the 3D data) attached to the leaves ( RegionType equals 1) of the Split tree (center view, above screenshot). To get a refined segmentation, change the persistence threshold from 180 down to 150 . Each toe will be subdivided into two segments, precisely along the joints.","title":"Pipeline description"},{"location":"ctBones/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/ctBones.pvsm","title":"ParaView"},{"location":"ctBones/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' ctBonesvti = XMLImageDataReader ( FileName = [ 'ctBones.vti' ]) # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = ctBonesvti ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0 , 9999999.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 180.0 , 255.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = ctBonesvti , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Scalars_' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , 'Scalars_' ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMergeandContourTreeFTM1 , 2 )) threshold3 . Scalars = [ 'POINTS' , 'RegionType' ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] SaveData ( \"CTBonesOutputSegmentation.vtu\" , threshold3 )","title":"Python code"},{"location":"ctBones/#inputs","text":"ctBones.vti : a three-dimensional regular grid encoding material density in a medical image (CT scan).","title":"Inputs"},{"location":"ctBones/#outputs","text":"CTBonesOutputSegmentation.vtu : the geometry of the volume of the bones of the toes, as extracted by the analysis pipeline (most persistent super-level set connected components).","title":"Outputs"},{"location":"ctBones/#cpython-api","text":"ContourTree (FTM) PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"dragon/","text":"Dragon \u00b6 Pipeline description \u00b6 This example first loads a triangle mesh from disk. In a pre-processing, the mesh is smoothed and an elevation function is computed on top of it. The elevation function will be considered as the input scalar data in the remainder. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of ScalarFieldCriticalPoints (top left view, above screenshot) and the ContourTree (FTM) (bottom left view, above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/dragon.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' dragonvtu = XMLUnstructuredGridReader ( FileName = [ 'dragon.vtu' ]) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = dragonvtu ) # create a new 'Calculator' elevation = Calculator ( Input = tTKGeometrySmoother1 ) elevation . ResultArrayName = 'Elevation' elevation . Function = 'coordsY' # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = elevation ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = elevation ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'Threshold' pairs = Threshold ( Input = tTKPersistenceDiagram1 ) pairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] pairs . ThresholdRange = [ 0.0 , 1000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = pairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 5.0 , 1000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = elevation , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = tTKTopologicalSimplification1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKContourTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKContourTree1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKContourTree1 . ArcSampling = 30 # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKContourTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 40 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube4 = Tube ( Input = extractSurface4 ) tube4 . NumberofSides = 12 tube4 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKContourTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # save the output SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'CriticalPoints.vtp' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'ContourTreeNodes.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'ContourTreeArcs.vtp' , tube4 ) Inputs \u00b6 dragon.vtu : a two-dimensional triangulation. Outputs \u00b6 PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. CriticalPoints.vtp : the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeNode.vtp : spheres, representing the nodes of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeArcs.vtp : cylinders, representing the arcs of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"Dragon"},{"location":"dragon/#dragon","text":"","title":"Dragon"},{"location":"dragon/#pipeline-description","text":"This example first loads a triangle mesh from disk. In a pre-processing, the mesh is smoothed and an elevation function is computed on top of it. The elevation function will be considered as the input scalar data in the remainder. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of ScalarFieldCriticalPoints (top left view, above screenshot) and the ContourTree (FTM) (bottom left view, above screenshot).","title":"Pipeline description"},{"location":"dragon/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/dragon.pvsm","title":"ParaView"},{"location":"dragon/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' dragonvtu = XMLUnstructuredGridReader ( FileName = [ 'dragon.vtu' ]) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = dragonvtu ) # create a new 'Calculator' elevation = Calculator ( Input = tTKGeometrySmoother1 ) elevation . ResultArrayName = 'Elevation' elevation . Function = 'coordsY' # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = elevation ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = elevation ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'Threshold' pairs = Threshold ( Input = tTKPersistenceDiagram1 ) pairs . Scalars = [ 'CELLS' , 'PairIdentifier' ] pairs . ThresholdRange = [ 0.0 , 1000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = pairs ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 5.0 , 1000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = elevation , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK ScalarFieldCriticalPoints' tTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints ( Input = tTKTopologicalSimplification1 ) tTKScalarFieldCriticalPoints1 . ScalarField = [ 'POINTS' , 'Elevation' ] # create a new 'TTK Merge and Contour Tree (FTM)' tTKContourTree1 = TTKMergeandContourTreeFTM ( Input = tTKTopologicalSimplification1 ) tTKContourTree1 . ScalarField = [ 'POINTS' , 'Elevation' ] tTKContourTree1 . ArcSampling = 30 # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = OutputPort ( tTKContourTree1 , 1 )) tTKGeometrySmoother2 . IterationNumber = 40 # create a new 'Extract Surface' extractSurface4 = ExtractSurface ( Input = tTKGeometrySmoother2 ) # create a new 'Tube' tube4 = Tube ( Input = extractSurface4 ) tube4 . NumberofSides = 12 tube4 . Radius = 0.75 # create a new 'TTK IcospheresFromPoints' tTKIcospheresFromPoints4 = TTKIcospheresFromPoints ( Input = tTKContourTree1 ) tTKIcospheresFromPoints4 . Radius = 2.0 # save the output SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'CriticalPoints.vtp' , tTKScalarFieldCriticalPoints1 ) SaveData ( 'ContourTreeNodes.vtp' , tTKIcospheresFromPoints4 ) SaveData ( 'ContourTreeArcs.vtp' , tube4 )","title":"Python code"},{"location":"dragon/#inputs","text":"dragon.vtu : a two-dimensional triangulation.","title":"Inputs"},{"location":"dragon/#outputs","text":"PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. CriticalPoints.vtp : the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeNode.vtp : spheres, representing the nodes of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. ContourTreeArcs.vtp : cylinders, representing the arcs of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"dragon/#cpython-api","text":"ContourTree (FTM) GeometrySmoother IcospheresFromPoints PersistenceCurve PersistenceDiagram ScalarFieldCriticalPoints TopologicalSimplification","title":"C++/Python API"},{"location":"imageProcessing/","text":"Image Processing \u00b6 Pipeline description \u00b6 This example processes a grayscale image (top left view on the above screenshot) to generate a segmentation. We will construct the segmentation from the image gradient. First, the image is loaded from disk. The gradient is computed with ParaView's ComputeDerivatives or Gradient filters. Since TTK only works on scalar field, a Calculator is used to compute the gradient magnitude. From the gradient magnitude, a simplification step involving PersistenceDiagram (bottom left view) and TopologicalSimplification helps removing the noise in the gradient (top right view). To segment the image, we use the MorseSmaleComplex filter. Since in the input image the objects correspond to low values in the gradient and their edges to high values, we are interested in the DescendingManifold scalar field of the Segmentation output, whose cells represent regions of low scalar field values. The IdentifierRandomizer filter is eventually used in order to color neighbor cells with a distinct color (bottom right view on the above screenshot). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/imageProcessing.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env python from paraview.simple import * naturalImagepng = PNGSeriesReader ( FileNames = [ \"naturalImage.png\" ]) # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = naturalImagepng ) computeDerivatives1 . Scalars = [ \"POINTS\" , \"PNGImage\" ] # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = \"gradient\" calculator1 . Function = \"mag(ScalarGradient)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 59608.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 6.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold , ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold3 . Scalars = [ \"CELLS\" , \"SeparatrixType\" ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 ), ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"DescendingManifold\" ] SaveData ( \"Segmentation.vti\" , tTKIdentifierRandomizer1 ) Inputs \u00b6 naturalImage.png : a grayscale PNG picture. Outputs \u00b6 Segmentation.vti : the image segmentation output. C++/Python API \u00b6 PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"Image Processing"},{"location":"imageProcessing/#image-processing","text":"","title":"Image Processing"},{"location":"imageProcessing/#pipeline-description","text":"This example processes a grayscale image (top left view on the above screenshot) to generate a segmentation. We will construct the segmentation from the image gradient. First, the image is loaded from disk. The gradient is computed with ParaView's ComputeDerivatives or Gradient filters. Since TTK only works on scalar field, a Calculator is used to compute the gradient magnitude. From the gradient magnitude, a simplification step involving PersistenceDiagram (bottom left view) and TopologicalSimplification helps removing the noise in the gradient (top right view). To segment the image, we use the MorseSmaleComplex filter. Since in the input image the objects correspond to low values in the gradient and their edges to high values, we are interested in the DescendingManifold scalar field of the Segmentation output, whose cells represent regions of low scalar field values. The IdentifierRandomizer filter is eventually used in order to color neighbor cells with a distinct color (bottom right view on the above screenshot).","title":"Pipeline description"},{"location":"imageProcessing/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/imageProcessing.pvsm","title":"ParaView"},{"location":"imageProcessing/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env python from paraview.simple import * naturalImagepng = PNGSeriesReader ( FileNames = [ \"naturalImage.png\" ]) # create a new 'Compute Derivatives' computeDerivatives1 = ComputeDerivatives ( Input = naturalImagepng ) computeDerivatives1 . Scalars = [ \"POINTS\" , \"PNGImage\" ] # create a new 'Cell Data to Point Data' cellDatatoPointData1 = CellDatatoPointData ( Input = computeDerivatives1 ) # create a new 'Calculator' calculator1 = Calculator ( Input = cellDatatoPointData1 ) calculator1 . ResultArrayName = \"gradient\" calculator1 . Function = \"mag(ScalarGradient)\" # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = calculator1 ) tTKPersistenceDiagram1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ \"CELLS\" , \"PairIdentifier\" ] threshold1 . ThresholdRange = [ - 0.1 , 59608.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ \"CELLS\" , \"Persistence\" ] persistenceThreshold . ThresholdRange = [ 6.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = calculator1 , Constraints = persistenceThreshold , ) tTKTopologicalSimplification1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ \"POINTS\" , \"gradient\" ] # create a new 'Threshold' threshold3 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold3 . Scalars = [ \"CELLS\" , \"SeparatrixType\" ] threshold3 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 ), ) tTKIdentifierRandomizer1 . ScalarField = [ \"POINTS\" , \"DescendingManifold\" ] SaveData ( \"Segmentation.vti\" , tTKIdentifierRandomizer1 )","title":"Python code"},{"location":"imageProcessing/#inputs","text":"naturalImage.png : a grayscale PNG picture.","title":"Inputs"},{"location":"imageProcessing/#outputs","text":"Segmentation.vti : the image segmentation output.","title":"Outputs"},{"location":"imageProcessing/#cpython-api","text":"PersistenceDiagram TopologicalSimplification MorseSmaleComplex IdentifierRandomizer","title":"C++/Python API"},{"location":"karhunenLoveDigits64Dimensions/","text":"Karhunen-Love Digits 64-Dimensions \u00b6 Pipeline description \u00b6 This example performs a persistence driven clustering of a high-dimensional data set, specifically a collection of 2000 images representing hand written digits . Each image is encoded by its Karhunen-Love coefficients, a 64-dimensional vector. This results in a point cloud of 2000 points (2000 rows), living in 64 dimensions (64 columns). The ground truth classification for each point is provided by the column Field0 (point color in the bottom right view, above screenshot), which indicates the digit represented by the corresponding image. The pipeline starts by using DimensionReduction (with tSNE) to project the data down to 2D. Next, the density of the projected 2D point cloud is estimated with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 10 most persistent density maxima are selected (corresponding to the 10 classes, one per digit, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field. The simplified density field then contains only 10 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/karhunenLoveDigits64Dimensions.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' karhunenLoveDigits64Dimensionscsv = CSVReader ( FileName = [ 'karhunenLoveDigits64Dimensions.csv' ]) karhunenLoveDigits64Dimensionscsv . HaveHeaders = 0 # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = karhunenLoveDigits64Dimensionscsv ) tTKDimensionReduction1 . InputColumns = [ 'Field 1' , 'Field 10' , 'Field 11' , 'Field 12' , 'Field 13' , 'Field 14' , 'Field 15' , 'Field 16' , 'Field 17' , 'Field 18' , 'Field 19' , 'Field 2' , 'Field 20' , 'Field 21' , 'Field 22' , 'Field 23' , 'Field 24' , 'Field 25' , 'Field 26' , 'Field 27' , 'Field 28' , 'Field 29' , 'Field 3' , 'Field 30' , 'Field 31' , 'Field 32' , 'Field 33' , 'Field 34' , 'Field 35' , 'Field 36' , 'Field 37' , 'Field 38' , 'Field 39' , 'Field 4' , 'Field 40' , 'Field 41' , 'Field 42' , 'Field 43' , 'Field 44' , 'Field 45' , 'Field 46' , 'Field 47' , 'Field 48' , 'Field 49' , 'Field 5' , 'Field 50' , 'Field 51' , 'Field 52' , 'Field 53' , 'Field 54' , 'Field 55' , 'Field 56' , 'Field 57' , 'Field 58' , 'Field 59' , 'Field 6' , 'Field 60' , 'Field 61' , 'Field 62' , 'Field 63' , 'Field 64' , 'Field 7' , 'Field 8' , 'Field 9' ] tTKDimensionReduction1 . Method = 't-distributed Stochastic Neighbor Embedding' # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 10.0 , 99999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 )) tTKIdentifierRandomizer1 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = tTKIdentifierRandomizer1 , DestinationMesh = tableToPoints1 ) resampleWithDataset1 . PassPointArrays = 1 SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 ) Inputs \u00b6 karhunenLoveDigits64Dimensions.csv : an input high dimensional point cloud (2000 points in 64 dimensions). Outputs \u00b6 OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column, ground truth: Field0 ) C++/Python API \u00b6 DimensionReduction Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"Karhunen-Love Digits 64-Dimensions"},{"location":"karhunenLoveDigits64Dimensions/#karhunen-love-digits-64-dimensions","text":"","title":"Karhunen-Love Digits 64-Dimensions"},{"location":"karhunenLoveDigits64Dimensions/#pipeline-description","text":"This example performs a persistence driven clustering of a high-dimensional data set, specifically a collection of 2000 images representing hand written digits . Each image is encoded by its Karhunen-Love coefficients, a 64-dimensional vector. This results in a point cloud of 2000 points (2000 rows), living in 64 dimensions (64 columns). The ground truth classification for each point is provided by the column Field0 (point color in the bottom right view, above screenshot), which indicates the digit represented by the corresponding image. The pipeline starts by using DimensionReduction (with tSNE) to project the data down to 2D. Next, the density of the projected 2D point cloud is estimated with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 10 most persistent density maxima are selected (corresponding to the 10 classes, one per digit, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field. The simplified density field then contains only 10 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter.","title":"Pipeline description"},{"location":"karhunenLoveDigits64Dimensions/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/karhunenLoveDigits64Dimensions.pvsm","title":"ParaView"},{"location":"karhunenLoveDigits64Dimensions/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' karhunenLoveDigits64Dimensionscsv = CSVReader ( FileName = [ 'karhunenLoveDigits64Dimensions.csv' ]) karhunenLoveDigits64Dimensionscsv . HaveHeaders = 0 # create a new 'TTK DimensionReduction' tTKDimensionReduction1 = TTKDimensionReduction ( Input = karhunenLoveDigits64Dimensionscsv ) tTKDimensionReduction1 . InputColumns = [ 'Field 1' , 'Field 10' , 'Field 11' , 'Field 12' , 'Field 13' , 'Field 14' , 'Field 15' , 'Field 16' , 'Field 17' , 'Field 18' , 'Field 19' , 'Field 2' , 'Field 20' , 'Field 21' , 'Field 22' , 'Field 23' , 'Field 24' , 'Field 25' , 'Field 26' , 'Field 27' , 'Field 28' , 'Field 29' , 'Field 3' , 'Field 30' , 'Field 31' , 'Field 32' , 'Field 33' , 'Field 34' , 'Field 35' , 'Field 36' , 'Field 37' , 'Field 38' , 'Field 39' , 'Field 4' , 'Field 40' , 'Field 41' , 'Field 42' , 'Field 43' , 'Field 44' , 'Field 45' , 'Field 46' , 'Field 47' , 'Field 48' , 'Field 49' , 'Field 5' , 'Field 50' , 'Field 51' , 'Field 52' , 'Field 53' , 'Field 54' , 'Field 55' , 'Field 56' , 'Field 57' , 'Field 58' , 'Field 59' , 'Field 6' , 'Field 60' , 'Field 61' , 'Field 62' , 'Field 63' , 'Field 64' , 'Field 7' , 'Field 8' , 'Field 9' ] tTKDimensionReduction1 . Method = 't-distributed Stochastic Neighbor Embedding' # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction1 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'Persistence' ] threshold1 . ThresholdRange = [ 10.0 , 99999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = threshold1 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK IdentifierRandomizer' tTKIdentifierRandomizer1 = TTKIdentifierRandomizer ( Input = OutputPort ( tTKMorseSmaleComplex1 , 3 )) tTKIdentifierRandomizer1 . ScalarField = [ 'POINTS' , 'AscendingManifold' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = tTKIdentifierRandomizer1 , DestinationMesh = tableToPoints1 ) resampleWithDataset1 . PassPointArrays = 1 SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 )","title":"Python code"},{"location":"karhunenLoveDigits64Dimensions/#inputs","text":"karhunenLoveDigits64Dimensions.csv : an input high dimensional point cloud (2000 points in 64 dimensions).","title":"Inputs"},{"location":"karhunenLoveDigits64Dimensions/#outputs","text":"OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column, ground truth: Field0 )","title":"Outputs"},{"location":"karhunenLoveDigits64Dimensions/#cpython-api","text":"DimensionReduction Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"manifoldCheck/","text":"Manifold Check \u00b6 Pipeline description \u00b6 This example loads three different hexahedral geometry files from disk. In a pre-processing, each geometry is tetrahedralized, which is used as input data. On each of the three geometries, ManifoldCheck is executed. This filters adds link numbers to vertices and cells, which can be used to detect and extract non-manifold vertices (left), edges (middle), and faces (right). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/manifoldChecks.pvsm Python code \u00b6 Non-manifold Vertices \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck0vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck0.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = manifoldCheck0vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck1 = TTKManifoldCheck ( Input = tetrahedralize1 ) # create a new 'Mask Points' maskPoints1 = MaskPoints ( Input = tTKManifoldCheck1 ) maskPoints1 . OnRatio = 1 maskPoints1 . MaximumNumberofPoints = 1000 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' # this extracts non-manifold vertices threshold1 = Threshold ( Input = maskPoints1 ) threshold1 . Scalars = [ 'POINTS' , 'VertexLinkComponentNumber' ] threshold1 . LowerThreshold = 2.0 threshold1 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck0_check.vtu' , tTKManifoldCheck1 ) SaveData ( 'manifoldCheck0_non_manifold.vtu' , threshold1 ) Non-manifold Edges \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck1vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck1.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = manifoldCheck1vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck2 = TTKManifoldCheck ( Input = tetrahedralize2 ) # create a new 'Extract Edges' extractEdges2 = ExtractEdges ( Input = tTKManifoldCheck2 ) # create a new 'Threshold' # this extracts non-manifold edges threshold2 = Threshold ( Input = extractEdges2 ) threshold2 . Scalars = [ 'POINTS' , 'EdgeLinkComponentNumber' ] threshold2 . LowerThreshold = 2.0 threshold2 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck1_check.vtu' , tTKManifoldCheck2 ) SaveData ( 'manifoldCheck1_non_manifold.vtu' , threshold2 ) Non-manifold Faces \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck2vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck2.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize3 = Tetrahedralize ( registrationName = 'Tetrahedralize3' , Input = manifoldCheck2vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck3 = TTKManifoldCheck ( registrationName = 'TTKManifoldCheck3' , Input = tetrahedralize3 ) # create a new 'Threshold' # this extracts tetrahedra that contain non-manifold faces threshold3 = Threshold ( registrationName = 'Threshold3' , Input = tTKManifoldCheck3 ) threshold3 . Scalars = [ 'CELLS' , 'TriangleLinkComponentNumber' ] threshold3 . LowerThreshold = 3.0 threshold3 . UpperThreshold = 3.0 # create a new 'Generate Ids' generateIds1 = GenerateIds ( registrationName = 'GenerateIds1' , Input = threshold3 ) generateIds1 . PointIdsArrayName = 'VertexIdentifiers' generateIds1 . CellIdsArrayName = 'CellIdentifiers' # create a new 'Threshold' # select two of the tetrahedra threshold4 = Threshold ( registrationName = 'Threshold4' , Input = generateIds1 ) threshold4 . Scalars = [ 'CELLS' , 'CellIdentifiers' ] threshold4 . UpperThreshold = 1.0 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( registrationName = 'ExtractSurface2' , Input = threshold4 ) # create a new 'Threshold' # this extracts non-manifold faces threshold5 = Threshold ( registrationName = 'Threshold5' , Input = extractSurface2 ) threshold5 . Scalars = [ 'POINTS' , 'TriangleLinkComponentNumber' ] threshold5 . LowerThreshold = 3.0 threshold5 . UpperThreshold = 3.0 # save the output SaveData ( 'manifoldCheck2_check.vtu' , tTKManifoldCheck3 ) SaveData ( 'manifoldCheck2_non_manifold.vtu' , threshold5 ) Inputs \u00b6 manifoldCheck0.vtu : example mesh with non-manifold vertices manifoldCheck1.vtu : example mesh with non-manifold edges manifoldCheck2.vtu : example mesh with non-manifold faces Outputs \u00b6 manifoldCheck0_check.vtu , manifoldCheck1_check.vtu , manifoldCheck2_check.vtu : tetrhedralized geometry with link numbers manifoldCheck0_non_manifold.vtu : non-manifold vertices in manifoldCheck0.vtu manifoldCheck1_non_manifold.vtu : non-manifold edges in manifoldCheck1.vtu manifoldCheck2_non_manifold.vtu : non-manifold faces in manifoldCheck2.vtu C++/Python API \u00b6 ManifoldCheck","title":"Manifold Check"},{"location":"manifoldCheck/#manifold-check","text":"","title":"Manifold Check"},{"location":"manifoldCheck/#pipeline-description","text":"This example loads three different hexahedral geometry files from disk. In a pre-processing, each geometry is tetrahedralized, which is used as input data. On each of the three geometries, ManifoldCheck is executed. This filters adds link numbers to vertices and cells, which can be used to detect and extract non-manifold vertices (left), edges (middle), and faces (right).","title":"Pipeline description"},{"location":"manifoldCheck/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/manifoldChecks.pvsm","title":"ParaView"},{"location":"manifoldCheck/#python-code","text":"","title":"Python code"},{"location":"manifoldCheck/#non-manifold-vertices","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck0vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck0.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = manifoldCheck0vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck1 = TTKManifoldCheck ( Input = tetrahedralize1 ) # create a new 'Mask Points' maskPoints1 = MaskPoints ( Input = tTKManifoldCheck1 ) maskPoints1 . OnRatio = 1 maskPoints1 . MaximumNumberofPoints = 1000 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' # this extracts non-manifold vertices threshold1 = Threshold ( Input = maskPoints1 ) threshold1 . Scalars = [ 'POINTS' , 'VertexLinkComponentNumber' ] threshold1 . LowerThreshold = 2.0 threshold1 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck0_check.vtu' , tTKManifoldCheck1 ) SaveData ( 'manifoldCheck0_non_manifold.vtu' , threshold1 )","title":"Non-manifold Vertices"},{"location":"manifoldCheck/#non-manifold-edges","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck1vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck1.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = manifoldCheck1vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck2 = TTKManifoldCheck ( Input = tetrahedralize2 ) # create a new 'Extract Edges' extractEdges2 = ExtractEdges ( Input = tTKManifoldCheck2 ) # create a new 'Threshold' # this extracts non-manifold edges threshold2 = Threshold ( Input = extractEdges2 ) threshold2 . Scalars = [ 'POINTS' , 'EdgeLinkComponentNumber' ] threshold2 . LowerThreshold = 2.0 threshold2 . UpperThreshold = 2.0 # save the output SaveData ( 'manifoldCheck1_check.vtu' , tTKManifoldCheck2 ) SaveData ( 'manifoldCheck1_non_manifold.vtu' , threshold2 )","title":"Non-manifold Edges"},{"location":"manifoldCheck/#non-manifold-faces","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Unstructured Grid Reader' manifoldCheck2vtu = XMLUnstructuredGridReader ( FileName = [ 'manifoldCheck2.vtu' ]) # create a new 'Tetrahedralize' tetrahedralize3 = Tetrahedralize ( registrationName = 'Tetrahedralize3' , Input = manifoldCheck2vtu ) # create a new 'TTK ManifoldCheck' tTKManifoldCheck3 = TTKManifoldCheck ( registrationName = 'TTKManifoldCheck3' , Input = tetrahedralize3 ) # create a new 'Threshold' # this extracts tetrahedra that contain non-manifold faces threshold3 = Threshold ( registrationName = 'Threshold3' , Input = tTKManifoldCheck3 ) threshold3 . Scalars = [ 'CELLS' , 'TriangleLinkComponentNumber' ] threshold3 . LowerThreshold = 3.0 threshold3 . UpperThreshold = 3.0 # create a new 'Generate Ids' generateIds1 = GenerateIds ( registrationName = 'GenerateIds1' , Input = threshold3 ) generateIds1 . PointIdsArrayName = 'VertexIdentifiers' generateIds1 . CellIdsArrayName = 'CellIdentifiers' # create a new 'Threshold' # select two of the tetrahedra threshold4 = Threshold ( registrationName = 'Threshold4' , Input = generateIds1 ) threshold4 . Scalars = [ 'CELLS' , 'CellIdentifiers' ] threshold4 . UpperThreshold = 1.0 # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( registrationName = 'ExtractSurface2' , Input = threshold4 ) # create a new 'Threshold' # this extracts non-manifold faces threshold5 = Threshold ( registrationName = 'Threshold5' , Input = extractSurface2 ) threshold5 . Scalars = [ 'POINTS' , 'TriangleLinkComponentNumber' ] threshold5 . LowerThreshold = 3.0 threshold5 . UpperThreshold = 3.0 # save the output SaveData ( 'manifoldCheck2_check.vtu' , tTKManifoldCheck3 ) SaveData ( 'manifoldCheck2_non_manifold.vtu' , threshold5 )","title":"Non-manifold Faces"},{"location":"manifoldCheck/#inputs","text":"manifoldCheck0.vtu : example mesh with non-manifold vertices manifoldCheck1.vtu : example mesh with non-manifold edges manifoldCheck2.vtu : example mesh with non-manifold faces","title":"Inputs"},{"location":"manifoldCheck/#outputs","text":"manifoldCheck0_check.vtu , manifoldCheck1_check.vtu , manifoldCheck2_check.vtu : tetrhedralized geometry with link numbers manifoldCheck0_non_manifold.vtu : non-manifold vertices in manifoldCheck0.vtu manifoldCheck1_non_manifold.vtu : non-manifold edges in manifoldCheck1.vtu manifoldCheck2_non_manifold.vtu : non-manifold faces in manifoldCheck2.vtu","title":"Outputs"},{"location":"manifoldCheck/#cpython-api","text":"ManifoldCheck","title":"C++/Python API"},{"location":"mergeTreeClustering/","text":"Merge Tree Clustering \u00b6 Pipeline description \u00b6 This example first loads an ensemble of scalar fields inside a single file from disk. Then, the FTMTree is computed on each scalar field for the Join Tree and the Split Tree. All these trees are passed to MergeTreeClustering to compute a clustering in the metric space of merge trees. Each input is considered as a tuple consisting of the Join Tree and the Split Tree of the corresponding scalar field. Each centroid is also a tuple of this kind and a distance between two tuples is the distance between their Join Tree plus the distance between their Split Trees. Then, a distance matrix is computed with MergeTreeDistanceMatrix with the input trees and the 3 centroids. This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 2D respecting the most the input distance matrix. In terms of visualisation, the MDS result is visualized and colored by clustering assignment. The split trees centroids are visualized with a planar layout and also some fields of each cluster. In the second layout, the star clustering is visualized, consisting of the input split trees grouped by cluster, with the centroid of the cluster in the middle. The python script computes the MDS and saves the resulting 2D points (for input trees and centroids). ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeClustering.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_JT_group = [] all_ST_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Join Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_JT_group . append ( groupDatasets1 ) # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM2 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM2 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM2 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets2 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM2 , OutputPort ( tTKMergeandContourTreeFTM2 , 1 ), OutputPort ( tTKMergeandContourTreeFTM2 , 2 )]) all_ST_group . append ( groupDatasets2 ) # create a new 'Group Datasets' mt_JT_all = GroupDatasets ( Input = all_JT_group ) # create a new 'Group Datasets' mT_all = GroupDatasets ( Input = all_ST_group ) # create a new 'TTK MergeTreeClustering' tTKMergeTreeClustering1 = TTKMergeTreeClustering ( Input = mT_all , OptionalInputclustering = mt_JT_all ) tTKMergeTreeClustering1 . ComputeBarycenter = 1 tTKMergeTreeClustering1 . NumberOfClusters = 3 tTKMergeTreeClustering1 . Deterministic = 1 tTKMergeTreeClustering1 . DimensionSpacing = 0.1 tTKMergeTreeClustering1 . PersistenceThreshold = 2.0 tTKMergeTreeClustering1 . ImportantPairs = 34.0 tTKMergeTreeClustering1 . MaximumNumberofImportantPairs = 3 tTKMergeTreeClustering1 . MinimumNumberofImportantPairs = 2 tTKMergeTreeClustering1 . ImportantPairsSpacing = 15.0 tTKMergeTreeClustering1 . NonImportantPairsProximity = 0.15 # create a new 'Group Datasets' groupDatasets14 = GroupDatasets ( Input = [ tTKMergeTreeClustering1 , OutputPort ( tTKMergeTreeClustering1 , 1 )]) # create a new 'TTK FlattenMultiBlock' tTKFlattenMultiBlock2 = TTKFlattenMultiBlock ( Input = groupDatasets14 ) # create a new 'TTK MergeTreeDistanceMatrix' tTKMergeTreeDistanceMatrix2 = TTKMergeTreeDistanceMatrix ( Input = tTKFlattenMultiBlock2 ) tTKMergeTreeDistanceMatrix2 . PersistenceThreshold = 2.0 # create a new 'TTK DimensionReduction' tTKDimensionReduction2 = TTKDimensionReduction ( Input = tTKMergeTreeDistanceMatrix2 , ModulePath = 'default' ) tTKDimensionReduction2 . InputColumns = [ 'Tree00' , 'Tree01' , 'Tree02' , 'Tree03' , 'Tree04' , 'Tree05' , 'Tree06' , 'Tree07' , 'Tree08' , 'Tree09' , 'Tree10' , 'Tree11' , 'Tree12' , 'Tree13' , 'Tree14' ] tTKDimensionReduction2 . InputIsaDistanceMatrix = 1 tTKDimensionReduction2 . UseAllCores = 0 # MDS is unstable in parallel mode # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction2 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Mask Points' (to threshold on points) maskPoints1 = MaskPoints ( Input = tableToPoints1 ) maskPoints1 . OnRatio = 0 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' threshold33 = Threshold ( Input = maskPoints1 ) threshold33 . Scalars = [ 'POINTS' , 'treeID' ] threshold33 . ThresholdRange = [ 0.0 , 11.0 ] # create a new 'Threshold' threshold34 = Threshold ( Input = maskPoints1 ) threshold34 . Scalars = [ 'POINTS' , 'treeID' ] threshold34 . ThresholdRange = [ 12.0 , 14.0 ] # save the output SaveData ( 'MDS_trees.csv' , threshold33 ) SaveData ( 'MDS_centroids.csv' , threshold34 ) Inputs \u00b6 isabel.vti : a three-dimensional regular grid with 12 scalar fields. Outputs \u00b6 MDS_trees.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the input trees. The 'ClusterAssignment' array contains the clustering assignments. MDS_centroids.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the centroids. C++/Python API \u00b6 FTMTree MergeTreeClustering MergeTreeDistanceMatrix DimensionReduction","title":"Merge Tree Clustering"},{"location":"mergeTreeClustering/#merge-tree-clustering","text":"","title":"Merge Tree Clustering"},{"location":"mergeTreeClustering/#pipeline-description","text":"This example first loads an ensemble of scalar fields inside a single file from disk. Then, the FTMTree is computed on each scalar field for the Join Tree and the Split Tree. All these trees are passed to MergeTreeClustering to compute a clustering in the metric space of merge trees. Each input is considered as a tuple consisting of the Join Tree and the Split Tree of the corresponding scalar field. Each centroid is also a tuple of this kind and a distance between two tuples is the distance between their Join Tree plus the distance between their Split Trees. Then, a distance matrix is computed with MergeTreeDistanceMatrix with the input trees and the 3 centroids. This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 2D respecting the most the input distance matrix. In terms of visualisation, the MDS result is visualized and colored by clustering assignment. The split trees centroids are visualized with a planar layout and also some fields of each cluster. In the second layout, the star clustering is visualized, consisting of the input split trees grouped by cluster, with the centroid of the cluster in the middle. The python script computes the MDS and saves the resulting 2D points (for input trees and centroids).","title":"Pipeline description"},{"location":"mergeTreeClustering/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeClustering.pvsm","title":"ParaView"},{"location":"mergeTreeClustering/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_JT_group = [] all_ST_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Join Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_JT_group . append ( groupDatasets1 ) # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM2 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM2 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM2 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets2 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM2 , OutputPort ( tTKMergeandContourTreeFTM2 , 1 ), OutputPort ( tTKMergeandContourTreeFTM2 , 2 )]) all_ST_group . append ( groupDatasets2 ) # create a new 'Group Datasets' mt_JT_all = GroupDatasets ( Input = all_JT_group ) # create a new 'Group Datasets' mT_all = GroupDatasets ( Input = all_ST_group ) # create a new 'TTK MergeTreeClustering' tTKMergeTreeClustering1 = TTKMergeTreeClustering ( Input = mT_all , OptionalInputclustering = mt_JT_all ) tTKMergeTreeClustering1 . ComputeBarycenter = 1 tTKMergeTreeClustering1 . NumberOfClusters = 3 tTKMergeTreeClustering1 . Deterministic = 1 tTKMergeTreeClustering1 . DimensionSpacing = 0.1 tTKMergeTreeClustering1 . PersistenceThreshold = 2.0 tTKMergeTreeClustering1 . ImportantPairs = 34.0 tTKMergeTreeClustering1 . MaximumNumberofImportantPairs = 3 tTKMergeTreeClustering1 . MinimumNumberofImportantPairs = 2 tTKMergeTreeClustering1 . ImportantPairsSpacing = 15.0 tTKMergeTreeClustering1 . NonImportantPairsProximity = 0.15 # create a new 'Group Datasets' groupDatasets14 = GroupDatasets ( Input = [ tTKMergeTreeClustering1 , OutputPort ( tTKMergeTreeClustering1 , 1 )]) # create a new 'TTK FlattenMultiBlock' tTKFlattenMultiBlock2 = TTKFlattenMultiBlock ( Input = groupDatasets14 ) # create a new 'TTK MergeTreeDistanceMatrix' tTKMergeTreeDistanceMatrix2 = TTKMergeTreeDistanceMatrix ( Input = tTKFlattenMultiBlock2 ) tTKMergeTreeDistanceMatrix2 . PersistenceThreshold = 2.0 # create a new 'TTK DimensionReduction' tTKDimensionReduction2 = TTKDimensionReduction ( Input = tTKMergeTreeDistanceMatrix2 , ModulePath = 'default' ) tTKDimensionReduction2 . InputColumns = [ 'Tree00' , 'Tree01' , 'Tree02' , 'Tree03' , 'Tree04' , 'Tree05' , 'Tree06' , 'Tree07' , 'Tree08' , 'Tree09' , 'Tree10' , 'Tree11' , 'Tree12' , 'Tree13' , 'Tree14' ] tTKDimensionReduction2 . InputIsaDistanceMatrix = 1 tTKDimensionReduction2 . UseAllCores = 0 # MDS is unstable in parallel mode # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = tTKDimensionReduction2 ) tableToPoints1 . XColumn = 'Component_0' tableToPoints1 . YColumn = 'Component_1' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Mask Points' (to threshold on points) maskPoints1 = MaskPoints ( Input = tableToPoints1 ) maskPoints1 . OnRatio = 0 maskPoints1 . GenerateVertices = 1 maskPoints1 . SingleVertexPerCell = 1 # create a new 'Threshold' threshold33 = Threshold ( Input = maskPoints1 ) threshold33 . Scalars = [ 'POINTS' , 'treeID' ] threshold33 . ThresholdRange = [ 0.0 , 11.0 ] # create a new 'Threshold' threshold34 = Threshold ( Input = maskPoints1 ) threshold34 . Scalars = [ 'POINTS' , 'treeID' ] threshold34 . ThresholdRange = [ 12.0 , 14.0 ] # save the output SaveData ( 'MDS_trees.csv' , threshold33 ) SaveData ( 'MDS_centroids.csv' , threshold34 )","title":"Python code"},{"location":"mergeTreeClustering/#inputs","text":"isabel.vti : a three-dimensional regular grid with 12 scalar fields.","title":"Inputs"},{"location":"mergeTreeClustering/#outputs","text":"MDS_trees.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the input trees. The 'ClusterAssignment' array contains the clustering assignments. MDS_centroids.vtu : the output points in 2D MDS (MultiDimensional Scaling) corresponding to the centroids.","title":"Outputs"},{"location":"mergeTreeClustering/#cpython-api","text":"FTMTree MergeTreeClustering MergeTreeDistanceMatrix DimensionReduction","title":"C++/Python API"},{"location":"mergeTreeTemporalReduction/","text":"Merge Tree Temporal Reduction \u00b6 Pipeline description \u00b6 This example first loads an ensemble of scalar fields inside a single file from disk. Then, the Split Tree is computed on each scalar field. All these trees are passed to MergeTreeTemporalReductionEncoding to compute a subsampling of a sequence of merge trees. The algorithm greedily removes trees in the sequence that can be accurately reconstructed by the geodesic computation. The remaining trees are called the key frames. In terms of visualisation, the three key frames trees and two reconstructed trees are visualized with a planar layout along with their corresponding scalar fields. The python script saves the information needed to reconstruct the trees removed in the sequence. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeTemporalReduction.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_MT_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_MT_group . append ( groupDatasets1 ) # create a new 'Group Datasets' all_MT = GroupDatasets ( Input = all_MT_group ) # create a new 'TTK MergeTreeTemporalReductionEncoding' tTKMergeTreeTemporalReductionEncoding1 = TTKMergeTreeTemporalReductionEncoding ( Input = all_MT ) tTKMergeTreeTemporalReductionEncoding1 . RemovalPercentage = 75.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon1 = 0.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon2 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon3 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . PersistenceThreshold = 3.0 SaveData ( 'ReductionCoefficients.csv' , OutputPort ( tTKMergeTreeTemporalReductionEncoding1 , 1 )) Inputs \u00b6 isabel.vti : a three-dimensional regular grid with 12 scalar fields. Outputs \u00b6 ReductionCoefficients.csv : a table containing information needed to reconstruct removed trees. For each removed tree we have the id of the two key frames needed to reconstruct it ('Index1' and 'Index2'), along with the interpolation parameter ('Alpha'). C++/Python API \u00b6 FTMTree MergeTreeTemporalReductionEncoding","title":"Merge Tree Temporal Reduction"},{"location":"mergeTreeTemporalReduction/#merge-tree-temporal-reduction","text":"","title":"Merge Tree Temporal Reduction"},{"location":"mergeTreeTemporalReduction/#pipeline-description","text":"This example first loads an ensemble of scalar fields inside a single file from disk. Then, the Split Tree is computed on each scalar field. All these trees are passed to MergeTreeTemporalReductionEncoding to compute a subsampling of a sequence of merge trees. The algorithm greedily removes trees in the sequence that can be accurately reconstructed by the geodesic computation. The remaining trees are called the key frames. In terms of visualisation, the three key frames trees and two reconstructed trees are visualized with a planar layout along with their corresponding scalar fields. The python script saves the information needed to reconstruct the trees removed in the sequence.","title":"Pipeline description"},{"location":"mergeTreeTemporalReduction/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/mergeTreeTemporalReduction.pvsm","title":"ParaView"},{"location":"mergeTreeTemporalReduction/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' isabelvti = XMLImageDataReader ( FileName = [ 'isabel.vti' ]) all_MT_group = [] scalarFields = [ 'velocityMag_02' , 'velocityMag_03' , 'velocityMag_04' , 'velocityMag_05' , 'velocityMag_30' , 'velocityMag_31' , 'velocityMag_32' , 'velocityMag_33' , 'velocityMag_45' , 'velocityMag_46' , 'velocityMag_47' , 'velocityMag_48' ] for scalarField in scalarFields : # create a new 'TTK Merge and Contour Tree (FTM)' tTKMergeandContourTreeFTM1 = TTKMergeandContourTreeFTM ( Input = isabelvti ) tTKMergeandContourTreeFTM1 . ScalarField = [ 'POINTS' , scalarField ] tTKMergeandContourTreeFTM1 . TreeType = 'Split Tree' # create a new 'Group Datasets' groupDatasets1 = GroupDatasets ( Input = [ tTKMergeandContourTreeFTM1 , OutputPort ( tTKMergeandContourTreeFTM1 , 1 ), OutputPort ( tTKMergeandContourTreeFTM1 , 2 )]) all_MT_group . append ( groupDatasets1 ) # create a new 'Group Datasets' all_MT = GroupDatasets ( Input = all_MT_group ) # create a new 'TTK MergeTreeTemporalReductionEncoding' tTKMergeTreeTemporalReductionEncoding1 = TTKMergeTreeTemporalReductionEncoding ( Input = all_MT ) tTKMergeTreeTemporalReductionEncoding1 . RemovalPercentage = 75.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon1 = 0.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon2 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . Epsilon3 = 100.0 tTKMergeTreeTemporalReductionEncoding1 . PersistenceThreshold = 3.0 SaveData ( 'ReductionCoefficients.csv' , OutputPort ( tTKMergeTreeTemporalReductionEncoding1 , 1 ))","title":"Python code"},{"location":"mergeTreeTemporalReduction/#inputs","text":"isabel.vti : a three-dimensional regular grid with 12 scalar fields.","title":"Inputs"},{"location":"mergeTreeTemporalReduction/#outputs","text":"ReductionCoefficients.csv : a table containing information needed to reconstruct removed trees. For each removed tree we have the id of the two key frames needed to reconstruct it ('Index1' and 'Index2'), along with the interpolation parameter ('Alpha').","title":"Outputs"},{"location":"mergeTreeTemporalReduction/#cpython-api","text":"FTMTree MergeTreeTemporalReductionEncoding","title":"C++/Python API"},{"location":"morseMolecule/","text":"Morse molecule \u00b6 Pipeline description \u00b6 This example first loads a VTI file on the disk. The VTI file contains three scalar fields namely Rho , log(Rho) , and log(s) . We are interested in topological analysis of the log(Rho) scalar field which corresponds to the electron density distribution around a simple molecule. The MorseSmaleComplex is computed for this scalar field. The reason for computing Morse-Smale complex is that many chemically relevant concepts, for example, covalent bonds can be directly translated to topological structures computed using the Morse-Smale complex. The critical points of this scalar field also have chemical relevance. The maxima correspond to the atom locations and 2-saddles occur along chemical bonds. Then the critical points are then converted into spheres using IcospheresFromPoints . The maxima are selected and highlighted as bigger spheres. Then using appropriate filtering, the 1-separatrices corresponding to the covalent bonds are selected. The criteria used is to select the 1-sepatrices which have no critical points on the boundary and for which SeparatrixType = 2 , that is they connect a 2-saddle to a maximum. Also, GeometrySmoother is used to make the jagged lines generated by the Morse-Smale complex a little smoother. Then, another type of 1-separatrix is extracted which connects a 2-saddle on a covalent bond to its neighbouring 1-saddles on the boundary. Lastly, 2-separatrices incident on the covalent bonds (of SeparatrixType = 1 ) are extracted which correspond to separating walls between adjacent atoms. Another type ( SeparatrixType = 2 ) of separating wall is also extracted. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseMolecule.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = builtInExamplevti ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . Descending2Separatrices = 1 # Generate spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints1 . Radius = 1.5 # Generate bigger spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 3.0 # Then select critical points of CellDimension 3 using 'Threshold' to select maxima threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ 'POINTS' , 'CellDimension' ] threshold3 . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Threshold' threshold1 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold1 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold1 . ThresholdRange = [ 0.0 , 0.0 ] # create a new 'Threshold' threshold2 = Threshold ( Input = threshold1 ) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold2 ) tTKGeometrySmoother1 . IterationNumber = 50 # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = tTKGeometrySmoother1 ) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = cleantoGrid1 ) # create a new 'Tube' tube1 = Tube ( Input = extractSurface1 ) tube1 . Scalars = [ 'POINTS' , 'CellDimension' ] tube1 . Radius = 1.25 # create a new 'Threshold' threshold8 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold8 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold8 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold9 = Threshold ( Input = threshold8 ) threshold9 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold9 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold11 = Threshold ( Input = threshold9 ) threshold11 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold11 . ThresholdRange = [ 75.0 , 76.0 ] # create a new 'Threshold' threshold10 = Threshold ( Input = threshold9 ) threshold10 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold10 . ThresholdRange = [ 73.0 , 74.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ threshold10 , threshold11 ]) # create a new 'Clean to Grid' cleantoGrid4 = CleantoGrid ( Input = appendDatasets1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother4 = TTKGeometrySmoother ( Input = cleantoGrid4 ) tTKGeometrySmoother4 . IterationNumber = 10 # create a new 'Extract Surface' extractSurface3 = ExtractSurface ( Input = tTKGeometrySmoother4 ) # create a new 'Tube' tube2 = Tube ( Input = extractSurface3 ) tube2 . Scalars = [ 'POINTS' , 'CellDimension' ] tube2 . Radius = 0.75 # create a new 'Threshold' threshold4 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold4 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold4 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Clean to Grid' cleantoGrid2 = CleantoGrid ( Input = threshold4 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid2 ) # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tetrahedralize1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = extractSurface2 ) tTKGeometrySmoother2 . IterationNumber = 20 # select 2-separatrices using 'Threshold' threshold5 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold5 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold5 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' threshold6 = Threshold ( Input = threshold5 ) threshold6 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold6 . ThresholdRange = [ 4.0 , 4.0 ] # select a particular 2-separatrix using 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold7 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Clean to Grid' cleantoGrid3 = CleantoGrid ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = cleantoGrid3 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize2 ) tTKGeometrySmoother3 . IterationNumber = 20 # save the output SaveData ( 'CriticalPoints.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'Maxima.vtu' , threshold3 ) SaveData ( 'CovalentBonds.vtp' , tube1 ) SaveData ( 'Selected2saddle1saddleConnectors.vtp' , tube2 ) SaveData ( 'CovalentBondSeparatrixWalls.vtp' , tTKGeometrySmoother2 ) SaveData ( 'SelectedType2SeparatrixWall.vtu' , tTKGeometrySmoother3 ) Inputs \u00b6 BuiltInExample2.vti : 3D scalar field corresponding to electron density distribution around a simple molecule. Outputs \u00b6 CriticalPoints.vtp : All the output critical points in VTK file format (small spheres in the above screenshot). Maxima.vtu : The computed maxima which also correspond to atom locations in VTK file format (bigger green spheres). CovalentBonds.vtp : Selected 1-separatrices corresponding to the covalent bonds in the molecule (the thick white tubes) Selected2saddle1saddleConnectors.vtp : Geometry of selected separatrices connecting a 2-saddle on a covalent bond to its neighbouring 1-saddles (the dark grey tubes in the screenshot above). CovalentBondSeparatrixWalls.vtp : Surface corresponding to 2-separatrices (walls) incident on the covalent bonds (the translucent blue surfaces in the above screenshot) SelectedType2SeparatrixWall.vtu : Surface corresponding to another type of wall (the green surface). Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 MorseSmaleComplex GeometrySmoother IcospheresFromPoints","title":"Morse molecule"},{"location":"morseMolecule/#morse-molecule","text":"","title":"Morse molecule"},{"location":"morseMolecule/#pipeline-description","text":"This example first loads a VTI file on the disk. The VTI file contains three scalar fields namely Rho , log(Rho) , and log(s) . We are interested in topological analysis of the log(Rho) scalar field which corresponds to the electron density distribution around a simple molecule. The MorseSmaleComplex is computed for this scalar field. The reason for computing Morse-Smale complex is that many chemically relevant concepts, for example, covalent bonds can be directly translated to topological structures computed using the Morse-Smale complex. The critical points of this scalar field also have chemical relevance. The maxima correspond to the atom locations and 2-saddles occur along chemical bonds. Then the critical points are then converted into spheres using IcospheresFromPoints . The maxima are selected and highlighted as bigger spheres. Then using appropriate filtering, the 1-separatrices corresponding to the covalent bonds are selected. The criteria used is to select the 1-sepatrices which have no critical points on the boundary and for which SeparatrixType = 2 , that is they connect a 2-saddle to a maximum. Also, GeometrySmoother is used to make the jagged lines generated by the Morse-Smale complex a little smoother. Then, another type of 1-separatrix is extracted which connects a 2-saddle on a covalent bond to its neighbouring 1-saddles on the boundary. Lastly, 2-separatrices incident on the covalent bonds (of SeparatrixType = 1 ) are extracted which correspond to separating walls between adjacent atoms. Another type ( SeparatrixType = 2 ) of separating wall is also extracted.","title":"Pipeline description"},{"location":"morseMolecule/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morseMolecule.pvsm","title":"ParaView"},{"location":"morseMolecule/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 from paraview.simple import * # create a new 'XML Image Data Reader' builtInExamplevti = XMLImageDataReader ( FileName = [ 'BuiltInExample2.vti' ]) # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = builtInExamplevti ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'log(Rho)' ] tTKMorseSmaleComplex1 . Ascending2Separatrices = 1 tTKMorseSmaleComplex1 . Descending2Separatrices = 1 # Generate spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints1 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints1 . Radius = 1.5 # Generate bigger spheres for the critical points using 'TTK IcospheresFromPoints' tTKIcospheresFromPoints2 = TTKIcospheresFromPoints ( Input = tTKMorseSmaleComplex1 ) tTKIcospheresFromPoints2 . Radius = 3.0 # Then select critical points of CellDimension 3 using 'Threshold' to select maxima threshold3 = Threshold ( Input = tTKIcospheresFromPoints2 ) threshold3 . Scalars = [ 'POINTS' , 'CellDimension' ] threshold3 . ThresholdRange = [ 3.0 , 3.0 ] # create a new 'Threshold' threshold1 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold1 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold1 . ThresholdRange = [ 0.0 , 0.0 ] # create a new 'Threshold' threshold2 = Threshold ( Input = threshold1 ) threshold2 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold2 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'TTK GeometrySmoother' tTKGeometrySmoother1 = TTKGeometrySmoother ( Input = threshold2 ) tTKGeometrySmoother1 . IterationNumber = 50 # create a new 'Clean to Grid' cleantoGrid1 = CleantoGrid ( Input = tTKGeometrySmoother1 ) # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = cleantoGrid1 ) # create a new 'Tube' tube1 = Tube ( Input = extractSurface1 ) tube1 . Scalars = [ 'POINTS' , 'CellDimension' ] tube1 . Radius = 1.25 # create a new 'Threshold' threshold8 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 1 )) threshold8 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold8 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold9 = Threshold ( Input = threshold8 ) threshold9 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold9 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Threshold' threshold11 = Threshold ( Input = threshold9 ) threshold11 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold11 . ThresholdRange = [ 75.0 , 76.0 ] # create a new 'Threshold' threshold10 = Threshold ( Input = threshold9 ) threshold10 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold10 . ThresholdRange = [ 73.0 , 74.0 ] # create a new 'Append Datasets' appendDatasets1 = AppendDatasets ( Input = [ threshold10 , threshold11 ]) # create a new 'Clean to Grid' cleantoGrid4 = CleantoGrid ( Input = appendDatasets1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother4 = TTKGeometrySmoother ( Input = cleantoGrid4 ) tTKGeometrySmoother4 . IterationNumber = 10 # create a new 'Extract Surface' extractSurface3 = ExtractSurface ( Input = tTKGeometrySmoother4 ) # create a new 'Tube' tube2 = Tube ( Input = extractSurface3 ) tube2 . Scalars = [ 'POINTS' , 'CellDimension' ] tube2 . Radius = 0.75 # create a new 'Threshold' threshold4 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold4 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold4 . ThresholdRange = [ 1.0 , 1.0 ] # create a new 'Clean to Grid' cleantoGrid2 = CleantoGrid ( Input = threshold4 ) # create a new 'Tetrahedralize' tetrahedralize1 = Tetrahedralize ( Input = cleantoGrid2 ) # create a new 'Extract Surface' extractSurface2 = ExtractSurface ( Input = tetrahedralize1 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother2 = TTKGeometrySmoother ( Input = extractSurface2 ) tTKGeometrySmoother2 . IterationNumber = 20 # select 2-separatrices using 'Threshold' threshold5 = Threshold ( Input = OutputPort ( tTKMorseSmaleComplex1 , 2 )) threshold5 . Scalars = [ 'CELLS' , 'SeparatrixType' ] threshold5 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Threshold' threshold6 = Threshold ( Input = threshold5 ) threshold6 . Scalars = [ 'CELLS' , 'NumberOfCriticalPointsOnBoundary' ] threshold6 . ThresholdRange = [ 4.0 , 4.0 ] # select a particular 2-separatrix using 'Threshold' threshold7 = Threshold ( Input = threshold6 ) threshold7 . Scalars = [ 'CELLS' , 'SeparatrixId' ] threshold7 . ThresholdRange = [ 2.0 , 2.0 ] # create a new 'Clean to Grid' cleantoGrid3 = CleantoGrid ( Input = threshold7 ) # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = cleantoGrid3 ) # create a new 'TTK GeometrySmoother' tTKGeometrySmoother3 = TTKGeometrySmoother ( Input = tetrahedralize2 ) tTKGeometrySmoother3 . IterationNumber = 20 # save the output SaveData ( 'CriticalPoints.vtp' , tTKIcospheresFromPoints1 ) SaveData ( 'Maxima.vtu' , threshold3 ) SaveData ( 'CovalentBonds.vtp' , tube1 ) SaveData ( 'Selected2saddle1saddleConnectors.vtp' , tube2 ) SaveData ( 'CovalentBondSeparatrixWalls.vtp' , tTKGeometrySmoother2 ) SaveData ( 'SelectedType2SeparatrixWall.vtu' , tTKGeometrySmoother3 )","title":"Python code"},{"location":"morseMolecule/#inputs","text":"BuiltInExample2.vti : 3D scalar field corresponding to electron density distribution around a simple molecule.","title":"Inputs"},{"location":"morseMolecule/#outputs","text":"CriticalPoints.vtp : All the output critical points in VTK file format (small spheres in the above screenshot). Maxima.vtu : The computed maxima which also correspond to atom locations in VTK file format (bigger green spheres). CovalentBonds.vtp : Selected 1-separatrices corresponding to the covalent bonds in the molecule (the thick white tubes) Selected2saddle1saddleConnectors.vtp : Geometry of selected separatrices connecting a 2-saddle on a covalent bond to its neighbouring 1-saddles (the dark grey tubes in the screenshot above). CovalentBondSeparatrixWalls.vtp : Surface corresponding to 2-separatrices (walls) incident on the covalent bonds (the translucent blue surfaces in the above screenshot) SelectedType2SeparatrixWall.vtu : Surface corresponding to another type of wall (the green surface). Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"morseMolecule/#cpython-api","text":"MorseSmaleComplex GeometrySmoother IcospheresFromPoints","title":"C++/Python API"},{"location":"morsePersistence/","text":"Morse persistence \u00b6 Pipeline description \u00b6 The first step is to create the data for our example. A plane is created to which we add random scalar values to create noise. The obtained scalar field is smoothed using the ScalarFieldSmoother . A sum of sine as scalar values is also added to create the nine main hills. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (center view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morsePersistence.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 #!/usr/bin/env python from paraview.simple import * # create a new 'Plane' plane1 = Plane () plane1 . XResolution = 300 plane1 . YResolution = 300 # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = plane1 ) # create a new 'Random Attributes' randomAttributes1 = RandomAttributes ( Input = tetrahedralize2 ) randomAttributes1 . DataType = 'Float' randomAttributes1 . ComponentRange = [ 0.0 , 1.0 ] randomAttributes1 . GeneratePointScalars = 1 # create a new 'TTK ScalarFieldSmoother' tTKScalarFieldSmoother1 = TTKScalarFieldSmoother ( Input = randomAttributes1 ) tTKScalarFieldSmoother1 . ScalarField = [ 'POINTS' , 'RandomPointScalars' ] tTKScalarFieldSmoother1 . IterationNumber = 6 # create a new 'Calculator' sine = Calculator ( Input = tTKScalarFieldSmoother1 ) sine . ResultArrayName = 'Sine' sine . Function = 'sin(20*coordsX+1.5)+sin(20*coordsY+1.5)' # create a new 'Calculator' distanceField = Calculator ( Input = sine ) distanceField . ResultArrayName = 'DistanceField' distanceField . Function = '-sqrt(coordsX*coordsX+coordsY*coordsY)' # create a new 'Calculator' calculator1 = Calculator ( Input = distanceField ) calculator1 . ResultArrayName = 'Blend' calculator1 . Function = 'Sine+5*DistanceField+5*RandomPointScalars' # create a new 'Extract Surface' extractSurface6 = ExtractSurface ( Input = calculator1 ) # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = extractSurface6 ) warpByScalar1 . Scalars = [ 'POINTS' , 'Blend' ] warpByScalar1 . ScaleFactor = 0.05 # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = warpByScalar1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = warpByScalar1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0.0 , 100000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.7 , 10000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = warpByScalar1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'Blend' ] # save the ouput SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'MorseComplexeCriticalPoints.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 0 )) SaveData ( 'MorseComplexe1Separatrices.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 1 )) SaveData ( 'MorseComplexeSegmentation.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 3 )) Inputs \u00b6 None Outputs \u00b6 PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. MorseComplexeCriticalPoints.vtp : the output critical points (or 0 dimensional elements) of the Morse Smale Complex in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexe1Separatrices.vtp : cylinders, representing the edges (or 1 dimensional elements) of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexeSegmentation.vtp : surfaces, representing the segmentation of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. C++/Python API \u00b6 ScalarFieldSmoother MorseSmaleComplex PersistenceCurve PersistenceDiagram TopologicalSimplification","title":"Morse persistence"},{"location":"morsePersistence/#morse-persistence","text":"","title":"Morse persistence"},{"location":"morsePersistence/#pipeline-description","text":"The first step is to create the data for our example. A plane is created to which we add random scalar values to create noise. The obtained scalar field is smoothed using the ScalarFieldSmoother . A sum of sine as scalar values is also added to create the nine main hills. Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot). The PersistenceCurve is also computed (top right view in the above screenshot). The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. This simplified data is then used as the input of the computation of MorseSmaleComplex (center view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces.","title":"Pipeline description"},{"location":"morsePersistence/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/morsePersistence.pvsm","title":"ParaView"},{"location":"morsePersistence/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 #!/usr/bin/env python from paraview.simple import * # create a new 'Plane' plane1 = Plane () plane1 . XResolution = 300 plane1 . YResolution = 300 # create a new 'Tetrahedralize' tetrahedralize2 = Tetrahedralize ( Input = plane1 ) # create a new 'Random Attributes' randomAttributes1 = RandomAttributes ( Input = tetrahedralize2 ) randomAttributes1 . DataType = 'Float' randomAttributes1 . ComponentRange = [ 0.0 , 1.0 ] randomAttributes1 . GeneratePointScalars = 1 # create a new 'TTK ScalarFieldSmoother' tTKScalarFieldSmoother1 = TTKScalarFieldSmoother ( Input = randomAttributes1 ) tTKScalarFieldSmoother1 . ScalarField = [ 'POINTS' , 'RandomPointScalars' ] tTKScalarFieldSmoother1 . IterationNumber = 6 # create a new 'Calculator' sine = Calculator ( Input = tTKScalarFieldSmoother1 ) sine . ResultArrayName = 'Sine' sine . Function = 'sin(20*coordsX+1.5)+sin(20*coordsY+1.5)' # create a new 'Calculator' distanceField = Calculator ( Input = sine ) distanceField . ResultArrayName = 'DistanceField' distanceField . Function = '-sqrt(coordsX*coordsX+coordsY*coordsY)' # create a new 'Calculator' calculator1 = Calculator ( Input = distanceField ) calculator1 . ResultArrayName = 'Blend' calculator1 . Function = 'Sine+5*DistanceField+5*RandomPointScalars' # create a new 'Extract Surface' extractSurface6 = ExtractSurface ( Input = calculator1 ) # create a new 'Warp By Scalar' warpByScalar1 = WarpByScalar ( Input = extractSurface6 ) warpByScalar1 . Scalars = [ 'POINTS' , 'Blend' ] warpByScalar1 . ScaleFactor = 0.05 # create a new 'TTK PersistenceCurve' tTKPersistenceCurve1 = TTKPersistenceCurve ( Input = warpByScalar1 ) tTKPersistenceCurve1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = warpByScalar1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'Threshold' threshold1 = Threshold ( Input = tTKPersistenceDiagram1 ) threshold1 . Scalars = [ 'CELLS' , 'PairIdentifier' ] threshold1 . ThresholdRange = [ 0.0 , 100000.0 ] # create a new 'Threshold' persistenceThreshold = Threshold ( Input = threshold1 ) persistenceThreshold . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold . ThresholdRange = [ 0.7 , 10000.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = warpByScalar1 , Constraints = persistenceThreshold ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'Blend' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'Blend' ] # save the ouput SaveData ( 'PersistenceDiagram.vtu' , tTKPersistenceDiagram1 ) SaveData ( 'PersistenceCurve.csv' , OutputPort ( tTKPersistenceCurve1 , 3 )) SaveData ( 'MorseComplexeCriticalPoints.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 0 )) SaveData ( 'MorseComplexe1Separatrices.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 1 )) SaveData ( 'MorseComplexeSegmentation.vtp' , OutputPort ( tTKMorseSmaleComplex1 , 3 ))","title":"Python code"},{"location":"morsePersistence/#inputs","text":"None","title":"Inputs"},{"location":"morsePersistence/#outputs","text":"PersistenceDiagram.vtu : the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the vtu file extension to that of any other supported file format (e.g. csv ) in the above python script. PersistenceCurve.csv : the output persistence curve. MorseComplexeCriticalPoints.vtp : the output critical points (or 0 dimensional elements) of the Morse Smale Complex in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexe1Separatrices.vtp : cylinders, representing the edges (or 1 dimensional elements) of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script. MorseComplexeSegmentation.vtp : surfaces, representing the segmentation of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the vtp file extension to that of any other supported file format (e.g. csv ) in the above python script.","title":"Outputs"},{"location":"morsePersistence/#cpython-api","text":"ScalarFieldSmoother MorseSmaleComplex PersistenceCurve PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"persistenceClustering0/","text":"Persistence Clustering 0 \u00b6 Pipeline description \u00b6 This example performs a persistence driven clustering of a 2D toy data set, taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline to a real-life, high-dimensional, data set. The pipeline starts by estimating the density of the input point cloud with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 2 most persistent density maxima are selected (corresponding to the desired 2 output clusters, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field (top right view, above screenshot). The simplified density field then contains only 2 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering0.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = tTKPersistenceDiagram1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) resampleWithDataset1 . CellLocator = 'Static Cell Locator' SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 ) Inputs \u00b6 clustering0.csv : a 2D point cloud taken from the scikit-learn examples . Outputs \u00b6 OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column) C++/Python API \u00b6 Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"Persistence Clustering 0"},{"location":"persistenceClustering0/#persistence-clustering-0","text":"","title":"Persistence Clustering 0"},{"location":"persistenceClustering0/#pipeline-description","text":"This example performs a persistence driven clustering of a 2D toy data set, taken from the scikit-learn examples . Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline to a real-life, high-dimensional, data set. The pipeline starts by estimating the density of the input point cloud with a Gaussian kernel, by the GaussianResampling filter, coupled with the Slice filter (to restrict the estimation to a 2D plane). Next, the PersistenceDiagram of the density field is computed and only the 2 most persistent density maxima are selected (corresponding to the desired 2 output clusters, bottom left view in the above screenshot). Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field (top right view, above screenshot). The simplified density field then contains only 2 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). Finally, the cluster identifier of each input point is given by the identifier of the corresponding ascending manifold of the Morse-Smale complex ( AscendingManifold ), with the ResampleWithDataset filter.","title":"Pipeline description"},{"location":"persistenceClustering0/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/persistenceClustering0.pvsm","title":"ParaView"},{"location":"persistenceClustering0/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python from paraview.simple import * # create a new 'CSV Reader' clustering0csv = CSVReader ( FileName = [ 'clustering0.csv' ]) # create a new 'Table To Points' tableToPoints1 = TableToPoints ( Input = clustering0csv ) tableToPoints1 . XColumn = 'X' tableToPoints1 . YColumn = 'Y' tableToPoints1 . a2DPoints = 1 tableToPoints1 . KeepAllDataArrays = 1 # create a new 'Gaussian Resampling' gaussianResampling1 = GaussianResampling ( Input = tableToPoints1 ) gaussianResampling1 . ResampleField = [ 'POINTS' , 'ignore arrays' ] gaussianResampling1 . ResamplingGrid = [ 256 , 256 , 3 ] gaussianResampling1 . SplatAccumulationMode = 'Sum' # create a new 'Slice' slice1 = Slice ( Input = gaussianResampling1 ) slice1 . SliceType = 'Plane' # init the 'Plane' selected for 'SliceType' slice1 . SliceType . Normal = [ 0.0 , 0.0 , 1.0 ] # create a new 'TTK PersistenceDiagram' tTKPersistenceDiagram1 = TTKPersistenceDiagram ( Input = slice1 ) tTKPersistenceDiagram1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Threshold' persistenceThreshold0 = Threshold ( Input = tTKPersistenceDiagram1 ) persistenceThreshold0 . Scalars = [ 'CELLS' , 'Persistence' ] persistenceThreshold0 . ThresholdRange = [ 10.0 , 9999.0 ] # create a new 'TTK TopologicalSimplification' tTKTopologicalSimplification1 = TTKTopologicalSimplification ( Domain = slice1 , Constraints = persistenceThreshold0 ) tTKTopologicalSimplification1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'TTK MorseSmaleComplex' tTKMorseSmaleComplex1 = TTKMorseSmaleComplex ( Input = tTKTopologicalSimplification1 ) tTKMorseSmaleComplex1 . ScalarField = [ 'POINTS' , 'SplatterValues' ] # create a new 'Resample With Dataset' resampleWithDataset1 = ResampleWithDataset ( SourceDataArrays = OutputPort ( tTKMorseSmaleComplex1 , 3 ), DestinationMesh = tableToPoints1 ) resampleWithDataset1 . CellLocator = 'Static Cell Locator' SaveData ( \"OutputClustering.csv\" , resampleWithDataset1 )","title":"Python code"},{"location":"persistenceClustering0/#inputs","text":"clustering0.csv : a 2D point cloud taken from the scikit-learn examples .","title":"Inputs"},{"location":"persistenceClustering0/#outputs","text":"OutputClustering.csv : the output clustering of the input point cloud (output cluster identifier: AscendingManifold column)","title":"Outputs"},{"location":"persistenceClustering0/#cpython-api","text":"Morse-Smale complex PersistenceDiagram TopologicalSimplification","title":"C++/Python API"},{"location":"timeTracking/","text":"Time Tracking \u00b6 Pipeline description \u00b6 This example loads a 2D time-dependent scalar field, where time steps are stored as a sequence of data arrays. Using TrackingFromFields , a tracking mesh for the temporal evolution of critical points is computed. This filter computes an optimal matching between persistence diagrams (with respect to Wasserstein metric), and discards critical point pairs below a persistence of 1% by default (parameter Tolerance ). The state file further contains an animation of the critical points over time. ParaView \u00b6 To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/timeTracking.pvsm Python code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' timeTrackingvti = XMLImageDataReader ( FileName = [ 'timeTracking.vti' ]) timeTrackingvti . CellArrayStatus = [] # select data arrays 000, 002, 004, ..., 118 timeTrackingvti . PointArrayStatus = [ ' {:0>3} ' . format ( i ) for i in range ( 0 , 120 , 2 )] # create a new 'TTK TrackingFromFields' tTKTrackingFromFields1 = TTKTrackingFromFields ( Input = timeTrackingvti ) tTKTrackingFromFields1 . ForceZtranslation = 1 tTKTrackingFromFields1 . ZTranslation = 0.125 # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tTKTrackingFromFields1 ) # save the output SaveData ( 'timeTracking.vtp' , extractSurface1 ) Inputs \u00b6 timeTracking.vti : time-dependent vorticity of a 2D vortex street, with time steps represented by data arrays '000', '002', ..., '118' Outputs \u00b6 timeTracking.vtp : tracking mesh of critical points C++/Python API \u00b6 TrackingFromFields","title":"Time Tracking"},{"location":"timeTracking/#time-tracking","text":"","title":"Time Tracking"},{"location":"timeTracking/#pipeline-description","text":"This example loads a 2D time-dependent scalar field, where time steps are stored as a sequence of data arrays. Using TrackingFromFields , a tracking mesh for the temporal evolution of critical points is computed. This filter computes an optimal matching between persistence diagrams (with respect to Wasserstein metric), and discards critical point pairs below a persistence of 1% by default (parameter Tolerance ). The state file further contains an animation of the critical points over time.","title":"Pipeline description"},{"location":"timeTracking/#paraview","text":"To reproduce the above screenshot, go to your ttk-data directory and enter the following command: $ paraview states/timeTracking.pvsm","title":"ParaView"},{"location":"timeTracking/#python-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python from paraview.simple import * # create a new 'XML Image Data Reader' timeTrackingvti = XMLImageDataReader ( FileName = [ 'timeTracking.vti' ]) timeTrackingvti . CellArrayStatus = [] # select data arrays 000, 002, 004, ..., 118 timeTrackingvti . PointArrayStatus = [ ' {:0>3} ' . format ( i ) for i in range ( 0 , 120 , 2 )] # create a new 'TTK TrackingFromFields' tTKTrackingFromFields1 = TTKTrackingFromFields ( Input = timeTrackingvti ) tTKTrackingFromFields1 . ForceZtranslation = 1 tTKTrackingFromFields1 . ZTranslation = 0.125 # create a new 'Extract Surface' extractSurface1 = ExtractSurface ( Input = tTKTrackingFromFields1 ) # save the output SaveData ( 'timeTracking.vtp' , extractSurface1 )","title":"Python code"},{"location":"timeTracking/#inputs","text":"timeTracking.vti : time-dependent vorticity of a 2D vortex street, with time steps represented by data arrays '000', '002', ..., '118'","title":"Inputs"},{"location":"timeTracking/#outputs","text":"timeTracking.vtp : tracking mesh of critical points","title":"Outputs"},{"location":"timeTracking/#cpython-api","text":"TrackingFromFields","title":"C++/Python API"}]}