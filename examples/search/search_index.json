{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the TTK Online Example Database!","text":"<p>This website hosts a list of data analysis pipelines exemplifying the usage of TTK with ParaView and its Python API <code>pvpython</code>.</p> <p>This website is targeting novice users who are not power users of ParaView but who would like to get started with topological data analysis with TTK in Python.</p> <p>Each example includes:</p> <ul> <li>a screenshot (or a tutorial video)</li> <li>a short description</li> <li>the command line to reproduce the example with ParaView</li> <li>the corresponding Python code, to:<ul> <li>load the input data </li> <li>execute the analysis pipeline</li> <li>store the output to disk (for later analysis or visualization, e.g. with ParaView)</li> </ul> </li> <li>a description of the inputs and outputs</li> <li>pointers to the corresponding C++/Python documentation</li> </ul> <p>This documentation assumes a default installation of the latest version of TTK (with the <code>pvpython</code> API support enabled) and that the repository ttk-data has been downloaded locally.</p> <p>If you have any questions regarding these examples, please let us know by sending an email to the TTK user mailing list!</p>"},{"location":"#scalar-data","title":"Scalar data","text":"Name Screenshot Dragon Morse persistence Built-in example 1 Interaction site Morse molecule Morse-Smale segmentation AT Tectonic puzzle CT bones Tribute Image processing Persistence driven compression Morse-Smale quadrangulation Persistent Generators Molecule Persistent Generators Cosmic Web"},{"location":"#bivariate-scalar-data","title":"Bivariate scalar data","text":"Name Screenshot Built-in example 2"},{"location":"#uncertain-scalar-data","title":"Uncertain scalar data","text":"Name Screenshot Uncertain starting vortex"},{"location":"#time-varying-scalar-data","title":"Time-varying scalar data","text":"Name Screenshot Time tracking Merge tree temporal reduction Nested tracking graph"},{"location":"#ensemble-scalar-data","title":"Ensemble scalar data","text":"Name Screenshot Persistence diagram distance Persistence diagram clustering Clustering Kelvin Helmoltz Instabilities Persistence diagram Wasserstein Auto-Encoding Merge feature tracking Merge tree clustering Merge tree principal geodesic analysis Merge tree Wasserstein Auto-Encoding Contour tree alignment Persistent Generators Periodic Picture"},{"location":"#high-dimensional-point-cloud-data","title":"High-dimensional / point cloud data","text":"Name Screenshot TopoMap Teaser Persistent Generators Household Analysis Karhunen-Love Digits 64-Dimensions Persistence clustering0 Persistence clustering1 Persistence clustering2 Persistence clustering3 Persistence clustering4 Persistence clustering gallery 1-manifold learning 1-manifold learning circles  2-manifold learning"},{"location":"#in-situ-features","title":"In-situ features","text":"Name Screenshot Geometry approximation"},{"location":"#misc-features","title":"Misc features","text":"Name Screenshot Persistent Generators Casting Persistent Generators Fertility Persistent Generators Skull Manifold checks Cinema IO Compact Triangulation"},{"location":"1manifoldLearning/","title":"1-Manifold Learning","text":""},{"location":"1manifoldLearning/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a point cloud from disk. </p> <p>In a pre-processing, the DimensionReduction is used to reduce the dimension of the input to 2D points. The data is then converted to a format understandable by Paraview using the <code>TableToPoints</code> filter. <code>GaussianResampling</code> is applied to the data (upper left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting <code>SplatterValues</code> field is a density estimation (with a Gaussian kernel) of the point cloud projected in 2D.</p> <p>Then, the PersistenceDiagram of a slice of the obtained data is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram.</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. Only certain maximal edges are displayed here: using thresholds, the edges connecting at least one critical point situated in the boundary are discarded. This way, the \"S\" shape made by the point cloud is outlined.</p>"},{"location":"1manifoldLearning/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/1manifoldLearning.pvsm\n</code></pre></p>"},{"location":"1manifoldLearning/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\npointCloudcsv = CSVReader(FileName=[\"pointCloud.csv\"])\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction1 = TTKDimensionReduction(\n    Input=pointCloudcsv, ModulePath=\"default\"\n)\ntTKDimensionReduction1.InputColumns = [\"Points:0\", \"Points:1\", \"Points:2\"]\ntTKDimensionReduction1.UseAllCores = 0\n\n# create a new 'Table To Points'\ntableToPoints2 = TableToPoints(Input=tTKDimensionReduction1)\ntableToPoints2.XColumn = \"Component_0\"\ntableToPoints2.YColumn = \"Component_1\"\ntableToPoints2.a2DPoints = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling2 = GaussianResampling(Input=tableToPoints2)\ngaussianResampling2.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling2.ResamplingGrid = [128, 64, 3]\ngaussianResampling2.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Python Calculator'\npythonCalculator1 = PythonCalculator(Input=gaussianResampling2)\npythonCalculator1.Expression = 'numpy.round_(inputs[0].PointData[\"SplatterValues\"], 6)'\npythonCalculator1.ArrayName = \"SplatterValues\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=pythonCalculator1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 3.0\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 1))\nthreshold2.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = 1.0\nthreshold2.UpperThreshold = 1.0\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=threshold2)\nthreshold3.Scalars = [\"CELLS\", \"NumberOfCriticalPointsOnBoundary\"]\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother1 = TTKGeometrySmoother(Input=threshold3)\ntTKGeometrySmoother1.IterationNumber = 100\n\nSaveData(\"OutputArc.vtu\", tTKGeometrySmoother1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/1manifoldLearning.py\n</code></pre></p>"},{"location":"1manifoldLearning/#inputs","title":"Inputs","text":"<ul> <li>pointCloud.csv: a table containing point coordinates.</li> </ul>"},{"location":"1manifoldLearning/#outputs","title":"Outputs","text":"<ul> <li><code>OutputArc.vtu</code>: edges (or 1 dimensional elements) of the output Morse Smale Complex that are not connected to any boundary critical point in VTK file format (right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"1manifoldLearning/#cpython-api","title":"C++/Python API","text":"<p>DimensionReduction</p> <p>GeometrySmoother</p> <p>MorseSmaleComplex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"1manifoldLearningCircles/","title":"1-Manifold Learning Circles","text":""},{"location":"1manifoldLearningCircles/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a point cloud from disk. The points are arranged in mainly two concentric circles, one bigger than the other.</p> <p>In a pre-processing, the data is converted to a format understandable by Paraview using the <code>TableToPoints</code> filter (upper left view, above screenshot). <code>GaussianResampling</code> is applied to the data. This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. Only a slice of the data is kept (upper right, above screenshot). The resulting <code>SplatterValues</code> field is a density estimation (with a Gaussian kernel) of the point cloud in 2D.</p> <p>Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom left view, above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of MorseSmaleComplex (bottom right view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges and dimension 2, which corresponds to its surfaces. The generators of the clusters are edges of the Morse-Smale Complex. Not all edges of the Complex are useful: using thresholds, only the separatrices connected to maxima are kept (<code>Separatrix = 1</code>). Then the edges with the field <code>SeparatrixFunctionMinimum</code> below a certain value (here 2) are also discarded. This corresponds to the two green and yellow generators (bottom right view, above screenshot).</p>"},{"location":"1manifoldLearningCircles/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data  directory and enter the following command: <pre><code>paraview states/1manifoldLearningCircles.pvsm\n</code></pre></p>"},{"location":"1manifoldLearningCircles/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\nclustering0csv = CSVReader(FileName=[\"clustering0.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clustering0csv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = True\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 1))\nthreshold2.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = 1.0\nthreshold2.UpperThreshold = 1.0\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=threshold2)\nthreshold3.Scalars = [\"CELLS\", \"SeparatrixFunctionMinimum\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 2.0\nthreshold3.UpperThreshold = 999999999\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the ouput\nSaveData(\"Clustering.csv\", resampleWithDataset1)\nSaveData(\"Generators.vtu\", threshold3)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/1manifoldLearningCircles.py\n</code></pre></p>"},{"location":"1manifoldLearningCircles/#inputs","title":"Inputs","text":"<ul> <li> <ul> <li>clustering0.csv: a table containing 2D point coordinates arranged in concentric circles.</li> </ul> </li> </ul>"},{"location":"1manifoldLearningCircles/#outputs","title":"Outputs","text":"<ul> <li><code>Clustering.csv</code>: Resampled dataset to store the clustering (field <code>AscendingManifold</code>). You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>Generators.vtu</code>: edges (or 1 dimensional elements) of the output Morse Smale Complex after passing through two thresholds in VTK file format (bottom right view, above screenshot). Only the edges connected to maximam with the field <code>SeparatrixFunctionMinimum</code> below 2 are saved in this file. You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script. </li> </ul>"},{"location":"1manifoldLearningCircles/#cpython-api","title":"C++/Python API","text":"<p>GeometrySmoother</p> <p>MorseSmaleComplex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"2manifoldLearning/","title":"2-Manifold Learning","text":""},{"location":"2manifoldLearning/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a point cloud from disk. </p> <p>In a pre-processing, the data is converted to a format understandable by Paraview using the <code>TableToPoints</code> filter. <code>GaussianResampling</code> is applied to the data (left view in the above screenshot). This filter has the effect of injecting input points to a structured data. For each injection, each point will \"splat\", or distribute values to nearby vertices. The resulting scalar field is a density estimation (with a Gaussian kernel) of the input point cloud.</p> <p>Then, the PersistenceDiagram is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram.</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of MorseSmaleComplex (right view, above screenshot). This complex is composed of elements of 4 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces, and dimension 3, which corresponds to pieces of volume that can be extracted from the <code>Segmentation</code> output. The \"S\" shape made by the point cloud is outlined by the maximal 1 and 2 dimension elements of the Morse-Smale Complex.</p>"},{"location":"2manifoldLearning/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/2manifoldLearning.pvsm\n</code></pre></p>"},{"location":"2manifoldLearning/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\npointCloudcsv = CSVReader(FileName=[\"pointCloud.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=pointCloudcsv)\ntableToPoints1.XColumn = \"Points:0\"\ntableToPoints1.YColumn = \"Points:1\"\ntableToPoints1.ZColumn = \"Points:2\"\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [64, 64, 128]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=gaussianResampling1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 0.01\npersistenceThreshold.UpperThreshold = 999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=gaussianResampling1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKMorseSmaleComplex1.Ascending2Separatrices = 1\ntTKMorseSmaleComplex1.ReturnSaddleConnectors = 1\ntTKMorseSmaleComplex1.SaddleConnectorsPersistenceThreshold = 0.01\ntTKMorseSmaleComplex1.ThresholdIsAbsolute = True\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=OutputPort(tTKMorseSmaleComplex1, 2))\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother2 = TTKGeometrySmoother(Input=tetrahedralize1)\ntTKGeometrySmoother2.IterationNumber = 20\ntTKGeometrySmoother2.InputMaskField = [None, \"\"]\n\n# threshold the output surface\nthreshold5 = Threshold(Input=tTKGeometrySmoother2)\nthreshold5.Scalars = ['CELLS', 'SeparatrixFunctionMinimum']\nthreshold5.LowerThreshold = 0.2\nthreshold5.UpperThreshold = 1\n\nSaveData(\"OutputSurface.vtu\", threshold5)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/2manifoldLearning.py\n</code></pre></p>"},{"location":"2manifoldLearning/#inputs","title":"Inputs","text":"<ul> <li>pointCloud.csv: a table containing point coordinates.</li> </ul>"},{"location":"2manifoldLearning/#outputs","title":"Outputs","text":"<ul> <li><code>OutputSurface.vtu</code>: surface (or 2 dimensional elements) of the output Morse Smale Complex in VTK file format (right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"2manifoldLearning/#cpython-api","title":"C++/Python API","text":"<p>GeometrySmoother</p> <p>MorseSmaleComplex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"BuiltInExample1/","title":"Builtin example 1","text":""},{"location":"BuiltInExample1/#pipeline-description","title":"Pipeline description","text":"<p>This example computes minima, maxima and the persistence diagram for 2D flow data (von Karman vortex street).</p> <p>First, the data is transformed and preprocessed to estimate the vorticity of the flow (via the orthogonal component of the curl). </p> <p>Then, the PersistenceDiagram and PersistenceCurve are computed. To the persistence diagram, a threshold is applied to remove the diagonal. The output are the persistence pairs. These pairs are filtered based on persistence to maintain only the most persistent features.</p> <p>Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification and the 2D domain is embedded into 3D space based on the scalar values.</p> <p>Finally, the Critical Points of the simplified and warped data are computed.</p>"},{"location":"BuiltInExample1/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/BuiltInExample1.pvsm\n</code></pre></p>"},{"location":"BuiltInExample1/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\nbuiltInExamplevti = XMLImageDataReader(FileName=[\"BuiltInExample1.vti\"])\n\n# create a new 'Transform'\ntransform1 = Transform(Input=builtInExamplevti)\ntransform1.Transform = \"Transform\"\n\n# init the 'Transform' selected for 'Transform'\ntransform1.Transform.Rotate = [0.0, 0.0, -90.0]\n\n# create a new 'Compute Derivatives'\ncomputeDerivatives1 = ComputeDerivatives(Input=transform1)\n# computeDerivatives1.Scalars = [None, '']\ncomputeDerivatives1.Vectors = [\"POINTS\", \"Vectors_\"]\ncomputeDerivatives1.OutputVectorType = \"Vorticity\"\n\n# create a new 'Cell Data to Point Data'\ncellDatatoPointData1 = CellDatatoPointData(Input=computeDerivatives1)\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=cellDatatoPointData1)\ncalculator1.ResultArrayName = \"myVorticity\"\ncalculator1.Function = \"Vorticity_Z\"\n\n# create a new 'TTK ScalarFieldNormalizer'\ntTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer(Input=calculator1)\ntTKScalarFieldNormalizer1.ScalarField = [\"POINTS\", \"myVorticity\"]\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=tTKScalarFieldNormalizer1)\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=tetrahedralize1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"myVorticity\"]\ntTKPersistenceDiagram1.IgnoreBoundary = True\n\n# create a new 'Threshold'\npersistencePairs = Threshold(Input=tTKPersistenceDiagram1)\npersistencePairs.Scalars = [\"CELLS\", \"PairIdentifier\"]\npersistencePairs.ThresholdMethod = \"Between\"\npersistencePairs.LowerThreshold = -0.1\npersistencePairs.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=persistencePairs)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 0.02\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK PersistenceCurve'\ntTKPersistenceCurve1 = TTKPersistenceCurve(Input=tTKPersistenceDiagram1)\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=tetrahedralize1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"myVorticity\"]\n\n# create a new 'Warp By Scalar'\nwarpByScalar1 = WarpByScalar(Input=tTKTopologicalSimplification1)\nwarpByScalar1.Scalars = [\"POINTS\", \"myVorticity\"]\nwarpByScalar1.ScaleFactor = 300.0\n\n# create a new 'TTK ScalarFieldCriticalPoints'\ntTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints(Input=warpByScalar1)\ntTKScalarFieldCriticalPoints1.ScalarField = [\"POINTS\", \"myVorticity\"]\n\n# save the output\nSaveData(\"warpedInput.vtu\", warpByScalar1)\nSaveData(\"CriticalPoints.csv\", tTKScalarFieldCriticalPoints1)\nSaveData(\"PersistenceDiagram.vtu\", tTKPersistenceDiagram1)\nSaveData(\"PersistenceCurve.csv\", OutputPort(tTKPersistenceCurve1, 3))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/BuiltInExample1.py\n</code></pre></p>"},{"location":"BuiltInExample1/#inputs","title":"Inputs","text":"<ul> <li>BuiltInExample1.vti: a two-dimensional regular grid encoding flow magnitude of a K\u00e1rm\u00e1n vortex street.</li> </ul>"},{"location":"BuiltInExample1/#outputs","title":"Outputs","text":"<ul> <li><code>warpedInput.vtu</code>: the warped and tetrahedralized scalar field in VTK file format (middle view, above screenshot).</li> <li><code>CriticalPoints.csv</code>: the critical points of the warped scalar field in csv format (middle view, above screenshot).</li> <li><code>PersistenceCurve.csv</code>: the output persistence curve (top right view, above screenshot).</li> <li><code>PersistenceDiagram.vtu</code>: the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"BuiltInExample1/#cpython-api","title":"C++/Python API","text":"<p>PersistenceCurve</p> <p>PersistenceDiagram</p> <p>ScalarFieldCriticalPoints</p> <p>ScalarFieldSmoother</p> <p>TopologicalSimplification</p>"},{"location":"builtInExample2/","title":"Builtin example 2","text":""},{"location":"builtInExample2/#pipeline-description","title":"Pipeline description","text":"<p>This example demostrates how bivariate analysis can be used for the analysis of molecular data. The input to this pipeline are two scalar fields: the electron density field denoted as <code>log(Rho)</code> and the reduced density gradeint denoted by <code>log(s)</code> for a simple molecule called 1,2-ethanediol.</p> <p>First, usual univariate scalar field analysis method is used for the analysis. An isosurafce is extracted in <code>log(Rho)</code> field which helps in identification of the location of atoms in the molecule, see black surfaces in the lower left panel of the screenshot above. Similarly, an isosurafce in <code>log(s)</code> identifies the covalent bonds.</p> <p>Next we perform bivariate analysis which looks at the joint behaviour <code>log(Rho)</code> and <code>log(s)</code> rather than looking at these scalar fields individually. We first compute the ContinuousScatterPlot for this bivariate data. This is shown in the top panel of the screenshot above. We then project the isosrfaces extrated earlier during univariate analysis in the range space using ProjectionFromField. As expected these isosurfaces project to two line segments which are perpendicular to each other and parallel to the X axis and Y axis, repectively.</p> <p>Note how the continuous scatter plot spreads largely diagonally down from top-left corner to bottom-right in the range space with four distinct protrusions coming out on the top and bottom. These protrusions are of interest. We manually select polylines in the range space at these four protrusions and use them for extraction of fiber surfaces using FiberSurface. </p> <p>Two of the fiber surfaces correspond to the atoms in the molecule, one of which identifies the Oxygen atoms (red surfaces in bottom right panel of the screenshot) while the other surface identifies the Carbon atoms (grey surfaces in bottom right panel of the screenshot). The other two fiber surfaces identify the bonds or interaction sites in the molecule. One surface clearly identifies the covalent bonds (blue surfaces in bottom right panel of the screenshot), while the other identifies a non-covalent interaction site in the molecule (light green surface in bottom right panel of the screenshot). Note that using univariate analysis of the data it is not straightforward to distinguish between different type of atoms and different types of bonds. However, it is much easier to do so using bivariate data analysis.</p> <p>Lastly, we also compute the JacobiSet for the bivariate data and project it in the range space. Notice how it aligns with the continuous scatter plot and identifies the boundaries and the distinguishable curves within it.</p>"},{"location":"builtInExample2/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/BuiltInExample2.pvsm\n</code></pre></p>"},{"location":"builtInExample2/#python-code","title":"Python code","text":"<pre><code>#### import the simple module from the paraview\nfrom paraview.simple import *\n\n# Load the scalar fields using 'XML Image Data Reader'\nexample2vti = XMLImageDataReader(FileName=[\"BuiltInExample2.vti\"])\n\n### Univariate data analysis using isosurfaces\n\n# create a new 'Contour' for 'log(Rho)' to identify atoms\ncontour2 = Contour(Input=example2vti)\ncontour2.ContourBy = [\"POINTS\", \"log(Rho)\"]\ncontour2.Isosurfaces = [1.57]\n\n# create a new 'Contour' for 'log(s)' to identify atoms\ncontour3 = Contour(Input=example2vti)\ncontour3.ContourBy = [\"POINTS\", \"log(s)\"]\ncontour3.Isosurfaces = [-0.575]\n\n### Bivariate data analysis using isosurfaces\n\n# create a new 'TTK ContinuousScatterPlot'\ntTKContinuousScatterPlot1 = TTKContinuousScatterPlot(Input=example2vti)\ntTKContinuousScatterPlot1.ScalarField1 = [\"POINTS\", \"log(Rho)\"]\ntTKContinuousScatterPlot1.ScalarField2 = [\"POINTS\", \"log(s)\"]\ntTKContinuousScatterPlot1.UseAllCores = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKContinuousScatterPlot1)\nthreshold1.Scalars = [\"POINTS\", \"ValidPointMask\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'TTK ProjectionFromField' to project the 'log(Rho)' contour onto the range space\ntTKProjectionFromField1 = TTKProjectionFromField(Input=contour2)\ntTKProjectionFromField1.UComponent = [\"POINTS\", \"log(Rho)\"]\ntTKProjectionFromField1.VComponent = [\"POINTS\", \"log(s)\"]\n\n# create a new 'Extract Edges'\nextractEdges1 = ExtractEdges(Input=tTKProjectionFromField1)\n\n# create a new 'TTK ProjectionFromField' to project the 'log(s)' contour onto the range space\ntTKProjectionFromField2 = TTKProjectionFromField(Input=contour3)\ntTKProjectionFromField2.UComponent = [\"POINTS\", \"log(Rho)\"]\ntTKProjectionFromField2.VComponent = [\"POINTS\", \"log(s)\"]\n\n# create a new 'Extract Edges'\nextractEdges2 = ExtractEdges(Input=tTKProjectionFromField2)\n\n# Four manually created polylines in the range space to select regions corresponding to\n# Oxygen and carbon atoms, followed by covalent and non-covalent bonds\nrangePolygonsCoordinates = [\n    [\n        1.89657,\n        -0.278516,\n        0.0,\n        2.06003,\n        -0.24493,\n        0.0,\n        2.15538,\n        -0.278516,\n        0.0,\n        2.21441,\n        -0.416216,\n        0.0,\n    ],\n    [\n        1.3744,\n        0.000242441,\n        0.0,\n        1.51061,\n        -0.00983316,\n        0.0,\n        1.65137,\n        -0.0434185,\n        0.0,\n        1.70586,\n        -0.181118,\n        0.0,\n    ],\n    [\n        1.21547,\n        -0.701691,\n        0.0,\n        1.27904,\n        -0.614369,\n        0.0,\n        1.51061,\n        -0.607652,\n        0.0,\n        1.52878,\n        -1.16853,\n        0.0,\n        1.53786,\n        -0.688257,\n        0.0,\n    ],\n    [\n        -0.310174,\n        -0.325535,\n        0.0,\n        -0.0150337,\n        -0.124023,\n        0.0,\n        0.216538,\n        -0.140816,\n        0.0,\n        0.466272,\n        -0.399423,\n        0.0,\n    ],\n]\n\n# Save the four range space control polygons\npolygons = []\n\n# Save the corresponding four fiber surfaces\nfiberSurfaces = []\n\nfor coords in rangePolygonsCoordinates:\n    # create a new 'Poly Line Source'\n    polyLineSource1 = PolyLineSource()\n    polyLineSource1.Points = coords\n\n    # create a new 'Resample With Dataset'\n    resampleWithDataset1 = ResampleWithDataset(\n        SourceDataArrays=tTKContinuousScatterPlot1, DestinationMesh=polyLineSource1\n    )\n\n    # create a new 'Tetrahedralize'\n    tetrahedralize2 = Tetrahedralize(Input=resampleWithDataset1)\n\n    # create a new 'TTK FiberSurface'\n    tTKFiberSurface1 = TTKFiberSurface(\n        InputDomain=example2vti, RangePolygon=tetrahedralize2\n    )\n    tTKFiberSurface1.DomainUComponent = [\"POINTS\", \"log(Rho)\"]\n    tTKFiberSurface1.DomainVComponent = [\"POINTS\", \"log(s)\"]\n    tTKFiberSurface1.PolygonUComponent = [\"POINTS\", \"log(Rho)\"]\n    tTKFiberSurface1.PolygonVComponent = [\"POINTS\", \"log(s)\"]\n    tTKFiberSurface1.WithPointMerging = 1\n\n    # create a new 'Generate Surface Normals'\n    generateSurfaceNormals1 = GenerateSurfaceNormals(Input=tTKFiberSurface1)\n\n    fiberSurfaces.append(generateSurfaceNormals1)\n\n    # create a new 'Extract Surface'\n    extractSurface1 = ExtractSurface(Input=resampleWithDataset1)\n\n    polygons.append(extractSurface1)\n\n# compute 'TTK JacobiSet' for the bivariate data\ntTKJacobiSet1 = TTKJacobiSet(Input=example2vti)\ntTKJacobiSet1.UComponent = [\"POINTS\", \"log(Rho)\"]\ntTKJacobiSet1.VComponent = [\"POINTS\", \"log(s)\"]\ntTKJacobiSet1.Withedgeidentifiers = 1\ntTKJacobiSet1.Withvertexscalars = 1\n\n# project the Jacobi set onto the range space using 'TTK ProjectionFromField'\ntTKProjectionFromField3 = TTKProjectionFromField(Input=tTKJacobiSet1)\ntTKProjectionFromField3.UComponent = [\"POINTS\", \"log(Rho)\"]\ntTKProjectionFromField3.VComponent = [\"POINTS\", \"log(s)\"]\n\n# save the output\nSaveData(\"logRhoIsosurfaceAtoms.vtp\", contour2)\nSaveData(\"logSIsosurfaceBonds.vtp\", contour3)\n\nSaveData(\"ContinuousScatterPlot.vtu\", threshold1)\nSaveData(\"logRhoIsosurfaceRangeProjection.vtp\", extractEdges1)\nSaveData(\"logSIsosurfaceRangeProjection.vtp\", extractEdges2)\nSaveData(\"OxygenAtomsRangePolygon.vtp\", polygons[0])\nSaveData(\"CarbonAtomsRangePolygon.vtp\", polygons[1])\nSaveData(\"CovalentBondsRangePolygon.vtp\", polygons[2])\nSaveData(\"NonCovalentIntercationSiteRangePolygon.vtp\", polygons[3])\n\nSaveData(\"OxygenAtomsFiberSurface.vtp\", fiberSurfaces[0])\nSaveData(\"CarbonAtomsFiberSurface.vtp\", fiberSurfaces[1])\nSaveData(\"CovalentBondsFiberSurface.vtp\", fiberSurfaces[2])\nSaveData(\"NonCovalentIntercationSiteFiberSurface.vtp\", fiberSurfaces[3])\n\nSaveData(\"JacobiSetRangeProjection.vtu\", tTKProjectionFromField3)\n</code></pre>"},{"location":"builtInExample2/#inputs","title":"Inputs","text":"<ul> <li>BuiltInExample2.vti: Bivariate field corresponding to electron density distribution <code>log(Rho)</code> and the reduced density gradient <code>log(s)</code> around a simple molecule 1,2-ethanediol.</li> </ul>"},{"location":"builtInExample2/#outputs","title":"Outputs","text":""},{"location":"builtInExample2/#univariate-analysis-outputs","title":"Univariate analysis outputs","text":"<ul> <li><code>logRhoIsosurfaceAtoms.vtp</code>: An isosurface extracted from <code>log(Rho)</code> scalar field which identifies the locations of the atoms.</li> <li><code>logSIsosurfaceBonds.vtp</code>: An isosurface extracted from <code>log(s)</code> scalar field which identifies the locations of the bonds or interaction sites.</li> </ul>"},{"location":"builtInExample2/#bivariate-analysis-outputs","title":"Bivariate analysis outputs","text":""},{"location":"builtInExample2/#continuous-scatter-plot-and-projection-of-isocontours","title":"Continuous scatter plot and projection of isocontours","text":"<ul> <li><code>ContinuousScatterPlot.vtu</code>: The continuous scatter plot for the <code>log(Rho)</code> and <code>log(s)</code> bivariate field.</li> <li><code>logRhoIsosurfaceRangeProjection.vtp</code>: The projection of the isosurface extracted from <code>log(Rho)</code> onto the bivariate range space.</li> <li><code>logSIsosurfaceRangeProjection.vtp</code>: The projection of the isosurface extracted from <code>log(s)</code> onto the bivariate range space.</li> </ul>"},{"location":"builtInExample2/#interesting-control-polygons-in-range-space","title":"Interesting control polygons in range space","text":"<ul> <li><code>OxygenAtomsRangePolygon.vtp</code>: Manually specified control polygon in range space to select the two Oxygen atoms in the molecule.</li> <li><code>CarbonAtomsRangePolygon.vtp</code>: Manually specified control polygon to select the Carbon atoms in the molecule.</li> <li><code>CovalentBondsRangePolygon.vtp</code>: Manually specified control polygon to identify the covalent bonds in the molecule.</li> <li><code>NonCovalentIntercationSiteRangePolygon.vtp</code>: Manually specified control polygon to identify the non-covalent interaction sites in the molecule.</li> </ul>"},{"location":"builtInExample2/#corresponding-fiber-surfaces-in-spatial-domain","title":"Corresponding fiber surfaces in spatial domain","text":"<ul> <li><code>OxygenAtomsFiberSurface.vtp</code>: The corresponding fiber surface in the spatial domain for the Oxygen atom control polygon.</li> <li><code>CarbonAtomsFiberSurface.vtp</code>: The corresponding fiber surface in the spatial domain for the Carbon atom control polygon.</li> <li><code>CovalentBondsFiberSurface.vtp</code>: The corresponding fiber surface in the spatial domain for the covalent bonds control polygon.</li> <li><code>NonCovalentIntercationSiteFiberSurface.vtp</code>: The corresponding fiber surface in the spatial domain for the non-covalent bonds control polygon.</li> </ul>"},{"location":"builtInExample2/#jacobi-set-projection-onto-the-continuous-scatter-plot","title":"Jacobi set projection onto the continuous scatter plot","text":"<ul> <li><code>JacobiSetRangeProjection.vtu</code>: The projection of the Jacobi set of the bivariate field onto the bivariate range space.</li> </ul> <p>Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</p>"},{"location":"builtInExample2/#cpython-api","title":"C++/Python API","text":"<p>ContinuousScatterPlot</p> <p>FiberSurface</p> <p>JacobiSet</p> <p>ProjectionFromField</p>"},{"location":"cinemaIO/","title":"CinemaIO","text":""},{"location":"cinemaIO/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a cinema database of a simulation from disk, consisting of three dimensional image files, using the CinemaReader. This outputs a vtkTable.</p> <p>The database is queried for a selection of images, using CinemaQuery, which supports SQL queries on <code>vtkTables</code> (bottom view shows query result in a spreadsheet view).</p> <p>Each selected entry in the database is read by the CinemaProductReader, which outputs a <code>vtkMultiBlock</code> of the images.</p> <p>The images are sliced with a plane, and each slice is visualized side-by-side using the GridLayout (top view in screenshot).</p> <p>ForEach is used to loop through all slices, and then the ArrayEditor is used to add a FieldData value to each slice. In this case, we add the interval  <code>SampleInterval</code> between each queried entry. Each slice is then written to a new cinema database with the CinemaWriter. Finally, the for-loop is terminated using EndFor.</p>"},{"location":"cinemaIO/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/cinemaIO.pvsm\n</code></pre></p>"},{"location":"cinemaIO/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\nviscousFingerscdb = TTKCinemaReader(DatabasePath=\"ViscousFingers.cdb\")\n\n# create a new 'TTK CinemaQuery'\ntTKCinemaQuery1 = TTKCinemaQuery(InputTable=viscousFingerscdb)\ntTKCinemaQuery1.SQLStatement = \"\"\"SELECT * FROM InputTable0\nWHERE Sim='run01' AND Time%10=0\nORDER BY Time\nLIMIT 8 OFFSET 1\"\"\"\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaQuery1)\n\n# create a new 'Slice'\nslice1 = Slice(Input=tTKCinemaProductReader1)\nslice1.SliceType = \"Plane\"\nslice1.HyperTreeGridSlicer = \"Plane\"\nslice1.SliceOffsetValues = [0.0]\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Origin = [31.5, 31.5, 31.5]\n\n# create a new 'TTK GridLayout'\ntTKGridLayout1 = TTKGridLayout(Input=slice1)\ntTKGridLayout1.ColumnAxis = \"Y\"\ntTKGridLayout1.ColumnGap = 8.0\ntTKGridLayout1.RowAxis = \"Z\"\ntTKGridLayout1.NumberofRows = 1\n\n# create a new 'TTK ForEach'\ntTKForEach1 = TTKForEach(Input=tTKGridLayout1)\ntTKForEach1.IterationMode = \"Block\"\ntTKForEach1.InputArray = [\"POINTS\", \"ImageFile\"]\ntTKForEach1.OutputType = \"vtkPolyData\"\n\n# create a new 'TTK ArrayEditor'\ntTKArrayEditor1 = TTKArrayEditor(Target=tTKForEach1, Source=None)\ntTKArrayEditor1.TargetAttributeType = \"Field Data\"\ntTKArrayEditor1.DataString = \"SampleInterval, 10\"\ntTKArrayEditor1.TargetArray = [\"POINTS\", \"ImageFile\"]\n\n# create a new 'TTK CinemaWriter'\ntTKCinemaWriter1 = TTKCinemaWriter(\n    Input=tTKArrayEditor1, DatabasePath=\"ViscousFingersSampled.cdb\"\n)\ntTKCinemaWriter1.ScalarField = [\"POINTS\", \"ImageFile\"]\n\n# create a new 'TTK EndFor'\ntTKEndFor1 = TTKEndFor(Data=tTKCinemaWriter1, For=tTKForEach1)\n\nUpdatePipeline()\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/cinemaIO.py\n</code></pre></p>"},{"location":"cinemaIO/#inputs","title":"Inputs","text":"<ul> <li>ViscousFingers.cdb: a cinema database of VTK Image files from a simulation.</li> </ul>"},{"location":"cinemaIO/#outputs","title":"Outputs","text":"<ul> <li><code>ViscousFingersSampled.cdb</code>: a cinema database containing the sampled slices of the input cinema database.</li> </ul>"},{"location":"cinemaIO/#cpython-api","title":"C++/Python API","text":"<p>ArrayEditor</p> <p>CinemaProductReader</p> <p>CinemaQuery</p> <p>CinemaReader</p> <p>CinemaWriter</p> <p>EndFor</p> <p>ForEach</p> <p>GridLayout</p>"},{"location":"clusteringKelvinHelmholtzInstabilities/","title":"Clustering Kelvin Helmholtz Instabilities","text":""},{"location":"clusteringKelvinHelmholtzInstabilities/#pipeline-description","title":"Pipeline description","text":"<p>This example illustrates the capabilities of  TTK to perform advanced statistical  analysis of collections of datasets, based on their structural representations,  along with the possibility to interactively explore the outcome of the analysis,  with linked views (between the selection in the planar view -- top right -- and  the flow visualization -- top left).</p> <p>This example considers an ensemble of 32 periodic, 2D Kelvin Helmholtz  Instabilities in computational fluid dynamics, obtained with various simulation  parameters (different solvers, different numerical schemes, different  interpolation orders, etc.).  The scalar field of interest is the \"Enstrophy\". It is an established measure  of vorticity. Its prominent maxima denote the center of strong vortices. Two example members from  the ensemble are show on the above screenshot (left). Strong vortices can be  visualized with the dark green regions. The simulation parameters as well as the ground truth classification are  provided as metadata for each entry of the database and are carried along the  entire pipeline. See this publication for  further details.</p> <p>The goal of this example is to classify the 32 members of the ensemble into two  classes, whether they  describe the beginning or the end of  the turbulence. This task is particularly challenging for traditional  clustering pipelines since turbulent flows are highly chaotic and two flows  belonging to the same ground truth class can be drastically different visually  (as shown on the above screenshot -- left). The common denominator between two  turbulent flows in the same ground truth class is the distribution of energies  of their vortices (i.e. the number and strengths of their vortices), which  describes the turbulence of the flow.</p> <p>In this context, topological data representations are particularly relevant to  extract such subtle structural features. In particular, the persistence diagram  involving the saddle-maximum pairs of the \"Enstrophy\" (second column, above  screenshot) nicely captures the number of vortices as well as their individual  strengths. Thus, in the reminder of this example, we will use this persistence  diagram as a descriptor of each turbulent flow and we will proceed to a k-means  clustering directly in the Wasserstein metric space of persistence diagrams.  For visualization purposes, we will compute a 2D layout of the ensemble (right  most columns, above screenshot) to inspect the resulting classification.</p> <p>First, the database of turbulent flows is loaded from disk with the  CinemaReader module (line 6 of the Python script below). Then an SQL  query is performed with  CinemaQuery to select a relevant subset of this database (line 9). Finally the module  CinemaProductReader is used to read the actual regular grids  corresponding to the result of the previous SQL query. From this point on, the  entire set of 32 turbulent flows will be organized as a  vtkMultiBlockDatSet and each of these 32 members will be processed by the rest of the  analysis pipeline.</p> <p>Then for each of the 32 members of the ensemble, the first step consists in  marking periodicity boundary conditions with the  TriangulationManager  (line 21). Next, the \"Enstrophy\" field of  each member is normalized (between 0 and 1) with the  ScalarFieldNormalizer to ease their comparison later. Finally  (line 28) the  PersistenceDiagram is computed (for the saddle-maximum pairs) to  represent each of the 32 ensemble members by a diagram which encodes the number  and the strengths of the vortices via the persistence of the maxima of  \"Enstrophy\".</p> <p>Next, the clustering of the persistence diagrams in the Wasserstein metric  space is performed with the module  PersistenceDiagramClustering (line 32).</p> <p>For visualization purposes, we will then compute a 2D layout of the ensemble,  where each ensemble member will be represented by a point and where the 2D  distance between 2 points will encode the Wasserstein distance between their  diagrams. This will provide an intuitive planar overview of the ensemble. For this, we will first compute a matrix of Wasserstein distances  with the module  PersistenceDiagramDistanceMatrix (line 39). The resulting  distance matrix is visualized at the bottom of the middle column in the above  screenshot. There, it can be seen that the Wasserstein distance already  identifies two major clusters (large blue sub-matrices of low Wasserstein  distances). Next (line 67),  the module  DimensionReduction is used to compute a 2D layout via  multidimensional scaling. Finally, the resulting table is turned into a 2D  point cloud which is ready to be visualized with TableToPoints (line 75). Then, the output is stored to a simple  CSV file (line 81).</p> <p>In the above screenshot, the resulting point cloud is shown in the 2 views at the bottom right corner of the screenshot. The first view (left) shows the  point cloud colored by cluster identifier computed by the pipeline. The second  view (right) show the same point cloud, colored by the ground truth class.  There, one can directly visualize that the two classifications are identical  and that, therefore, this topological clustering pipeline succeeded.</p> <p>For reference, a traditional pipeline based on the L2-distance between the  \"Entrophy\" fields is also provided in this example. For that, the module  LDistanceMatrix is used (line 45) to compute a matrix of the L2  distances between each scalar field of the ensemble.  The resulting distance matrix is visualized at the top of the middle column  in the above screenshot. There, it can be seen that the L2 distance between the  scalar fields fails at identifying any clear clusters (there are no large blue  sub-matrices). Next (line 49), the module  DimensionReduction is used to compute a 2D layout via  multidimensional scaling. The resulting table is turned into a 2D point cloud  with  TableToPoints (line 55). Finally, the k-means algorithm is run on  this 2D point cloud with the module  KMeans. Then, the output is stored to a simple  CSV file (line 83). The resulting clustering can be visualized with the two views at  the top right corner of the above screenshot. The ground-truth classification  is provided by the color coding of the points in the second view (right) while  the classification computed with this traditional pipeline is shown in the  first view (left). There, it can bee seen that the coloring of the two point  clouds differ, indicating an incorrect classification by the traditional kMeans  algorithm. In particular, since all the metadata associated with each ensemble  member travels down the analysis pipeline, one can select points in these  planar views to inspect the corresponding datasets and persistence diagrams  (left two columns of the screenshot). In particular, two members (red and  yellow spheres) incorrectly marked as belonging to different classes are  visualized on the left. There, one can see that although the two flows have the  same \"profile\" of vortices (number and strengths), these are located in  drastically different spots of the field, due to the chaotic nature of  turbulence, hence explaining the reason of failure of traditional  clustering pipelines.</p>"},{"location":"clusteringKelvinHelmholtzInstabilities/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/clusteringKelvinHelmholtzInstabilities.pvsm \n</code></pre></p>"},{"location":"clusteringKelvinHelmholtzInstabilities/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"khi.cdb\")\n\n# create a new 'TTK CinemaQuery'\ntTKCinemaQuery1 = TTKCinemaQuery(InputTable=tTKCinemaReader1)\ntTKCinemaQuery1.SQLStatement = \"\"\"\n    SELECT * FROM InputTable0\n        WHERE Resolution='512' \n            AND (Time='0' OR Time='2') \n            AND (NOT (Solver='hll'))\"\"\"\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaQuery1)\n\n# create a new 'TTK TriangulationManager'\ntTKTriangulationManager1 = TTKTriangulationManager(Input=tTKCinemaProductReader1)\ntTKTriangulationManager1.PeriodicityinAllDimensions = 1\n\n# create a new 'TTK ScalarFieldNormalizer'\ntTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer(Input=tTKTriangulationManager1)\ntTKScalarFieldNormalizer1.ScalarField = [\"POINTS\", \"Enstrophy\"]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=tTKScalarFieldNormalizer1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"Enstrophy\"]\n\n# create a new 'TTK PersistenceDiagramClustering'\ntTKPersistenceDiagramClustering1 = TTKPersistenceDiagramClustering(\n    Input=tTKPersistenceDiagram1\n)\ntTKPersistenceDiagramClustering1.Criticalpairsusedfortheclustering = \"saddle-max pairs\"\ntTKPersistenceDiagramClustering1.Numberofclusters = 2\n\n# create a new 'TTK PersistenceDiagramDistanceMatrix'\ntTKPersistenceDiagramDistanceMatrix1 = TTKPersistenceDiagramDistanceMatrix(\n    Input=tTKPersistenceDiagramClustering1\n)\ntTKPersistenceDiagramDistanceMatrix1.Criticalpairsused = \"saddle-max pairs\"\n\n# create a new 'TTK LDistanceMatrix'\ntTKLDistanceMatrix1 = TTKLDistanceMatrix(Input=tTKCinemaProductReader1)\ntTKLDistanceMatrix1.ScalarField = [\"POINTS\", \"Enstrophy\"]\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction2 = TTKDimensionReduction(Input=tTKLDistanceMatrix1)\ntTKDimensionReduction2.Regexp = \"Dataset.*\"\ntTKDimensionReduction2.SelectFieldswithaRegexp = 1\ntTKDimensionReduction2.InputIsaDistanceMatrix = 1\ntTKDimensionReduction2.UseAllCores = False\n\n# create a new 'Table To Points'\ntableToPoints2 = TableToPoints(Input=tTKDimensionReduction2)\ntableToPoints2.XColumn = \"Component_0\"\ntableToPoints2.YColumn = \"Component_1\"\ntableToPoints2.a2DPoints = 1\ntableToPoints2.KeepAllDataArrays = 1\n\n# create a new 'K Means'\nkMeans1 = KMeans(Input=tableToPoints2)\nkMeans1.VariablesofInterest = [\"Component_0\", \"Component_1\"]\nkMeans1.k = 2\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction1 = TTKDimensionReduction(\n    Input=tTKPersistenceDiagramDistanceMatrix1\n)\ntTKDimensionReduction1.Regexp = \"Diagram.*\"\ntTKDimensionReduction1.SelectFieldswithaRegexp = 1\ntTKDimensionReduction1.InputIsaDistanceMatrix = 1\ntTKDimensionReduction1.UseAllCores = False\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=tTKDimensionReduction1)\ntableToPoints1.XColumn = \"Component_0\"\ntableToPoints1.YColumn = \"Component_1\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\nSaveData(\"W2clusteringAndW2dimensionReduction.csv\", tableToPoints1)\n\nSaveData(\"L2dimensionReductionAndClustering.csv\", OutputPort(kMeans1, 1))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/clusteringKelvinHelmholtzInstabilities.py\n</code></pre></p>"},{"location":"clusteringKelvinHelmholtzInstabilities/#inputs","title":"Inputs","text":"<ul> <li>khi.cdb: a  cinema database containing 32 regular grids describing periodic, 2D Kelvin  Helmholtz Instabilities (computational fluid dynamics).  The scalar field of interest is the \"Enstrophy\" (an established measure of  vorticity). The simulation parameters as well as the ground truth classification (two  classes: beginning or end of the turbulence) are provided as metadata for each  entry of the database and are carried along the entire pipeline. See this publication for further details.</li> </ul>"},{"location":"clusteringKelvinHelmholtzInstabilities/#outputs","title":"Outputs","text":"<ul> <li> <p><code>W2clusteringAndW2dimensionReduction.csv</code>: 2D point cloud representing the  input ensemble (1 line = 1 member of the ensemble). The field <code>ClusterId</code>  denotes the class identifier computed with a k-means clustering (with  k=2) directly performed in the Wasserstein metric space of persistence  diagrams. After that, the 2D layout of the points is computed by  multidimensional scaling of the matrix of Wasserstein distances between  persistence diagrams. With this technique, the output classification perfectly  matches the ground-truth classification.</p> </li> <li> <p><code>L2dimensionReductionAndClustering.csv</code>: 2D point cloud representing the  input ensemble (1 line = 1 member of the ensemble). The field <code>ClosestId(0)</code>  denotes the class identifier computed with a standard k-means clustering (with  k=2) obtained after a 2D projection of the point cloud. In particular,  the 2D layout of the points is computed by multidimensional scaling  of the matrix of L2 distances between the Enstrophy fields. With this  technique, the output classification does not match the ground-truth  classification.</p> </li> </ul>"},{"location":"clusteringKelvinHelmholtzInstabilities/#cpython-api","title":"C++/Python API","text":"<p>CinemaProductReader</p> <p>CinemaQuery</p> <p>CinemaReader</p> <p>DimensionReduction</p> <p>LDistanceMatrix</p> <p>PersistenceDiagram</p> <p>PersistenceDiagramClustering</p> <p>PersistenceDiagramDistanceMatrix</p> <p>ScalarFieldNormalizer</p> <p>TriangulationManager</p>"},{"location":"compactTriangulation/","title":"Compact Triangulation","text":""},{"location":"compactTriangulation/#pipeline-description","title":"Pipeline description","text":"<p>This example demonstrates how to invoke the CompactTriangulation data structure in TTK. </p> <p>The example first loads a triangle mesh from disk. An elevation function along the y-axis is then computed and added on top of the mesh using the <code>Elevation</code> filter.</p> <p>Then, the example uses TriangulationManager to initialize a clustering of the mesh vertices. The clustering information is saved into a new scalar field named <code>ttkCompactTriangulationIndex</code>. The number associated with each vertex by <code>ttkCompactTriangulationIndex</code> represents the cluster index to which the vertex belongs.</p> <p>Once a scalar field named <code>ttkCompactTriangulationIndex</code> is defined on a dataset, any TTK plugin applied to such dataset will be executed using the <code>CompactTriangulation</code> data structure.</p> <p>The example continues applying the ScalarFieldCriticalPoints module on the elevation function previously defined on the input mesh.</p>"},{"location":"compactTriangulation/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/compactTriangulation.pvsm\n</code></pre></p>"},{"location":"compactTriangulation/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\ndragonvtu = XMLUnstructuredGridReader(FileName=[\"dragon.vtu\"])\n\n# create a new 'Elevation'\nelevation1 = Calculator(Input=dragonvtu)\nelevation1.ResultArrayName = \"Elevation\"\nelevation1.Function = \"coordsY\"\n\n# create a new 'TTK TriangulationManager'\ntTKTriangulationManager1 = TTKTriangulationManager(Input=elevation1)\ntTKTriangulationManager1.DataArrays = [\"Elevation\"]\n\n# create a new 'TTK ScalarFieldCriticalPoints'\ntTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints(\n    Input=tTKTriangulationManager1\n)\ntTKScalarFieldCriticalPoints1.ScalarField = [\"POINTS\", \"Elevation\"]\n\n# save the output\nSaveData(\"CompactTriangulation.vtu\", tTKTriangulationManager1)\nSaveData(\"CriticalPoints.vtp\", tTKScalarFieldCriticalPoints1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/compactTriangulation.py\n</code></pre></p>"},{"location":"compactTriangulation/#inputs","title":"Inputs","text":"<ul> <li>dragon.vtu: a two-dimensional triangulation.</li> </ul>"},{"location":"compactTriangulation/#outputs","title":"Outputs","text":"<ul> <li><code>CompactTriangulation.vtu</code>: the input dataset in VTK file format with an additional scalar field named <code>ttkCompactTriangulationIndex</code> that stores the cluster index for each vertex.  </li> <li><code>CriticalPoints.vtp</code>: the output critical points in VTK file format. You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"compactTriangulation/#cpython-api","title":"C++/Python API","text":"<p>CompactTriangulation</p> <p>TriangulationManager</p> <p>Octree</p> <p>ScalarFieldCriticalPoints</p>"},{"location":"contourTreeAlignment/","title":"Contour Tree Alignment","text":""},{"location":"contourTreeAlignment/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a scalar field ensemble from disk as a cinema data base. The ensemble consists of 23 time-dependent scalar fields with 10 time steps each. The ensemble is then filtered for the 23 scalar fields of one fixed time point and read as a vtkMultiBlockDataSet. Here we use the CinemaReader, CinemaQuery and CinemaProductReader filters.</p> <p>In a pre-processing, the scalar fields are topologically simplified by persistence using the TopologicalSimplificationByPersistence filter. The filter is automatically applied to each member of the MultiBlockDataSet. Then, for each simplified member field, the contour tree is computed using the ContourTree module.</p> <p>The resulting MultiBlock of contour trees is then used as input for the Contour Tree Alignment filter. This alignment is a super tree of all contour trees and can be seen as a representative of the topology of the whole ensemble. Unfortunately, the vtk object representing the alignment does not have any layout information attached. Therefore, we use the PlanarGraphLayout together with a paraview calculator to compute and apply the layout information.</p> <p>We now want to check which features of the original scalar fields have been matched onto each other. Therefore, we use the <code>ExtractSeletion</code> filter to extract one vertex and attach its <code>segmentationIDs</code> array to the multi block data set representing the segmentations of the contour trees. We also use a Grid Layout to render the multi block in a comparable fashion (right view, above screenshot).</p> <p>As a last step, we use the ForEach and EndFor filters to iterate the multi block of segmentations and in each iteration, we extract the region of the scalar field that corresponds to the segmentation id from the selected vertex. The extraction is done using the TTKExtract filter.</p>"},{"location":"contourTreeAlignment/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/contourTreeAlignment.pvsm\n</code></pre></p>"},{"location":"contourTreeAlignment/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\nttkCinemaReader = TTKCinemaReader(\n    DatabasePath=\"./heatedCylinder/heatedCylinder_2D_raw.cdb\"\n)\n\n# create a new 'TTK CinemaQuery'\nttkCinemaQuery = TTKCinemaQuery(InputTable=ttkCinemaReader)\nttkCinemaQuery.SQLStatement = \"\"\"SELECT * FROM InputTable0 WHERE time=4.2\"\"\"\n\n# create a new 'TTK CinemaProductReader'\nttkCinemaProductReader = TTKCinemaProductReader(Input=ttkCinemaQuery)\n\n# create a new 'TTK TopologicalSimplificationByPersistence'\nttkTopologicalSimplificationByPersistence = TTKTopologicalSimplificationByPersistence(\n    Input=ttkCinemaProductReader\n)\nttkTopologicalSimplificationByPersistence.InputArray = [\"POINTS\", \"nrrd\"]\nttkTopologicalSimplificationByPersistence.PersistenceThreshold = 0.05\nttkTopologicalSimplificationByPersistence.ThresholdIsAbsolute = True\n\n# create a new 'TTK Merge and Contour Tree ()'\nttkMergeandContourTree = TTKContourTree(\n    Input=ttkTopologicalSimplificationByPersistence\n)\nttkMergeandContourTree.ScalarField = [\"POINTS\", \"nrrd\"]\n\n# create a new 'TTK ContourTreeAlignment'\ncontourTreeAlignment = TTKContourTreeAlignment(\n    Input=OutputPort(ttkMergeandContourTree, 1), ExportPath=\"\"\n)\ncontourTreeAlignment.ScalarField = [\"POINTS\", \"Scalar\"]\ncontourTreeAlignment.Regionsizearray = [\"CELLS\", \"RegionSize\"]\ncontourTreeAlignment.SegmentationIDarrayforCT = [\"CELLS\", \"SegmentationId\"]\ncontourTreeAlignment.SegmentIDarrayforsegmentation = [\"POINTS\", \"Scalar\"]\ncontourTreeAlignment.Seed = 35\n\n# create a new 'TTK PlanarGraphLayout'\nalignmentLayout = TTKPlanarGraphLayout(Input=contourTreeAlignment)\nalignmentLayout.SequenceArray = [\"POINTS\", \"Scalar\"]\nalignmentLayout.SizeArray = [\"POINTS\", \"BranchIDs\"]\nalignmentLayout.UseBranches = 1\nalignmentLayout.BranchArray = [\"POINTS\", \"BranchIDs\"]\nalignmentLayout.LevelArray = [\"POINTS\", \"BranchIDs\"]\n\n# create a new 'Calculator'\nalignmentEdges = Calculator(Input=alignmentLayout)\nalignmentEdges.CoordinateResults = 1\nalignmentEdges.Function = \"iHat*Layout_Y+jHat*Scalar*3\"\n\n# create a query selection\nShow()\nQuerySelect(\n    QueryString=\"(id == 16)\", Source=alignmentEdges, FieldType=\"POINT\", InsideOut=0\n)\n\n# create a new 'Extract Selection'\nselectedVertex = ExtractSelection(Input=alignmentEdges)\n\n# create a new 'TTK GridLayout'\nsegmentationsGrid = TTKGridLayout(Input=OutputPort(ttkMergeandContourTree, 2))\nsegmentationsGrid.ColumnGap = 10.0\nsegmentationsGrid.RowGap = 10.0\n\n# create a new 'TTK ForEach'\nttkForEach = TTKForEach(Input=segmentationsGrid)\nttkForEach.InputArray = [\"POINTS\", \"SegmentationId\"]\nttkForEach.ImageExtent = [0, 127, 0, 255, 0, 0]\n\n# create a new 'Merge Blocks'\nmergeBlocks = MergeBlocks(Input=ttkForEach)\n\n# create a new 'TTK ArrayEditor'\npassSegmentationIDs = TTKArrayEditor(Target=mergeBlocks, Source=selectedVertex)\npassSegmentationIDs.EditorMode = \"Add Arrays from Source\"\npassSegmentationIDs.TargetAttributeType = \"Field Data\"\npassSegmentationIDs.SourcePointDataArrays = [\"segmentationIDs\"]\npassSegmentationIDs.TargetArray = [\"POINTS\", \"SegmentationId\"]\n\n# create a new 'TTK Extract'\nextractMatchedGeometry = TTKExtract(Input=passSegmentationIDs)\nextractMatchedGeometry.ExtractionMode = \"Geometry\"\nextractMatchedGeometry.Expression = \"{segmentationIDs[{_ttk_IterationInfo[0]}]}\"\nextractMatchedGeometry.ImageExtent = [\n    2147483647,\n    -2147483647,\n    2147483647,\n    -2147483647,\n    2147483647,\n    -2147483647,\n]\nextractMatchedGeometry.InputArray = [\"POINTS\", \"SegmentationId\"]\n\n# create a new 'TTK BlockAggregator'\nttkBlockAggregator = TTKBlockAggregator(Input=extractMatchedGeometry)\n\n# create a new 'TTK EndFor'\nttkEndFor = TTKEndFor(Data=ttkBlockAggregator, For=ttkForEach)\n\n# save the output\nSaveData(\"ContourTreeAlignment.vtu\", alignmentEdges)\nSaveData(\"Segmentations.vtm\", segmentationsGrid)\nSaveData(\"MatchedRegions.vtm\", ttkEndFor)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/contourTreeAlignment.py\n</code></pre></p>"},{"location":"contourTreeAlignment/#inputs","title":"Inputs","text":"<ul> <li>heatedCylinder/heatedCylinder_2D_raw.cdb: a cinema data base of 23x10 2D scalar fields.</li> </ul>"},{"location":"contourTreeAlignment/#outputs","title":"Outputs","text":"<ul> <li><code>ContorTreeAlignment.vtu</code>: the output alignment in VTK file format (left view, above screenshot).</li> <li><code>Segmentations.vtm</code>: the segmentations of the input scalar fields in VTK multiblock format (right view, above screenshot).</li> <li><code>MatchedRegions.vtm</code>: the regions of the original fields that are represented by a selected vertex in VTK multiblock format (right view, ab\u017fove screenshot).</li> </ul>"},{"location":"contourTreeAlignment/#cpython-api","title":"C++/Python API","text":"<p>ArrayEditor</p> <p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaQuery</p> <p>CinemaReader</p> <p>ContourTree</p> <p>ContourTreeAlignment</p> <p>EndFor</p> <p>Extract</p> <p>ForEach</p> <p>GridLayout</p> <p>PlanarGraphLayout</p> <p>TopologicalSimplificationByPersistence</p>"},{"location":"ctBones/","title":"CT bones","text":""},{"location":"ctBones/#pipeline-description","title":"Pipeline description","text":"<p>This example segments medical image data based on topological persistence.</p> <p>First, the PersistenceDiagram of the data is computed (top right view, above screenshot). </p> <p>Then, only the 5 most persistent maxima are selected, corresponding to the toes of the foot.</p> <p>Next, the input data is simplified based on the selected persistent features, via TopologicalSimplification.</p> <p>Next, the Split tree of the simplified data is computed. </p> <p>Finally, the geometry of the bones of the toes is extracted by selecting the regions (in the 3D data) attached to the leaves (<code>RegionType</code> equals 1) of the Split tree (center view, above screenshot).</p> <p>To get a refined segmentation, change the persistence threshold from <code>180</code> down to <code>150</code>.  Each toe will be subdivided into two segments, precisely along the joints.</p>"},{"location":"ctBones/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/ctBones.pvsm\n</code></pre></p>"},{"location":"ctBones/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\nctBonesvti = XMLImageDataReader(FileName=[\"ctBones.vti\"])\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=ctBonesvti)\ncalculator1.ResultArrayName = \"Scalars_\"\ncalculator1.Function = \"-Scalars_\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"Scalars_\"]\ntTKPersistenceDiagram1.Dimensions = \"Selected Dimensions (no infinite pairs)\"\ntTKPersistenceDiagram1.Saddlesaddlediagramdimension1slowest = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.0\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 180.0\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=calculator1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"Scalars_\"]\n\n# create a new 'TTK Merge and Contour Tree ()'\ntTKMergeandContourTree1 = TTKMergeTree(\n    Input=tTKTopologicalSimplification1\n)\ntTKMergeandContourTree1.ScalarField = [\"POINTS\", \"Scalars_\"]\ntTKMergeandContourTree1.TreeType = \"Join Tree\"\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=OutputPort(tTKMergeandContourTree1, 2))\nthreshold3.Scalars = [\"POINTS\", \"RegionType\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 0.0\nthreshold3.UpperThreshold = 0.0\n\nSaveData(\"CTBonesOutputSegmentation.vtu\", threshold3)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/ctBones.py\n</code></pre></p>"},{"location":"ctBones/#inputs","title":"Inputs","text":"<ul> <li>ctBones.vti: a three-dimensional regular grid encoding material density in a medical image (CT scan).</li> </ul>"},{"location":"ctBones/#outputs","title":"Outputs","text":"<ul> <li><code>CTBonesOutputSegmentation.vtu</code>: the geometry of the volume of the bones of the toes, as extracted by the analysis pipeline (most persistent super-level set connected components).</li> </ul>"},{"location":"ctBones/#cpython-api","title":"C++/Python API","text":"<p>MergeTree</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"dragon/","title":"Dragon","text":""},{"location":"dragon/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a triangle mesh from disk. In a pre-processing, the mesh is smoothed and an elevation function is computed on top of it. The elevation function will be considered as the input scalar data in the remainder.</p> <p>Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot).</p> <p>The PersistenceCurve is also computed (top right view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of ScalarFieldCriticalPoints (top left view, above screenshot) and the ContourTree (bottom left view, above screenshot).</p>"},{"location":"dragon/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/dragon.pvsm\n</code></pre></p>"},{"location":"dragon/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\ndragonvtu = XMLUnstructuredGridReader(FileName=[\"dragon.vtu\"])\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother1 = TTKGeometrySmoother(Input=dragonvtu)\n\n# create a new 'Calculator'\nelevation = Calculator(Input=tTKGeometrySmoother1)\nelevation.ResultArrayName = \"Elevation\"\nelevation.Function = \"coordsY\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=elevation)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"Elevation\"]\ntTKPersistenceDiagram1.IgnoreBoundary = True\n\n# create a new 'TTK PersistenceCurve'\ntTKPersistenceCurve1 = TTKPersistenceCurve(Input=tTKPersistenceDiagram1)\n\n# create a new 'Threshold'\npairs = Threshold(Input=tTKPersistenceDiagram1)\npairs.Scalars = [\"CELLS\", \"PairIdentifier\"]\npairs.ThresholdMethod = \"Between\"\npairs.LowerThreshold = 0.0\npairs.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=pairs)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 5.0\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=elevation, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"Elevation\"]\n\n# create a new 'TTK ScalarFieldCriticalPoints'\ntTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints(\n    Input=tTKTopologicalSimplification1\n)\ntTKScalarFieldCriticalPoints1.ScalarField = [\"POINTS\", \"Elevation\"]\n\n# create a new 'TTK Merge and Contour Tree ()'\ntTKContourTree1 = TTKContourTree(Input=tTKTopologicalSimplification1)\ntTKContourTree1.ScalarField = [\"POINTS\", \"Elevation\"]\ntTKContourTree1.ArcSampling = 30\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother2 = TTKGeometrySmoother(Input=OutputPort(tTKContourTree1, 1))\ntTKGeometrySmoother2.IterationNumber = 40\n\n# create a new 'Extract Surface'\nextractSurface4 = ExtractSurface(Input=tTKGeometrySmoother2)\n\n# create a new 'Tube'\ntube4 = Tube(Input=extractSurface4)\ntube4.NumberofSides = 12\ntube4.Radius = 0.75\n\n# create a new 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints4 = TTKIcospheresFromPoints(Input=tTKContourTree1)\ntTKIcospheresFromPoints4.Radius = 2.0\n\n# save the output\nSaveData(\"PersistenceDiagram.vtu\", tTKPersistenceDiagram1)\nSaveData(\"PersistenceCurve.csv\", OutputPort(tTKPersistenceCurve1, 3))\nSaveData(\"CriticalPoints.vtp\", tTKScalarFieldCriticalPoints1)\nSaveData(\"ContourTreeNodes.vtp\", tTKIcospheresFromPoints4)\nSaveData(\"ContourTreeArcs.vtp\", tube4)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/dragon.py\n</code></pre></p>"},{"location":"dragon/#inputs","title":"Inputs","text":"<ul> <li>dragon.vtu: a two-dimensional triangulation.</li> </ul>"},{"location":"dragon/#outputs","title":"Outputs","text":"<ul> <li><code>PersistenceDiagram.vtu</code>: the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>PersistenceCurve.csv</code>: the output persistence curve.</li> <li><code>CriticalPoints.vtp</code>: the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>ContourTreeNode.vtp</code>: spheres, representing the nodes of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>ContourTreeArcs.vtp</code>: cylinders, representing the arcs of the output contour tree in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"dragon/#cpython-api","title":"C++/Python API","text":"<p>ContourTree</p> <p>GeometrySmoother</p> <p>IcospheresFromPoints</p> <p>PersistenceCurve</p> <p>PersistenceDiagram</p> <p>ScalarFieldCriticalPoints</p> <p>TopologicalSimplification</p>"},{"location":"geometryApproximation/","title":"Geometry Approximation","text":""},{"location":"geometryApproximation/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads the geometry of a stone.</p> <p>A fake shadow is put on the stone mesh to give the mesh depth values. The stone object is placed within a sphere using IcosphereFromObject. The object and the icosphere is then given to the CinemaImaging filter. It generates multiple images of the stone object, and the images are taken from cameras placed on the vertices of the icosphere.</p> <p>An approximation of the geometry is calculated from the images using DepthImageBasedGeometryApproximation. The approximated geometry can be extracted using the <code>Threshold</code> filter.</p>"},{"location":"geometryApproximation/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/geometryApproximation.pvsm\n</code></pre></p>"},{"location":"geometryApproximation/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML PolyData Reader'\nstonevtp = XMLPolyDataReader(FileName=[\"GroundWater.cdb/stone.vtp\"])\n\n# create a new 'Elevation'\nfakeShadow = Elevation(Input=stonevtp)\nfakeShadow.LowPoint = [0.13294358695786565, 0.08882809227819845, -0.018024881743751362]\nfakeShadow.HighPoint = [0.06742407365289238, 0.018398674549435334, 0.138207120609427]\n\n# create a new 'TTK IcosphereFromObject'\ntTKIcosphereFromObject1 = TTKIcosphereFromObject(Object=stonevtp)\n\n# create a new 'TTK CinemaImaging'\ntTKCinemaImaging1 = TTKCinemaImaging(\n    Dataset=fakeShadow, SamplingGrid=tTKIcosphereFromObject1\n)\n\n# create a new 'TTK DepthImageBasedGeometryApproximation'\ntTKDepthImageBasedGeometryApproximation1 = TTKDepthImageBasedGeometryApproximation(\n    Input=tTKCinemaImaging1\n)\ntTKDepthImageBasedGeometryApproximation1.DepthArray = [\"POINTS\", \"Depth\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKDepthImageBasedGeometryApproximation1)\nthreshold1.Scalars = [\"CELLS\", \"TriangleDistortion\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -999999999\nthreshold1.UpperThreshold = 0.02\n\nSaveData(\"CinemaImages.vtm\", tTKCinemaImaging1)\nSaveData(\"GeometryApproximatedStone.vtm\", threshold1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/geometryApproximation.py\n</code></pre></p>"},{"location":"geometryApproximation/#inputs","title":"Inputs","text":"<ul> <li>stone.vtp: a mesh of the stone around the ground water.</li> </ul>"},{"location":"geometryApproximation/#outputs","title":"Outputs","text":"<ul> <li><code>CinemaImages.vtm</code>: the images from the cameras given in a multiblock.</li> <li><code>GeometryApproximatedStone.vtm</code>: the reconstructed objected as a multiblock of meshes.</li> </ul>"},{"location":"geometryApproximation/#cpython-api","title":"C++/Python API","text":"<p>IcosphereFromObject</p> <p>CinemaImaging</p> <p>DepthImageBasedGeometryApproximation</p>"},{"location":"harmonicSkeleton/","title":"Harmonic Skeleton","text":""},{"location":"harmonicSkeleton/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads the pegasus triangle mesh from disk. For pre-processing, an elevation function is computed on the mesh, creating Ids for all vertices afterwards. From the created ids the bottom middle of the platform, both wing tips, the tip of the nose and the tip of the horn of pegasus are selected (right view shows them together with more vertices).</p> <p>Now, a HarmonicField is computed using these five points as extrema in the output field, helping to reduce noise in the dataset, creating a smooth field with defined extrema that can later be extracted.</p> <p>The harmonic field is then normalized using the ScalarFieldNormalizer.</p> <p>Then, the PersistenceDiagram is computed on the normalized field, extracting a threshold that is used to simplify the harmonic field using TopologicalSimplification.</p> <p>Finally, the ReebGraph is constructed, extracting its nodes and arcs afterwards (right view shows them). The arcs of the ReebGraph are smoothed with the GeometrySmoother to produce the final, output shape skeleton.</p>"},{"location":"harmonicSkeleton/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/harmonicSkeleton.pvsm\n</code></pre></p>"},{"location":"harmonicSkeleton/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\n#### import the simple module from the paraview\nfrom paraview.simple import *\n\n# load the pegasus dataset by creating a'XML Unstructured Grid Reader'\npegasusvtu = XMLUnstructuredGridReader(FileName=[\"pegasus.vtu\"])\n\n# create a new 'Elevation' on the dataset\nelevation1 = Elevation(Input=pegasusvtu)\nelevation1.LowPoint = [55.58376886060912, -88.42696707641238, -1166.7651999539546]\nelevation1.HighPoint = [-27.56680371810648, 70.65296514617846, -1072.7592471929715]\n\n# create a new 'Generate Ids'\ngenerateIds1 = GenerateIds(Input=elevation1)\ngenerateIds1.PointIdsArrayName = \"ttkVertexScalarField\"\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=elevation1, DestinationMesh=generateIds1\n)\nresampleWithDataset1.PassPointArrays = 1\nresampleWithDataset1.CellLocator = \"Static Cell Locator\"\n\n# create a new 'Extract Selection', creating its query first and clearing it afterwards\nShow()\nQuerySelect(\n    QueryString=\"(ttkVertexScalarField == 29019)\",\n    FieldType=\"POINT\",\n    InsideOut=0,\n    Source=resampleWithDataset1,\n)\nextractSelection1 = ExtractSelection(Input=resampleWithDataset1)\nClearSelection()\n\n# create a new 'Extract Selection', creating its query first and clearing it afterwards\nQuerySelect(\n    QueryString=\"(ttkVertexScalarField == 171102)\",\n    FieldType=\"POINT\",\n    InsideOut=0,\n    Source=resampleWithDataset1,\n)\nextractSelection2 = ExtractSelection(Input=resampleWithDataset1)\nClearSelection()\n\n# create a new 'Extract Selection', creating its query first and clearing it afterwards\nQuerySelect(\n    QueryString=\"(ttkVertexScalarField == 204530)\",\n    FieldType=\"POINT\",\n    InsideOut=0,\n    Source=resampleWithDataset1,\n)\nextractSelection3 = ExtractSelection(Input=resampleWithDataset1)\nClearSelection()\n\n# create a new 'Extract Selection', creating its query first and clearing it afterwards\nQuerySelect(\n    QueryString=\"(ttkVertexScalarField == 216852)\",\n    FieldType=\"POINT\",\n    InsideOut=0,\n    Source=resampleWithDataset1,\n)\nextractSelection4 = ExtractSelection(Input=resampleWithDataset1)\nClearSelection()\n\n# create a new 'Extract Selection', creating its query first and clearing it afterwards\nQuerySelect(\n    QueryString=\"(ttkVertexScalarField == 219572)\",\n    FieldType=\"POINT\",\n    InsideOut=0,\n    Source=resampleWithDataset1,\n)\nextractSelection5 = ExtractSelection(Input=resampleWithDataset1)\nClearSelection()\n\n# create a new 'Append Datasets'\nappendDatasets1 = AppendDatasets(\n    Input=[\n        extractSelection1,\n        extractSelection2,\n        extractSelection3,\n        extractSelection4,\n        extractSelection5,\n    ]\n)\n\n# create a new 'TTK HarmonicField'\ntTKHarmonicField1 = TTKHarmonicField(\n    Domain=resampleWithDataset1, Constraints=appendDatasets1\n)\ntTKHarmonicField1.ScalarField = [\"POINTS\", \"Elevation\"]\ntTKHarmonicField1.ConstraintVerticesIdentifiers = [\"POINTS\", \"Elevation\"]\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKHarmonicField1)\ncalculator1.ResultArrayName = \"ScaledHarmonic\"\ncalculator1.Function = \"OutputHarmonicField^2.375\"\n\n# create a new 'TTK ScalarFieldNormalizer'\ntTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer(Input=calculator1)\ntTKScalarFieldNormalizer1.ScalarField = [\"POINTS\", \"ScaledHarmonic\"]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=tTKScalarFieldNormalizer1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"ScaledHarmonic\"]\ntTKPersistenceDiagram1.EmbedinDomain = 1\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"Persistence\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.001\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=tTKScalarFieldNormalizer1, Constraints=threshold1\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"ScaledHarmonic\"]\n\n# create a new 'TTK Reeb Graph'\ntTKReebgraphFTR1 = TTKReebGraph(Input=tTKTopologicalSimplification1)\ntTKReebgraphFTR1.ScalarField = [\"POINTS\", \"ScaledHarmonic\"]\ntTKReebgraphFTR1.ArcSampling = 20\ntTKReebgraphFTR1.UseAllCores = False\n\n# create a new 'TTK GeometrySmoother' taking the reeb graph edges for input\ntTKGeometrySmoother1 = TTKGeometrySmoother(Input=OutputPort(tTKReebgraphFTR1, 1))\ntTKGeometrySmoother1.IterationNumber = 20\n\n# create a new 'Extract Surface'\nextractSurface2 = ExtractSurface(Input=tTKGeometrySmoother1)\n\n# create a new 'Tube' representing the reep graph edges\ntube1 = Tube(Input=extractSurface2)\ntube1.Radius = 0.75\n\n# create a new 'TTK IcospheresFromPoints' representing the reeb graph nodes\ntTKIcospheresFromPoints1 = TTKIcospheresFromPoints(Input=tTKReebgraphFTR1)\ntTKIcospheresFromPoints1.Radius = 2.0\n\nSaveData(\"ReebGraphNodes.vtp\", tTKIcospheresFromPoints1)\nSaveData(\"ReebGraphArcs.vtp\", tube1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/harmonicSkeleton.py\n</code></pre></p>"},{"location":"harmonicSkeleton/#inputs","title":"Inputs","text":"<ul> <li>pegasus.vtu: a two-dimensional triangulation.</li> </ul>"},{"location":"harmonicSkeleton/#outputs","title":"Outputs","text":"<ul> <li><code>ReebGraphNodes.vtp</code>: spheres, representing the nodes of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>ReebGraphArcs.vtp</code>: cylinders (the output skeleton of the input shape), representing the arcs of the output ReebGraph in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"harmonicSkeleton/#cpython-api","title":"C++/Python API","text":"<p>ReebGraph</p> <p>GeometrySmoother</p> <p>HarmonicField</p> <p>IcosphereFromPoints</p> <p>PersistenceDiagram</p> <p>ScalarFieldNormalizer</p> <p>TopologicalSimplification</p>"},{"location":"imageProcessing/","title":"Image Processing","text":""},{"location":"imageProcessing/#pipeline-description","title":"Pipeline description","text":"<p>This example processes a grayscale image (top left view on the above screenshot) to generate a segmentation. We will construct the segmentation from the image gradient.</p> <p>First, the image is loaded from disk. The gradient is computed with ParaView's <code>ComputeDerivatives</code> or <code>Gradient</code> filters. Since TTK only works on scalar field, a <code>Calculator</code> is used to compute the gradient magnitude.</p> <p>From the gradient magnitude, a simplification step involving PersistenceDiagram (bottom left view) and TopologicalSimplification helps removing the noise in the gradient (top right view).</p> <p>To segment the image, we use the MorseSmaleComplex filter. Since in the input image the objects correspond to low values in the gradient and their edges to high values, we are interested in the <code>DescendingManifold</code> scalar field of the <code>Segmentation</code> output, whose cells represent regions of low scalar field values.</p> <p>The IdentifierRandomizer filter is eventually used in order to color neighbor cells with a distinct color (bottom right view on the above screenshot).</p>"},{"location":"imageProcessing/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command:</p> <pre><code>paraview states/imageProcessing.pvsm\n</code></pre>"},{"location":"imageProcessing/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\nnaturalImagepng = PNGSeriesReader(FileNames=[\"naturalImage.png\"])\n\n# create a new 'Compute Derivatives'\ncomputeDerivatives1 = ComputeDerivatives(Input=naturalImagepng)\ncomputeDerivatives1.Scalars = [\"POINTS\", \"PNGImage\"]\n\n# create a new 'Cell Data to Point Data'\ncellDatatoPointData1 = CellDatatoPointData(Input=computeDerivatives1)\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=cellDatatoPointData1)\ncalculator1.ResultArrayName = \"gradient\"\ncalculator1.Function = \"mag(ScalarGradient)\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"gradient\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.0\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 6.0\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=calculator1,\n    Constraints=persistenceThreshold,\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"gradient\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"gradient\"]\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 1))\nthreshold3.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 1.0\nthreshold3.UpperThreshold = 1.0\n\n# create a new 'TTK IdentifierRandomizer'\ntTKIdentifierRandomizer1 = TTKIdentifierRandomizer(\n    Input=OutputPort(tTKMorseSmaleComplex1, 3),\n)\ntTKIdentifierRandomizer1.ScalarField = [\"POINTS\", \"DescendingManifold\"]\n\nSaveData(\"Segmentation.vti\", tTKIdentifierRandomizer1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/imageProcessing.py\n</code></pre></p>"},{"location":"imageProcessing/#inputs","title":"Inputs","text":"<ul> <li>naturalImage.png:   a grayscale PNG picture.</li> </ul>"},{"location":"imageProcessing/#outputs","title":"Outputs","text":"<ul> <li><code>Segmentation.vti</code>: the image segmentation output.</li> </ul>"},{"location":"imageProcessing/#cpython-api","title":"C++/Python API","text":"<p>IdentifierRandomizer</p> <p>MorseSmaleComplex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"interactionSites/","title":"Interaction sites","text":""},{"location":"interactionSites/#pipeline-description","title":"Pipeline description","text":"<p>This example demostrates how topological analysis can be used to identify interaction sites i.e. different kind of chemical bonds in molecules. Using simulations and experiments, the electron density field denoted as <code>Rho</code> can be estimated for a molecule. Topological analysis of this scalar field can reveal important features in the data. For example, the maxima of this field correspond to the atom locations while saddles occur along the covalent bonds. However, for identification of non-covalent interactions like ionic bonds, analysis of the density field <code>Rho</code> is not enough. A derived scalar field from <code>Rho</code> called reduced density gradeint denoted by <code>s</code> is suggested in literature which can reveal non-covalent interation sites in a molecule. In this example, we will extract and compare the critical points for the <code>Rho</code> and <code>s</code> scalar fields for a simple molecule 1,2-ethanediol. </p> <p>First a VTI file is loaded which contains two scalar fields namely <code>log(Rho)</code> and <code>log(s)</code>. Then using ScalarFieldCriticalPoints, the critical points for <code>log(Rho)</code> are computed which are then converted into spheres using IcospheresFromPoints. They are shown as bigger transluscent green and white spheres in the screenshot above. Note that these critical points identify the atoms and covalent bonds in the molecule.</p> <p>Next, we analyse <code>log(s)</code>, the reduced gradient scalar field. Here, the PersistenceCurve is computed (top right view in the above screenshot). Then, the PersistenceDiagram for <code>log(s)</code> is computed and thresholds are applied based on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data. The simplified data is then used as input to MergeTree to compute the join tree for the data. The join tree captures the topological changes in sub-level sets of the scalar field and therefore consists of leaves corresponding to minima and internal nodes corresponding to saddles, the points where sublevel sets merge. The nodes of this join tree are selected and highlighted as smaller opaque blue and white spheres using IcospheresFromPoints. Similarly, the arcs of the join tree are also extracted and shown as thin grey tubes in the screenshot above.</p> <p>Using topological analysis of <code>log(s)</code>, we identify an outlying minimum which is not close to the atom locations. This corresponds to a non-covalent interaction site in the molecule which is not identifiable using direct toplogical analysis of electron density field <code>Rho</code>. Lastly, we extract the segmented region corresponding to this particular minimum (shown as transluscent blue surface in the screenshot). </p>"},{"location":"interactionSites/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/interactionSites.pvsm\n</code></pre></p>"},{"location":"interactionSites/#python-code","title":"Python code","text":"<pre><code>#### import the simple module from the paraview\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\nbuiltInExamplevti = XMLImageDataReader(FileName=[\"BuiltInExample2.vti\"])\n\n#### Topological analysis of 'log(Rho)'\n\n# extract the critical points using 'TTK ScalarFieldCriticalPoints'\ntTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints(Input=builtInExamplevti)\ntTKScalarFieldCriticalPoints1.ScalarField = [\"POINTS\", \"log(Rho)\"]\n\n# covert these points to spheres using 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints3 = TTKIcospheresFromPoints(Input=tTKScalarFieldCriticalPoints1)\ntTKIcospheresFromPoints3.Radius = 3.0\n\n#### Topological analysis of 'log(s)'\n\n# compute the 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=builtInExamplevti)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"log(s)\"]\n\n# compute the 'TTK PersistenceCurve'\ntTKPersistenceCurve1 = TTKPersistenceCurve(Input=tTKPersistenceDiagram1)\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.0\nthreshold1.UpperThreshold = 999999999\n\n# remove low persistence critical points using 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 0.5\npersistenceThreshold.UpperThreshold = 999999999\n\n# simplify the field using 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=builtInExamplevti, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"log(s)\"]\n\n# create a new 'TTK Merge and Contour Tree' to compute the join tree\ntTKJoinTree1 = TTKMergeTree(Input=tTKTopologicalSimplification1)\ntTKJoinTree1.ScalarField = [\"POINTS\", \"log(s)\"]\ntTKJoinTree1.TreeType = \"Join Tree\"\ntTKJoinTree1.ArcSampling = 30\n\n# covert the critical points to spheres using 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints4 = TTKIcospheresFromPoints(Input=tTKJoinTree1)\ntTKIcospheresFromPoints4.Radius = 2.0\n\n# extract the join tree arcs and save them as tubes\ntTKGeometrySmoother2 = TTKGeometrySmoother(Input=OutputPort(tTKJoinTree1, 1))\ntTKGeometrySmoother2.IterationNumber = 300\n\n# create a new 'Extract Surface'\nextractSurface4 = ExtractSurface(Input=tTKGeometrySmoother2)\n\n# create a new 'Tube'\ntube5 = Tube(Input=extractSurface4)\ntube5.Radius = 0.25\n\n# Extract the segmentation region corresponding to the interaction site\nthreshold6 = Threshold(Input=OutputPort(tTKJoinTree1, 2))\nthreshold6.Scalars = [\"POINTS\", \"RegionType\"]\n\n# create a new 'Threshold'\nthreshold7 = Threshold(Input=threshold6)\nthreshold7.Scalars = [\"POINTS\", \"SegmentationId\"]\nthreshold7.ThresholdMethod = \"Between\"\nthreshold7.LowerThreshold = 13.0\nthreshold7.UpperThreshold = 13.0\n\n# create a new 'Extract Surface'\nextractSurface5 = ExtractSurface(Input=threshold7)\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=extractSurface5)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother3 = TTKGeometrySmoother(Input=tetrahedralize1)\ntTKGeometrySmoother3.IterationNumber = 10\n\n# save the output\nSaveData(\"logRhoCriticalPoints.vtp\", tTKIcospheresFromPoints3)\nSaveData(\"logSPersistenceCurve.csv\", OutputPort(tTKPersistenceCurve1, 0))\nSaveData(\"logSPersistenceDiagram.vtu\", tTKPersistenceDiagram1)\nSaveData(\"logSJoinTreeCriticalPoints.vtp\", tTKIcospheresFromPoints4)\nSaveData(\"logSJoinTreeArcs.vtp\", tube5)\nSaveData(\"NonCovalentInteractionSite.vtu\", tTKGeometrySmoother3)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/interactionSites.py\n</code></pre></p>"},{"location":"interactionSites/#inputs","title":"Inputs","text":"<ul> <li>BuiltInExample2.vti: 3D scalar fields corresponding to electron density distribution <code>Rho</code> and the reduced density gradient <code>s</code> around a simple molecule 1,2-ethanediol.</li> </ul>"},{"location":"interactionSites/#outputs","title":"Outputs","text":"<ul> <li><code>logRhoCriticalPoints.vtp</code>: All the scalar field critical points computed for <code>log(Rho)</code>. </li> <li><code>logSPersistenceCurve.csv</code>: The output persistence curve for <code>log(s)</code>.</li> <li><code>logSPersistenceDiagram.vtu</code>: The output persistence diagram for <code>log(s)</code>.</li> <li><code>logSJoinTreeCriticalPoints.vtp</code>: The critical points in the join tree of <code>log(s)</code>.</li> <li><code>logSJoinTreeArcs.vtp</code>: The arcs of the join tree of <code>log(s)</code>.</li> <li><code>NonCovalentInteractionSite.vtp</code>: The non-covalent interaction site region identified using the join tree of <code>log(s)</code>.</li> </ul> <p>Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</p>"},{"location":"interactionSites/#cpython-api","title":"C++/Python API","text":"<p>MergeTree</p> <p>GeometrySmoother</p> <p>IcospheresFromPoints</p> <p>PersistenceCurve</p> <p>PersistenceDiagram</p> <p>ScalarFieldCriticalPoints</p> <p>TopologicalSimplification</p>"},{"location":"karhunenLoveDigits64Dimensions/","title":"Karhunen-Love Digits 64-Dimensions","text":""},{"location":"karhunenLoveDigits64Dimensions/#pipeline-description","title":"Pipeline description","text":"<p>This example performs a persistence driven clustering of a high-dimensional data set, specifically a collection of 2000 images representing hand written digits. Each image is encoded by its Karhunen-Love coefficients, a 64-dimensional vector. This results in a point cloud of 2000 points (2000 rows), living in 64 dimensions (64 columns).</p> <p>The ground truth classification for each point is provided by the column <code>Field0</code> (point color in the bottom right view, above screenshot), which indicates the digit represented by the corresponding image.</p> <p>The pipeline starts by using DimensionReduction (with tSNE) to project the data down to 2D.</p> <p>Next, the density of the projected 2D point cloud is estimated with a Gaussian kernel, by the <code>GaussianResampling</code>  filter, coupled with the <code>Slice</code> filter (to restrict the estimation to a 2D plane). </p> <p>Next, the PersistenceDiagram of the density field is computed and only the 10 most persistent density maxima are selected (corresponding to the 10 classes, one per digit, bottom left view in the above screenshot).</p> <p>Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field. The simplified density field then contains only 10 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot). </p> <p>Finally, the cluster identifier of each input point is given by the identifier of the  corresponding ascending manifold of the Morse-Smale complex (<code>AscendingManifold</code>), with the <code>ResampleWithDataset</code> filter.</p>"},{"location":"karhunenLoveDigits64Dimensions/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/karhunenLoveDigits64Dimensions.pvsm\n</code></pre></p>"},{"location":"karhunenLoveDigits64Dimensions/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\nkarhunenLoveDigits64Dimensionscsv = CSVReader(\n    FileName=[\"karhunenLoveDigits64Dimensions.csv\"]\n)\nkarhunenLoveDigits64Dimensionscsv.HaveHeaders = 0\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction1 = TTKDimensionReduction(Input=karhunenLoveDigits64Dimensionscsv)\ntTKDimensionReduction1.InputColumns = [\n    \"Field 1\",\n    \"Field 10\",\n    \"Field 11\",\n    \"Field 12\",\n    \"Field 13\",\n    \"Field 14\",\n    \"Field 15\",\n    \"Field 16\",\n    \"Field 17\",\n    \"Field 18\",\n    \"Field 19\",\n    \"Field 2\",\n    \"Field 20\",\n    \"Field 21\",\n    \"Field 22\",\n    \"Field 23\",\n    \"Field 24\",\n    \"Field 25\",\n    \"Field 26\",\n    \"Field 27\",\n    \"Field 28\",\n    \"Field 29\",\n    \"Field 3\",\n    \"Field 30\",\n    \"Field 31\",\n    \"Field 32\",\n    \"Field 33\",\n    \"Field 34\",\n    \"Field 35\",\n    \"Field 36\",\n    \"Field 37\",\n    \"Field 38\",\n    \"Field 39\",\n    \"Field 4\",\n    \"Field 40\",\n    \"Field 41\",\n    \"Field 42\",\n    \"Field 43\",\n    \"Field 44\",\n    \"Field 45\",\n    \"Field 46\",\n    \"Field 47\",\n    \"Field 48\",\n    \"Field 49\",\n    \"Field 5\",\n    \"Field 50\",\n    \"Field 51\",\n    \"Field 52\",\n    \"Field 53\",\n    \"Field 54\",\n    \"Field 55\",\n    \"Field 56\",\n    \"Field 57\",\n    \"Field 58\",\n    \"Field 59\",\n    \"Field 6\",\n    \"Field 60\",\n    \"Field 61\",\n    \"Field 62\",\n    \"Field 63\",\n    \"Field 64\",\n    \"Field 7\",\n    \"Field 8\",\n    \"Field 9\",\n]\ntTKDimensionReduction1.Method = \"t-distributed Stochastic Neighbor Embedding\"\ntTKDimensionReduction1.UseAllCores = False\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=tTKDimensionReduction1)\ntableToPoints1.XColumn = \"Component_0\"\ntableToPoints1.YColumn = \"Component_1\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"Persistence\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 10.0\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=threshold1\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK IdentifierRandomizer'\ntTKIdentifierRandomizer1 = TTKIdentifierRandomizer(\n    Input=OutputPort(tTKMorseSmaleComplex1, 3)\n)\ntTKIdentifierRandomizer1.ScalarField = [\"POINTS\", \"AscendingManifold\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=tTKIdentifierRandomizer1, DestinationMesh=tableToPoints1\n)\nresampleWithDataset1.PassPointArrays = 1\n\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/karhunenLoveDigits64Dimensions.py\n</code></pre></p>"},{"location":"karhunenLoveDigits64Dimensions/#inputs","title":"Inputs","text":"<ul> <li>karhunenLoveDigits64Dimensions.csv: an input high dimensional point cloud (2000 points in 64 dimensions).</li> </ul>"},{"location":"karhunenLoveDigits64Dimensions/#outputs","title":"Outputs","text":"<ul> <li><code>OutputClustering.csv</code>: the output clustering of the input point cloud (output cluster identifier: <code>AscendingManifold</code> column, ground truth: <code>Field0</code>)</li> </ul>"},{"location":"karhunenLoveDigits64Dimensions/#cpython-api","title":"C++/Python API","text":"<p>DimensionReduction</p> <p>IdentifierRandomizer</p> <p>Morse-Smale complex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"manifoldCheck/","title":"Manifold Check","text":""},{"location":"manifoldCheck/#pipeline-description","title":"Pipeline description","text":"<p>This example loads three different hexahedral geometry files from disk. In a pre-processing, each geometry is tetrahedralized, which is used as input data.</p> <p>On each of the three geometries, ManifoldCheck is executed. This filters adds link numbers to vertices and cells, which can be used to detect and extract non-manifold vertices (left), edges (middle), and faces (right).</p>"},{"location":"manifoldCheck/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/manifoldChecks.pvsm\n</code></pre></p>"},{"location":"manifoldCheck/#python-code","title":"Python code","text":""},{"location":"manifoldCheck/#non-manifold-vertices","title":"Non-manifold Vertices","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nmanifoldCheck0vtu = XMLUnstructuredGridReader(FileName=[\"manifoldCheck0.vtu\"])\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=manifoldCheck0vtu)\n\n# create a new 'TTK ManifoldCheck'\ntTKManifoldCheck1 = TTKManifoldCheck(Input=tetrahedralize1)\n\n# create a new 'Mask Points'\nmaskPoints1 = MaskPoints(Input=tTKManifoldCheck1)\nmaskPoints1.OnRatio = 1\nmaskPoints1.MaximumNumberofPoints = 1000\nmaskPoints1.GenerateVertices = 1\nmaskPoints1.SingleVertexPerCell = 1\n\n# create a new 'Threshold'\n# this extracts non-manifold vertices\nthreshold1 = Threshold(Input=maskPoints1)\nthreshold1.Scalars = [\"POINTS\", \"VertexLinkComponentNumber\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 2.0\nthreshold1.UpperThreshold = 2.0\n\n# save the output\nSaveData(\"manifoldCheck0_check.vtu\", tTKManifoldCheck1)\nSaveData(\"manifoldCheck0_non_manifold.vtu\", threshold1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/manifoldCheck0.py\n</code></pre></p>"},{"location":"manifoldCheck/#non-manifold-edges","title":"Non-manifold Edges","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nmanifoldCheck1vtu = XMLUnstructuredGridReader(FileName=[\"manifoldCheck1.vtu\"])\n\n# create a new 'Tetrahedralize'\ntetrahedralize2 = Tetrahedralize(Input=manifoldCheck1vtu)\n\n# create a new 'TTK ManifoldCheck'\ntTKManifoldCheck2 = TTKManifoldCheck(Input=tetrahedralize2)\n\n# create a new 'Extract Edges'\nextractEdges2 = ExtractEdges(Input=tTKManifoldCheck2)\n\n# create a new 'Threshold'\n# this extracts non-manifold edges\nthreshold2 = Threshold(Input=extractEdges2)\nthreshold2.Scalars = [\"POINTS\", \"EdgeLinkComponentNumber\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = 2.0\nthreshold2.UpperThreshold = 2.0\n\n# save the output\nSaveData(\"manifoldCheck1_check.vtu\", tTKManifoldCheck2)\nSaveData(\"manifoldCheck1_non_manifold.vtu\", threshold2)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/manifoldCheck1.py\n</code></pre></p>"},{"location":"manifoldCheck/#non-manifold-faces","title":"Non-manifold Faces","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nmanifoldCheck2vtu = XMLUnstructuredGridReader(FileName=[\"manifoldCheck2.vtu\"])\n\n# create a new 'Tetrahedralize'\ntetrahedralize3 = Tetrahedralize(\n    registrationName=\"Tetrahedralize3\", Input=manifoldCheck2vtu\n)\n\n# create a new 'TTK ManifoldCheck'\ntTKManifoldCheck3 = TTKManifoldCheck(\n    registrationName=\"TTKManifoldCheck3\", Input=tetrahedralize3\n)\n\n# create a new 'Threshold'\n# this extracts tetrahedra that contain non-manifold faces\nthreshold3 = Threshold(registrationName=\"Threshold3\", Input=tTKManifoldCheck3)\nthreshold3.Scalars = [\"CELLS\", \"TriangleLinkComponentNumber\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 3.0\nthreshold3.UpperThreshold = 3.0\n\n# create a new 'Generate Ids'\ngenerateIds1 = GenerateIds(registrationName=\"GenerateIds1\", Input=threshold3)\ngenerateIds1.PointIdsArrayName = \"VertexIdentifiers\"\ngenerateIds1.CellIdsArrayName = \"CellIdentifiers\"\n\n# create a new 'Threshold'\n# select two of the tetrahedra\nthreshold4 = Threshold(registrationName=\"Threshold4\", Input=generateIds1)\nthreshold4.Scalars = [\"CELLS\", \"CellIdentifiers\"]\nthreshold4.ThresholdMethod = \"Between\"\nthreshold4.LowerThreshold = 0.0\nthreshold4.UpperThreshold = 1.0\n\n# create a new 'Extract Surface'\nextractSurface2 = ExtractSurface(registrationName=\"ExtractSurface2\", Input=threshold4)\n\n# create a new 'Threshold'\n# this extracts non-manifold faces\nthreshold5 = Threshold(registrationName=\"Threshold5\", Input=extractSurface2)\nthreshold5.Scalars = [\"POINTS\", \"TriangleLinkComponentNumber\"]\nthreshold5.ThresholdMethod = \"Between\"\nthreshold5.LowerThreshold = 3.0\nthreshold5.UpperThreshold = 3.0\n\n# save the output\nSaveData(\"manifoldCheck2_check.vtu\", tTKManifoldCheck3)\nSaveData(\"manifoldCheck2_non_manifold.vtu\", threshold5)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/manifoldCheck2.py\n</code></pre></p>"},{"location":"manifoldCheck/#inputs","title":"Inputs","text":"<ul> <li>manifoldCheck0.vtu: example mesh with non-manifold vertices</li> <li>manifoldCheck1.vtu: example mesh with non-manifold edges</li> <li>manifoldCheck2.vtu: example mesh with non-manifold faces</li> </ul>"},{"location":"manifoldCheck/#outputs","title":"Outputs","text":"<ul> <li><code>manifoldCheck0_check.vtu</code>, <code>manifoldCheck1_check.vtu</code>, <code>manifoldCheck2_check.vtu</code>: tetrhedralized geometry with link numbers</li> <li><code>manifoldCheck0_non_manifold.vtu</code>: non-manifold vertices in <code>manifoldCheck0.vtu</code></li> <li><code>manifoldCheck1_non_manifold.vtu</code>: non-manifold edges in <code>manifoldCheck1.vtu</code></li> <li><code>manifoldCheck2_non_manifold.vtu</code>: non-manifold faces in <code>manifoldCheck2.vtu</code></li> </ul>"},{"location":"manifoldCheck/#cpython-api","title":"C++/Python API","text":"<p>ManifoldCheck </p>"},{"location":"mergeTreeClustering/","title":"Merge Tree Clustering","text":""},{"location":"mergeTreeClustering/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the MergeTree is computed on each scalar field for the Join Tree and the Split Tree.</p> <p>All these trees are passed to MergeTreeClustering to compute a clustering in the metric space of merge trees. Each input is considered as a tuple consisting of the Join Tree and the Split Tree of the corresponding scalar field. Each centroid is also a tuple of this kind and a distance between two tuples is the distance between their Join Tree plus the distance between their Split Trees.</p> <p>Then, a distance matrix is computed with MergeTreeDistanceMatrix with the input trees and the 3 centroids.</p> <p>This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 2D respecting the most the input distance matrix.</p> <p>In terms of visualisation, the MDS result is visualized and colored by clustering assignment. The split trees centroids are visualized with a planar layout and also some fields of each cluster.</p> <p>In the second layout, the star clustering is visualized, consisting of the input split trees grouped by cluster, with the centroid of the cluster in the middle.</p> <p>The python script computes the MDS and saves the resulting 2D points (for input trees and centroids).</p>"},{"location":"mergeTreeClustering/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>araview states/mergeTreeClustering.pvsm\n</code></pre></p>"},{"location":"mergeTreeClustering/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"./Isabel.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\ntTKCinemaProductReader1.AddFieldDataRecursively = 1\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM26 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM26.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKMergeandContourTreeFTM26.TreeType = \"Join Tree\"\n\n# create a new 'Group Datasets'\nmt_JT_all = GroupDatasets(\n    Input=[\n        tTKMergeandContourTreeFTM26,\n        OutputPort(tTKMergeandContourTreeFTM26, 1),\n        OutputPort(tTKMergeandContourTreeFTM26, 2),\n    ]\n)\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM25 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM25.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKMergeandContourTreeFTM25.TreeType = \"Split Tree\"\n\n# create a new 'Group Datasets'\nmT_all = GroupDatasets(\n    Input=[\n        tTKMergeandContourTreeFTM25,\n        OutputPort(tTKMergeandContourTreeFTM25, 1),\n        OutputPort(tTKMergeandContourTreeFTM25, 2),\n    ]\n)\n\n# create a new 'TTK MergeTreeClustering'\ntTKMergeTreeClustering1 = TTKMergeTreeClustering(\n    Input=mT_all, OptionalInputclustering=mt_JT_all\n)\ntTKMergeTreeClustering1.ComputeBarycenter = 1\ntTKMergeTreeClustering1.NumberOfClusters = 3\ntTKMergeTreeClustering1.Deterministic = 1\ntTKMergeTreeClustering1.DimensionSpacing = 0.1\ntTKMergeTreeClustering1.PersistenceThreshold = 2.0\ntTKMergeTreeClustering1.ImportantPairs = 34.0\ntTKMergeTreeClustering1.MaximumNumberofImportantPairs = 3\ntTKMergeTreeClustering1.MinimumNumberofImportantPairs = 2\ntTKMergeTreeClustering1.ImportantPairsSpacing = 15.0\ntTKMergeTreeClustering1.NonImportantPairsProximity = 0.15\n\n# create a new 'Extract Block'\nnodes = ExtractBlock(Input=OutputPort(tTKMergeTreeClustering1, 1))\nnodes.Selectors = [\"/Root/Block0\"]\n\n# create a new 'Extract Block'\nnodes_1 = ExtractBlock(Input=tTKMergeTreeClustering1)\nnodes_1.Selectors = [\"/Root/Block0\"]\n\n# create a new 'Extract Block'\narcs = ExtractBlock(Input=OutputPort(tTKMergeTreeClustering1, 1))\narcs.Selectors = [\"/Root/Block1\"]\n\n# create a new 'Extract Block'\narcs_1 = ExtractBlock(Input=tTKMergeTreeClustering1)\narcs_1.Selectors = [\"/Root/Block1\"]\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator1 = TTKBlockAggregator(\n    registrationName=\"TTKBlockAggregator1\", Input=[nodes_1, nodes]\n)\n\n# create a new 'TTK FlattenMultiBlock'\ntTKFlattenMultiBlock1 = TTKFlattenMultiBlock(\n    registrationName=\"TTKFlattenMultiBlock1\", Input=tTKBlockAggregator1\n)\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator2 = TTKBlockAggregator(\n    registrationName=\"TTKBlockAggregator2\", Input=[arcs_1, arcs]\n)\n\n# create a new 'TTK FlattenMultiBlock'\ntTKFlattenMultiBlock3 = TTKFlattenMultiBlock(\n    registrationName=\"TTKFlattenMultiBlock3\", Input=tTKBlockAggregator2\n)\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator3 = TTKBlockAggregator(\n    registrationName=\"TTKBlockAggregator3\",\n    Input=[tTKFlattenMultiBlock1, tTKFlattenMultiBlock3],\n)\ntTKBlockAggregator3.FlattenInput = 0\n\n# create a new 'TTK MergeTreeDistanceMatrix'\ntTKMergeTreeDistanceMatrix2 = TTKMergeTreeDistanceMatrix(Input=tTKBlockAggregator3)\ntTKMergeTreeDistanceMatrix2.PersistenceThreshold = 2.0\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction2 = TTKDimensionReduction(\n    Input=tTKMergeTreeDistanceMatrix2, ModulePath=\"default\"\n)\ntTKDimensionReduction2.SelectFieldswithaRegexp = 1\ntTKDimensionReduction2.Regexp = \"Tree[0-9]+\"\ntTKDimensionReduction2.InputIsaDistanceMatrix = 1\ntTKDimensionReduction2.UseAllCores = 0  # MDS is unstable in parallel mode\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=tTKDimensionReduction2)\ntableToPoints1.XColumn = \"Component_0\"\ntableToPoints1.YColumn = \"Component_1\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Mask Points' (to threshold on points)\nmaskPoints1 = MaskPoints(Input=tableToPoints1)\nmaskPoints1.OnRatio = 0\nmaskPoints1.GenerateVertices = 1\nmaskPoints1.SingleVertexPerCell = 1\n\n# create a new 'Threshold'\nthreshold33 = Threshold(Input=maskPoints1)\nthreshold33.Scalars = [\"POINTS\", \"treeID\"]\nthreshold33.ThresholdMethod = \"Between\"\nthreshold33.LowerThreshold = 0.0\nthreshold33.UpperThreshold = 11.0\n\n# create a new 'Threshold'\nthreshold34 = Threshold(Input=maskPoints1)\nthreshold34.Scalars = [\"POINTS\", \"treeID\"]\nthreshold34.ThresholdMethod = \"Between\"\nthreshold34.LowerThreshold = 12.0\nthreshold34.UpperThreshold = 14.0\n\n# save the output\nSaveData(\"MDS_trees.csv\", threshold33)\nSaveData(\"MDS_centroids.csv\", threshold34)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreeClustering.py\n</code></pre></p>"},{"location":"mergeTreeClustering/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"mergeTreeClustering/#outputs","title":"Outputs","text":"<ul> <li><code>MDS_trees.vtu</code>: the output points in 2D MDS (MultiDimensional Scaling) corresponding to the input trees. The 'ClusterAssignment' array contains the clustering assignments.</li> <li><code>MDS_centroids.vtu</code>: the output points in 2D MDS (MultiDimensional Scaling) corresponding to the centroids.</li> </ul>"},{"location":"mergeTreeClustering/#cpython-api","title":"C++/Python API","text":"<p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaReader</p> <p>DimensionReduction</p> <p>FlattenMultiBlock</p> <p>MergeTree</p> <p>MergeTreeClustering</p> <p>MergeTreeDistanceMatrix</p>"},{"location":"mergeTreeExTreeM/","title":"Merge Trees via ExTreeM","text":""},{"location":"mergeTreeExTreeM/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the merge tree and the join tree from an electronic density of the Adenine-Thymine molecular complex.</p> <p>The ascending and descending segmentations needed for the computation are computed using PathCompression. They are computed by their own filter in this example, but generally, they will be computed by the MergeTree if they don't exist already.</p> <p>The python script simply computes the segmentation and saves the geometry of the join and split trees <code>.vtu</code> files.</p>"},{"location":"mergeTreeExTreeM/#paraview","title":"ParaView","text":"<p>To reproduce the example in Paraview, go to your ttk-data directory and enter the following command: <pre><code>paraview states/mergeTreeExTreeM.pvsm\n</code></pre></p>"},{"location":"mergeTreeExTreeM/#python-code","title":"Python code","text":"<pre><code># state file generated using paraview version 5.10.1\n\n# uncomment the following three lines to ensure this script works in future versions\n# import paraview\n# paraview.compatibility.major = 5\n# paraview.compatibility.minor = 10\n\n#### import the simple module from the paraview\nfrom paraview.simple import *\n\n#### disable automatic camera reset on 'Show'\n\n# create a new 'XML Image Data Reader'\natvti = XMLImageDataReader(FileName=[\"at.vti\"])\natvti.PointArrayStatus = [\"density\"]\n\n# create a new 'TTK PathCompression'\ntTKPathCompression1 = TTKPathCompression(Input=atvti)\ntTKPathCompression1.ScalarField = [\"POINTS\", \"density\"]\n\n# create a new 'TTK MergeTree'\ntTKMergeTree1 = TTKMergeTree(Input=tTKPathCompression1)\ntTKMergeTree1.ScalarField = [\"POINTS\", \"density\"]\ntTKMergeTree1.TreeType = \"Split Tree\"\ntTKMergeTree1.Backend = \"ExTreeM (IEEE TVCG 2023)\"\n\n# create a new 'TTK MergeTree'\ntTKMergeTree2 = TTKMergeTree(Input=tTKPathCompression1)\ntTKMergeTree2.ScalarField = [\"POINTS\", \"density\"]\ntTKMergeTree2.TreeType = \"Join Tree\"\ntTKMergeTree2.Backend = \"ExTreeM (IEEE TVCG 2023)\"\n\nSaveData(\"splitTree.vtu\", proxy=OutputPort(tTKMergeTree1, 1))\nSaveData(\"joinTree.vtu\", proxy=OutputPort(tTKMergeTree2, 1))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreeExTreeM.py\n</code></pre></p>"},{"location":"mergeTreeExTreeM/#inputs","title":"Inputs","text":"<ul> <li>at.vti: A molecular dataset: a three-dimensional regular grid with 1 scalar field, the electronic density in the Adenine Thymine complex.</li> </ul>"},{"location":"mergeTreeExTreeM/#outputs","title":"Outputs","text":"<ul> <li><code>joinTree.vtu</code>: the join tree.</li> <li><code>splitTree.vtu</code>: the split tree.</li> </ul>"},{"location":"mergeTreeExTreeM/#cpython-api","title":"C++/Python API","text":"<p>PathCompression</p> <p>MergeTree</p>"},{"location":"mergeTreeFeatureTracking/","title":"Merge Tree Feature Tracking","text":""},{"location":"mergeTreeFeatureTracking/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads two pairs of timesteps of an ensemble of scalar fields inside a cinema database from disk.</p> <p>Then, the MergeTree is computed on each scalar field for the Split Tree.</p> <p>These two pairs of timesteps are given respectively to two MergeTreeClustering filters to compute a distance between them.</p> <p>In terms of visualisation, the matching between the trees of the first pair and the trees of the second pair are visualized using their planar layout and their embedding in the data.</p> <p>The python script computes the matchings and saves the result (for each pair of trees).</p>"},{"location":"mergeTreeFeatureTracking/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/mergeTreeFeatureTracking.pvsm\n</code></pre></p>"},{"location":"mergeTreeFeatureTracking/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"./Isabel.cdb\")\n\n# create a new 'TTK CinemaQuery'\ntTKCinemaQuery1 = TTKCinemaQuery(InputTable=tTKCinemaReader1)\ntTKCinemaQuery1.SQLStatement = \"\"\"SELECT * FROM InputTable0\nWHERE TimeStep == 2 or TimeStep == 32\"\"\"\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaQuery1)\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM4 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM4.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKMergeandContourTreeFTM4.TreeType = \"Split Tree\"\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator1 = TTKBlockAggregator(\n    Input=[\n        tTKMergeandContourTreeFTM4,\n        OutputPort(tTKMergeandContourTreeFTM4, 1),\n        OutputPort(tTKMergeandContourTreeFTM4, 2),\n    ]\n)\ntTKBlockAggregator1.FlattenInput = 0\n\n# create a new 'TTK MergeTreeClustering'\ntTKMergeTreeClustering3 = TTKMergeTreeClustering(\n    Input=tTKBlockAggregator1, OptionalInputclustering=None\n)\ntTKMergeTreeClustering3.Deterministic = 1\ntTKMergeTreeClustering3.DimensionSpacing = 0.1\ntTKMergeTreeClustering3.DimensionToshift = \"Y\"\ntTKMergeTreeClustering3.Epsilon1 = 20.0\ntTKMergeTreeClustering3.Epsilon2 = 100.0\ntTKMergeTreeClustering3.Epsilon3 = 100.0\ntTKMergeTreeClustering3.PersistenceThreshold = 2.0\ntTKMergeTreeClustering3.ImportantPairs = 20.0\ntTKMergeTreeClustering3.ImportantPairsSpacing = 20.0\ntTKMergeTreeClustering3.NonImportantPairsProximity = 0.2\n\n# create a new 'TTK CinemaQuery'\ntTKCinemaQuery2 = TTKCinemaQuery(InputTable=tTKCinemaReader1)\ntTKCinemaQuery2.SQLStatement = \"\"\"SELECT * FROM InputTable0\nWHERE TimeStep == 32 or TimeStep == 45\"\"\"\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader2 = TTKCinemaProductReader(Input=tTKCinemaQuery2)\ntTKCinemaProductReader2.AddFieldDataRecursively = 1\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM5 = TTKMergeTree(Input=tTKCinemaProductReader2)\ntTKMergeandContourTreeFTM5.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKMergeandContourTreeFTM5.TreeType = \"Split Tree\"\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator2 = TTKBlockAggregator(\n    Input=[\n        tTKMergeandContourTreeFTM5,\n        OutputPort(tTKMergeandContourTreeFTM5, 1),\n        OutputPort(tTKMergeandContourTreeFTM5, 2),\n    ]\n)\ntTKBlockAggregator2.FlattenInput = 0\n\n# create a new 'TTK MergeTreeClustering'\ntTKMergeTreeClustering4 = TTKMergeTreeClustering(\n    Input=tTKBlockAggregator2, OptionalInputclustering=None\n)\ntTKMergeTreeClustering4.Deterministic = 1\ntTKMergeTreeClustering4.DimensionSpacing = 0.1\ntTKMergeTreeClustering4.DimensionToshift = \"Y\"\ntTKMergeTreeClustering4.PersistenceThreshold = 2.0\ntTKMergeTreeClustering4.ImportantPairs = 23.0\ntTKMergeTreeClustering4.ImportantPairsSpacing = 20.0\ntTKMergeTreeClustering4.NonImportantPairsProximity = 0.2\n\n# save the output\nSaveData(\"matching_T2_T32.vtm\", OutputPort(tTKMergeTreeClustering3, 2))\nSaveData(\"matching_T32_T45.vtm\", OutputPort(tTKMergeTreeClustering4, 2))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreeFeatureTracking.py\n</code></pre></p>"},{"location":"mergeTreeFeatureTracking/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"mergeTreeFeatureTracking/#outputs","title":"Outputs","text":"<ul> <li><code>matching_T2_T32.vtm</code>: the output matching between timestep 2 and 32.</li> <li><code>matching_T32_T45.vtm</code>: the output matching between timestep 32 and 45.</li> </ul>"},{"location":"mergeTreeFeatureTracking/#cpython-api","title":"C++/Python API","text":"<p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaQuery</p> <p>CinemaReader</p> <p>MergeTree</p> <p>MergeTreeClustering</p>"},{"location":"mergeTreePGA/","title":"Merge Tree Principal Geodesic Analysis","text":""},{"location":"mergeTreePGA/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the MergeTree is computed on each scalar field to compute the Split Tree.</p> <p>All these trees are passed to MergeTreePrincipalGeodesics to compute principal geodesic analysis in the metric space of merge trees. </p> <p>Then the filter MergeTreePrincipalGeodesicsDecoding is used to reconstruct the input trees, to sample evenly trees along the principal geodesics and to sample a discrete grid of merge trees of the PGA basis.</p> <p>A distance matrix is then computed with MergeTreeDistanceMatrix with the trees of the grid. This distance matrix is used as input of DimensionReduction to compute a MultiDimensional Scaling (MDS), performing a dimensionality reduction in 3D (and 2D with a second DimensionReduction filter) respecting the most the input distance matrix. </p> <p>Finally the PointSetToSurface and ProjectionFromTable are used to create the 3D surface (and the 2D surface). The ProjectionFromTable allows to project the points (reconstructed trees, geodesic trees etc.) to the 3D (or 2D) surface.</p> <p>In terms of visualisation, a scalar field of each cluster is displayed with a zoom on their right of the important persistence pairs. The original trees are displayed alongside their reconstruction at their right. The persistence pairs of the trees are colored by ID to see what features they correspond to in the scalar field.</p> <p>The 3D and 2D surface are displayed with the persistence correlation view at the top right. The 12 scalar fields are colored by Cluster ID. Finally, a path drawn with PolyLineSource on the surface is drawn at the bottom right to show how we can interactivily explore the MT-PGA basis in user-defined locations.</p> <p>The python script computes the MT-PGA basis. It saves the resulting coefficients of the input trees and the geodesics of the basis. Finally it saves the reconstructed trees given the basis and the coordinates of the trees in the basis.</p>"},{"location":"mergeTreePGA/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/mergeTreePGA.pvsm\n</code></pre></p>"},{"location":"mergeTreePGA/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"./Earthquake.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\ntTKCinemaProductReader1.AddFieldDataRecursively = 1\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM1 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM1.ScalarField = [\"POINTS\", \"VectorMag\"]\ntTKMergeandContourTreeFTM1.TreeType = \"Split Tree\"\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator1 = TTKBlockAggregator(\n    Input=[\n        tTKMergeandContourTreeFTM1,\n        OutputPort(tTKMergeandContourTreeFTM1, 1),\n        OutputPort(tTKMergeandContourTreeFTM1, 2),\n    ]\n)\ntTKBlockAggregator1.FlattenInput = 0\n\n# create a new 'TTK MergeTreePrincipalGeodesics'\ntTKMergeTreePrincipalGeodesics1 = TTKMergeTreePrincipalGeodesics(\n    Input=tTKBlockAggregator1, OptionalInput=None\n)\ntTKMergeTreePrincipalGeodesics1.BarycenterSizeLimitPercent = 17.0\ntTKMergeTreePrincipalGeodesics1.Deterministic = 1\ntTKMergeTreePrincipalGeodesics1.Epsilon1 = 1.5\ntTKMergeTreePrincipalGeodesics1.Epsilon2 = 35.0\ntTKMergeTreePrincipalGeodesics1.Epsilon3 = 34.0\ntTKMergeTreePrincipalGeodesics1.PersistenceThreshold = 1.0\ntTKMergeTreePrincipalGeodesics1.DeleteMultiPersistencePairs = 1\n\n# create a new 'TTK MergeTreePrincipalGeodesicsDecoding'\ntTKMergeTreePrincipalGeodesicsDecoding1 = TTKMergeTreePrincipalGeodesicsDecoding(\n    Barycenter=tTKMergeTreePrincipalGeodesics1,\n    Coefficients=OutputPort(tTKMergeTreePrincipalGeodesics1, 1),\n    GeodesicsVectors=OutputPort(tTKMergeTreePrincipalGeodesics1, 2),\n    CorrelationMatrixoptional=None,\n    InputTreesoptional=None,\n)\n\n# save the output\nSaveData(\"MT-PGA_coef.csv\", OutputPort(tTKMergeTreePrincipalGeodesics1, 1))\nSaveData(\"MT-PGA_geodesics.csv\", OutputPort(tTKMergeTreePrincipalGeodesics1, 2))\nSaveData(\"MT-PGA_reconstructed_trees.vtm\", tTKMergeTreePrincipalGeodesicsDecoding1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreePGA.py\n</code></pre></p>"},{"location":"mergeTreePGA/#inputs","title":"Inputs","text":"<ul> <li>Earthquake.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"mergeTreePGA/#outputs","title":"Outputs","text":"<ul> <li><code>MT-PGA_coef.csv</code>: the coefficients of the input trees corresponding to their coordinates in the PGA basis.</li> <li><code>MT-PGA_geodesics.csv</code>: the geodesics of the PGA basis.</li> <li><code>MT-PGA_reconstructed_trees.vtm</code>: the reconstructed input trees.</li> </ul>"},{"location":"mergeTreePGA/#cpython-api","title":"C++/Python API","text":"<p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaReader</p> <p>DataSetToTable</p> <p>DimensionReduction</p> <p>FlattenMultiBlock</p> <p>MergeTree</p> <p>GeometrySmoother</p> <p>MergeBockTables</p> <p>MergeTreeClustering</p> <p>MergeTreeDistanceMatrix</p> <p>MergeTreePrincipalGeodesics</p> <p>MergeTreePrincipalGeodesicsDecoding</p> <p>PointSetToCurve</p> <p>PointSetToSurface</p> <p>ProjectionFromTable</p>"},{"location":"mergeTreeTemporalReduction/","title":"Merge Tree Temporal Reduction","text":""},{"location":"mergeTreeTemporalReduction/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the MergeTree is computed on each scalar field.</p> <p>All these trees are passed to MergeTreeTemporalReduction to compute a subsampling of a sequence of merge trees. The algorithm greedily removes trees in the sequence that can be accurately reconstructed by the geodesic computation. The remaining trees are called the key frames.</p> <p>In terms of visualisation, the three key frames trees and two reconstructed trees are visualized with a planar layout along with their corresponding scalar fields.</p> <p>The python script saves the information needed to reconstruct the trees removed in the sequence.</p>"},{"location":"mergeTreeTemporalReduction/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/mergeTreeTemporalReduction.pvsm\n</code></pre></p>"},{"location":"mergeTreeTemporalReduction/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"./Isabel.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\ntTKCinemaProductReader1.AddFieldDataRecursively = 1\n\n# create a new 'TTK Merge and Contour Tree (FTM)'\ntTKMergeandContourTreeFTM26 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM26.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKMergeandContourTreeFTM26.TreeType = \"Split Tree\"\n\n# create a new 'Group Datasets'\nall_MT = GroupDatasets(\n    Input=[\n        tTKMergeandContourTreeFTM26,\n        OutputPort(tTKMergeandContourTreeFTM26, 1),\n        OutputPort(tTKMergeandContourTreeFTM26, 2),\n    ]\n)\n\n# create a new 'TTK MergeTreeTemporalReduction'\ntTKMergeTreeTemporalReduction1 = TTKMergeTreeTemporalReduction(Input=all_MT)\ntTKMergeTreeTemporalReduction1.RemovalPercentage = 75.0\ntTKMergeTreeTemporalReduction1.Epsilon1 = 0.0\ntTKMergeTreeTemporalReduction1.Epsilon2 = 100.0\ntTKMergeTreeTemporalReduction1.Epsilon3 = 100.0\ntTKMergeTreeTemporalReduction1.PersistenceThreshold = 3.0\n\nSaveData(\"ReductionCoefficients.csv\", OutputPort(tTKMergeTreeTemporalReduction1, 1))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreeTemporalReduction.py\n</code></pre></p>"},{"location":"mergeTreeTemporalReduction/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"mergeTreeTemporalReduction/#outputs","title":"Outputs","text":"<ul> <li><code>ReductionCoefficients.csv</code>: a table containing information needed to reconstruct removed trees. For each removed tree we have the id of the two key frames needed to reconstruct it ('Index1' and 'Index2'), along with the interpolation parameter ('Alpha').</li> </ul>"},{"location":"mergeTreeTemporalReduction/#cpython-api","title":"C++/Python API","text":"<p>CinemaProductReader</p> <p>CinemaReader</p> <p>MergeTree</p> <p>MergeTreeTemporalReduction</p>"},{"location":"mergeTreeWAE/","title":"Merge Tree Wasserstein Auto-Encoder","text":""},{"location":"mergeTreeWAE/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the MergeTree is computed on each scalar field to compute the Split Tree.</p> <p>All these trees are passed to MergeTreeAutoencoder to compute a wasserstein auto-encoding in the metric space of merge trees. </p> <p>Then the filter MergeTreeAutoencoderDecoding is used to reconstruct the input merge trees. </p> <p>In terms of visualization, a scalar field is displayed for each cluster, with a zoom on their right of the important persistence pairs. The original merge trees are displayed alongside their reconstruction at their right. The persistence pairs of the trees are colored by ID to see what features they correspond to in the scalar field.</p> <p>The 2D planar layout is displayed with the persistence correlation view at the top right. The 12 scalar fields are colored by Cluster ID. Finally, a path drawn with PolyLineSource on the layout is drawn at the bottom right to show how we can interactivily explore the MT-WAE latent space with user-defined locations.</p> <p>The python script computes the MT-WAE basis. This computation is not deterministic and it may take several minutes (depending on your hardware). It saves the resulting coefficients of the input merge trees and the axes of the bases and their origins. Finally it saves the reconstructed merge trees given the bases and the coordinates of the merge trees in the basis.</p>"},{"location":"mergeTreeWAE/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/mergeTreeWAEDecoding.pvsm\n</code></pre></p> <p>To reproduce the above analysis pipeline as well as the (non-deterministic) training procedure, go to your ttk-data directory and enter the following command (the computation will take several minutes, depending on your hardware): <pre><code>paraview states/mergeTreeWAE.pvsm\n</code></pre></p>"},{"location":"mergeTreeWAE/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"./Earthquake.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\ntTKCinemaProductReader1.AddFieldDataRecursively = 1\n\n# create a new 'TTK Merge and Contour Tree'\ntTKMergeandContourTreeFTM1 = TTKMergeTree(Input=tTKCinemaProductReader1)\ntTKMergeandContourTreeFTM1.ScalarField = [\"POINTS\", \"VectorMag\"]\ntTKMergeandContourTreeFTM1.TreeType = \"Split Tree\"\ntTKMergeandContourTreeFTM1.UseAllCores = 0\n\n# create a new 'TTK BlockAggregator'\ntTKBlockAggregator1 = TTKBlockAggregator(\n    Input=[\n        tTKMergeandContourTreeFTM1,\n        OutputPort(tTKMergeandContourTreeFTM1, 1),\n    ]\n)\ntTKBlockAggregator1.FlattenInput = 0\n\n# create a new 'TTK MergeTreeAutoencoder'\ntTKMergeTreeAutoencoder1 = TTKMergeTreeAutoencoder(\n    Input=tTKBlockAggregator1, OptionalInput=None, Info=tTKCinemaReader1\n)\ntTKMergeTreeAutoencoder1.ScaleLayerAfterLatent = 1\ntTKMergeTreeAutoencoder1.InputOriginPrimeSizePercent = 7.0\ntTKMergeTreeAutoencoder1.LatentSpaceOriginPrimeSizePercent = 1.0\ntTKMergeTreeAutoencoder1.MinIteration = 300\ntTKMergeTreeAutoencoder1.MaxIteration = 1000\ntTKMergeTreeAutoencoder1.GradientStepSize = 0.0005\ntTKMergeTreeAutoencoder1.TrackingLossWeight = 1e-06\ntTKMergeTreeAutoencoder1.ClusteringLossWeight = 0.02\ntTKMergeTreeAutoencoder1.ClusteringArrayName = \"ClusterID\"\ntTKMergeTreeAutoencoder1.PairTypeMixtureCoefficient = 0.0\ntTKMergeTreeAutoencoder1.DeleteMultiPersistencePairs = 1\ntTKMergeTreeAutoencoder1.Epsilon1 = 0.5\ntTKMergeTreeAutoencoder1.Epsilon2 = 35.0\ntTKMergeTreeAutoencoder1.Epsilon3 = 34.0\ntTKMergeTreeAutoencoder1.PersistenceThreshold = 2.0\n\n# create a new 'TTK MergeTreeAutoencoderDecoding'\ntTKMergeTreeAutoencoderDecoding1 = TTKMergeTreeAutoencoderDecoding(\n    Origins=OutputPort(tTKMergeTreeAutoencoder1, 0),\n    BasesVectors=OutputPort(tTKMergeTreeAutoencoder1, 1),\n    Coefficients=OutputPort(tTKMergeTreeAutoencoder1, 2),\n)\n\n# save the output\nSaveData(\"MT-WAE_processed_diagrams.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 0))\nSaveData(\"MT-WAE_origins.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 1))\nSaveData(\"MT-WAE_axes.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 2))\nSaveData(\"MT-WAE_coef.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 3))\nSaveData(\"MT-WAE_reconstructed_diagrams.vtm\", tTKMergeTreeAutoencoderDecoding1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/mergeTreeWAE.py\n</code></pre></p>"},{"location":"mergeTreeWAE/#inputs","title":"Inputs","text":"<ul> <li>Earthquake.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"mergeTreeWAE/#outputs","title":"Outputs","text":"<ul> <li><code>MT-WAE_processed_diagrams.vtm</code>: the processed input merge trees.</li> <li><code>MT-WAE_origins.vtm</code>: the origins of each basis.</li> <li><code>MT-WAE_axes.vtm</code>: the axes of each basis.</li> <li><code>MT-WAE_coef.vtm</code>: the coefficients of the input merge trees corresponding to their coordinates in each basis.</li> <li><code>MT-WAE_reconstructed_diagrams.vtm</code>: the reconstructed input merge trees.</li> </ul>"},{"location":"mergeTreeWAE/#cpython-api","title":"C++/Python API","text":"<p>ArrayEditor</p> <p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaReader</p> <p>DataSetToTable</p> <p>FlattenMultiBlock</p> <p>IcospheresFromPoints</p> <p>MergeTree</p> <p>GeometrySmoother</p> <p>MergeTreeClustering</p> <p>MergeTreeAutoencoder</p> <p>MergeTreeAutoencoderDecoding</p>"},{"location":"morseMolecule/","title":"Morse molecule","text":""},{"location":"morseMolecule/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a VTI file on the disk. The VTI file contains three scalar fields namely <code>Rho</code>, <code>log(Rho)</code>, and <code>log(s)</code>. We are interested in topological analysis of the <code>log(Rho)</code> scalar field which corresponds to the electron density distribution around a simple molecule. </p> <p>The MorseSmaleComplex is computed for this scalar field. The reason for computing Morse-Smale complex is that many chemically relevant concepts, for example, covalent bonds can be directly translated to topological structures computed using the Morse-Smale complex. The critical points of this scalar field also have chemical relevance. The maxima correspond to the atom locations and 2-saddles occur along chemical bonds. </p> <p>Then the critical points are then converted into spheres using IcospheresFromPoints. The maxima are selected and highlighted as bigger spheres. </p> <p>Then using appropriate filtering, the 1-separatrices corresponding to the covalent bonds are selected. The criteria used is to select the 1-sepatrices which have no critical points on the boundary and for which <code>SeparatrixType = 2</code>, that is they connect a 2-saddle to a maximum. Also, GeometrySmoother is used to make the jagged lines generated by the Morse-Smale complex a little smoother. Then, another type of 1-separatrix is extracted which connects a 2-saddle on a covalent bond to its neighbouring 1-saddles on the boundary.</p> <p>Lastly, 2-separatrices incident on the covalent bonds (of <code>SeparatrixType = 1</code>) are extracted which correspond to separating walls between adjacent atoms. Another type (<code>SeparatrixType = 2</code>) of separating wall is also extracted.</p>"},{"location":"morseMolecule/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/morseMolecule.pvsm\n</code></pre></p>"},{"location":"morseMolecule/#python-code","title":"Python code","text":"<pre><code>from paraview.simple import *\n\n# create a new 'XML Image Data Reader'\nbuiltInExamplevti = XMLImageDataReader(FileName=[\"BuiltInExample2.vti\"])\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=builtInExamplevti)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"log(Rho)\"]\ntTKMorseSmaleComplex1.Ascending2Separatrices = 1\ntTKMorseSmaleComplex1.Descending2Separatrices = 1\n\n# Generate spheres for the critical points using 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints1 = TTKIcospheresFromPoints(Input=tTKMorseSmaleComplex1)\ntTKIcospheresFromPoints1.Radius = 1.5\n\n# Generate bigger spheres for the critical points using 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints2 = TTKIcospheresFromPoints(Input=tTKMorseSmaleComplex1)\ntTKIcospheresFromPoints2.Radius = 3.0\n\n# Then select critical points of CellDimension 3 using 'Threshold' to select maxima\nthreshold3 = Threshold(Input=tTKIcospheresFromPoints2)\nthreshold3.Scalars = [\"POINTS\", \"CellDimension\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 3.0\nthreshold3.UpperThreshold = 3.0\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 1))\nthreshold1.Scalars = [\"CELLS\", \"NumberOfCriticalPointsOnBoundary\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.0\nthreshold1.UpperThreshold = 0.0\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=threshold1)\nthreshold2.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = 2.0\nthreshold2.UpperThreshold = 2.0\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother1 = TTKGeometrySmoother(Input=threshold2)\ntTKGeometrySmoother1.IterationNumber = 50\n\n# create a new 'Clean to Grid'\ncleantoGrid1 = CleantoGrid(Input=tTKGeometrySmoother1)\n\n# create a new 'Extract Surface'\nextractSurface1 = ExtractSurface(Input=cleantoGrid1)\n\n# create a new 'Tube'\ntube1 = Tube(Input=extractSurface1)\ntube1.Scalars = [\"POINTS\", \"CellDimension\"]\ntube1.Radius = 1.25\n\n# create a new 'Threshold'\nthreshold8 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 1))\nthreshold8.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold8.ThresholdMethod = \"Between\"\nthreshold8.LowerThreshold = 1.0\nthreshold8.UpperThreshold = 1.0\n\n# create a new 'Threshold'\nthreshold9 = Threshold(Input=threshold8)\nthreshold9.Scalars = [\"CELLS\", \"NumberOfCriticalPointsOnBoundary\"]\nthreshold9.ThresholdMethod = \"Between\"\nthreshold9.LowerThreshold = 1.0\nthreshold9.UpperThreshold = 1.0\n\n# create a new 'Threshold'\nthreshold11 = Threshold(Input=threshold9)\nthreshold11.Scalars = [\"CELLS\", \"SeparatrixId\"]\nthreshold11.ThresholdMethod = \"Between\"\nthreshold11.LowerThreshold = 75.0\nthreshold11.UpperThreshold = 76.0\n\n# create a new 'Threshold'\nthreshold10 = Threshold(Input=threshold9)\nthreshold10.Scalars = [\"CELLS\", \"SeparatrixId\"]\nthreshold10.ThresholdMethod = \"Between\"\nthreshold10.LowerThreshold = 73.0\nthreshold10.UpperThreshold = 74.0\n\n# create a new 'Append Datasets'\nappendDatasets1 = AppendDatasets(Input=[threshold10, threshold11])\n\n# create a new 'Clean to Grid'\ncleantoGrid4 = CleantoGrid(Input=appendDatasets1)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother4 = TTKGeometrySmoother(Input=cleantoGrid4)\ntTKGeometrySmoother4.IterationNumber = 10\n\n# create a new 'Extract Surface'\nextractSurface3 = ExtractSurface(Input=tTKGeometrySmoother4)\n\n# create a new 'Tube'\ntube2 = Tube(Input=extractSurface3)\ntube2.Scalars = [\"POINTS\", \"CellDimension\"]\ntube2.Radius = 0.75\n\n# create a new 'Threshold'\nthreshold4 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 2))\nthreshold4.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold4.ThresholdMethod = \"Between\"\nthreshold4.LowerThreshold = 1.0\nthreshold4.UpperThreshold = 1.0\n\n# create a new 'Clean to Grid'\ncleantoGrid2 = CleantoGrid(Input=threshold4)\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=cleantoGrid2)\n\n# create a new 'Extract Surface'\nextractSurface2 = ExtractSurface(Input=tetrahedralize1)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother2 = TTKGeometrySmoother(Input=extractSurface2)\ntTKGeometrySmoother2.IterationNumber = 20\n\n# select 2-separatrices using 'Threshold'\nthreshold5 = Threshold(Input=OutputPort(tTKMorseSmaleComplex1, 2))\nthreshold5.Scalars = [\"CELLS\", \"SeparatrixType\"]\nthreshold5.ThresholdMethod = \"Between\"\nthreshold5.LowerThreshold = 2.0\nthreshold5.UpperThreshold = 2.0\n\n# create a new 'Threshold'\nthreshold6 = Threshold(Input=threshold5)\nthreshold6.Scalars = [\"CELLS\", \"NumberOfCriticalPointsOnBoundary\"]\nthreshold6.ThresholdMethod = \"Between\"\nthreshold6.LowerThreshold = 4.0\nthreshold6.UpperThreshold = 4.0\n\n# select a particular 2-separatrix using 'Threshold'\nthreshold7 = Threshold(Input=threshold6)\nthreshold7.Scalars = [\"CELLS\", \"SeparatrixId\"]\nthreshold7.ThresholdMethod = \"Between\"\nthreshold7.LowerThreshold = 2.0\nthreshold7.UpperThreshold = 2.0\n\n# create a new 'Clean to Grid'\ncleantoGrid3 = CleantoGrid(Input=threshold7)\n\n# create a new 'Tetrahedralize'\ntetrahedralize2 = Tetrahedralize(Input=cleantoGrid3)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother3 = TTKGeometrySmoother(Input=tetrahedralize2)\ntTKGeometrySmoother3.IterationNumber = 20\n\n# save the output\nSaveData(\"CriticalPoints.vtp\", tTKIcospheresFromPoints1)\nSaveData(\"Maxima.vtu\", threshold3)\nSaveData(\"CovalentBonds.vtp\", tube1)\nSaveData(\"Selected2saddle1saddleConnectors.vtp\", tube2)\nSaveData(\"CovalentBondSeparatrixWalls.vtp\", tTKGeometrySmoother2)\nSaveData(\"SelectedType2SeparatrixWall.vtu\", tTKGeometrySmoother3)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/morseMolecule.py\n</code></pre></p>"},{"location":"morseMolecule/#inputs","title":"Inputs","text":"<ul> <li>BuiltInExample2.vti: 3D scalar field corresponding to electron density distribution around a simple molecule.</li> </ul>"},{"location":"morseMolecule/#outputs","title":"Outputs","text":"<ul> <li><code>CriticalPoints.vtp</code>: All the output critical points in VTK file format (small spheres in the above screenshot). </li> <li><code>Maxima.vtu</code>: The computed maxima which also correspond to atom locations in VTK file format (bigger green spheres).</li> <li><code>CovalentBonds.vtp</code>: Selected 1-separatrices corresponding to the covalent bonds in the molecule (the thick white tubes)</li> <li><code>Selected2saddle1saddleConnectors.vtp</code>: Geometry of selected separatrices connecting a 2-saddle on a covalent bond to its neighbouring 1-saddles (the dark grey tubes in the screenshot above). </li> <li><code>CovalentBondSeparatrixWalls.vtp</code>: Surface corresponding to 2-separatrices (walls) incident on the covalent bonds (the translucent blue surfaces in the above screenshot)</li> <li><code>SelectedType2SeparatrixWall.vtu</code>: Surface corresponding to another type of wall (the green surface).</li> </ul> <p>Note that you are free to change the VTK file extensions to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</p>"},{"location":"morseMolecule/#cpython-api","title":"C++/Python API","text":"<p>GeometrySmoother</p> <p>IcospheresFromPoints</p> <p>MorseSmaleComplex</p>"},{"location":"morsePersistence/","title":"Morse persistence","text":""},{"location":"morsePersistence/#pipeline-description","title":"Pipeline description","text":"<p>The first step is to create the data for our example. A plane is created to which we add random scalar values to create noise. The obtained scalar field is smoothed using the ScalarFieldSmoother. A sum of sine as scalar values is also added to create the nine main hills.</p> <p>Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (bottom right view in the above screenshot).</p> <p>The PersistenceCurve is also computed (top right view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of MorseSmaleComplex (center view, above screenshot). This complex is composed of elements of 3 dimensions: dimension 0, which corresponds to the critical points of the Morse-Smale Complex, dimension 1, which corresponds to its edges (in grey in the screenshot) and dimension 2, which corresponds to its surfaces.</p>"},{"location":"morsePersistence/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your <code>ttk-data</code>  directory and enter the following command: <pre><code>paraview states/morsePersistence.pvsm\n</code></pre></p>"},{"location":"morsePersistence/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'Plane'\nplane1 = Plane()\nplane1.XResolution = 300\nplane1.YResolution = 300\n\n# create a new 'Tetrahedralize'\ntetrahedralize2 = Tetrahedralize(Input=plane1)\n\n# create a new 'Random Attributes'\nrandomAttributes1 = RandomAttributes(Input=tetrahedralize2)\nrandomAttributes1.DataType = \"Float\"\nrandomAttributes1.ComponentRange = [0.0, 1.0]\nrandomAttributes1.GeneratePointScalars = 1\n\n# create a new 'TTK ScalarFieldSmoother'\ntTKScalarFieldSmoother1 = TTKScalarFieldSmoother(Input=randomAttributes1)\ntTKScalarFieldSmoother1.ScalarField = [\"POINTS\", \"RandomPointScalars\"]\ntTKScalarFieldSmoother1.IterationNumber = 7\n\n# create a new 'Calculator'\nsine = Calculator(Input=tTKScalarFieldSmoother1)\nsine.ResultArrayName = \"Sine\"\nsine.Function = \"sin(20*coordsX+1.5)+sin(20*coordsY+1.5)\"\n\n# create a new 'Calculator'\ndistanceField = Calculator(Input=sine)\ndistanceField.ResultArrayName = \"DistanceField\"\ndistanceField.Function = \"-sqrt(coordsX*coordsX+coordsY*coordsY)\"\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=distanceField)\ncalculator1.ResultArrayName = \"Blend\"\ncalculator1.Function = \"Sine+5*DistanceField+5*RandomPointScalars\"\n\n# create a new 'Extract Surface'\nextractSurface6 = ExtractSurface(Input=calculator1)\n\n# create a new 'Warp By Scalar'\nwarpByScalar1 = WarpByScalar(Input=extractSurface6)\nwarpByScalar1.Scalars = [\"POINTS\", \"Blend\"]\nwarpByScalar1.ScaleFactor = 0.05\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=warpByScalar1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"Blend\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'TTK PersistenceCurve'\ntTKPersistenceCurve1 = TTKPersistenceCurve(Input=tTKPersistenceDiagram1)\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.0\nthreshold1.UpperThreshold = 100000.0\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 0.7\npersistenceThreshold.UpperThreshold = 10000.0\n\n# create a new 'Tetrehedralize'\ntetrahedralize1 = Tetrahedralize(Input=warpByScalar1)\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=tetrahedralize1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"Blend\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"Blend\"]\n\n# save the ouput\nSaveData(\"PersistenceDiagram.vtu\", tTKPersistenceDiagram1)\nSaveData(\"PersistenceCurve.csv\", OutputPort(tTKPersistenceCurve1, 3))\nSaveData(\"MorseComplexeCriticalPoints.vtp\", OutputPort(tTKMorseSmaleComplex1, 0))\nSaveData(\"MorseComplexe1Separatrices.vtp\", OutputPort(tTKMorseSmaleComplex1, 1))\nSaveData(\"MorseComplexeSegmentation.vtu\", OutputPort(tTKMorseSmaleComplex1, 3))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/morsePersistence.py\n</code></pre></p>"},{"location":"morsePersistence/#inputs","title":"Inputs","text":"<ul> <li>None</li> </ul>"},{"location":"morsePersistence/#outputs","title":"Outputs","text":"<ul> <li><code>PersistenceDiagram.vtu</code>: the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>PersistenceCurve.csv</code>: the output persistence curve.</li> <li><code>MorseComplexeCriticalPoints.vtp</code>: the output critical points (or 0 dimensional elements) of the Morse Smale Complex in VTK file format (center view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>MorseComplexe1Separatrices.vtp</code>: cylinders, representing the edges (or 1 dimensional elements) of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>MorseComplexeSegmentation.vtp</code>: surfaces, representing the segmentation  of the output Morse Smale Complexe in VTK file format (center view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> </ul>"},{"location":"morsePersistence/#cpython-api","title":"C++/Python API","text":"<p>MorseSmaleComplex</p> <p>PersistenceCurve</p> <p>PersistenceDiagram</p> <p>ScalarFieldSmoother</p> <p>TopologicalSimplification</p>"},{"location":"morseSmaleQuadrangulation/","title":"Morse-Smale Quadrangulation","text":""},{"location":"morseSmaleQuadrangulation/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads a mecanical model as a 2D triangle mesh from disk. This mechanical model embeds a collection of scalar fields that corresponds to the output of the EigenField module. This module generated a family of functions that are coupled to the form of the dataset (basically, they are eigenfunctions of the laplacian matrix of the triangulation, sorted by decreasing eigenvalue magnitude).</p> <p>In a pre-processing step, the 83rd EigenFunction is extracted and normalized with ScalarFieldNormalizer then simplified using PersistenceDiagram and TopologicalSimplification.</p> <p>We then compute the MorseSmaleComplex of the simplified scalar field. The critical points are evenly spread onto the 2D surface and the 1-separatrices will form the base of the quadrangulation (left view on the above screenshot).</p> <p>The filter MorseSmaleQuadrangulation creates a coarse quadrangulation of the input mesh using the Morse-Smale complex critical points and 1-separatrices.</p> <p>This coarse quadrangulation is eventually refined with the QuadrangulationSubdivision filter (right view on the above screenshot).</p>"},{"location":"morseSmaleQuadrangulation/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/morseSmaleQuadrangulation.pvsm\n</code></pre></p>"},{"location":"morseSmaleQuadrangulation/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nrockerArmvtu = XMLUnstructuredGridReader(FileName=[\"rockerArm.vtu\"])\n\n# create a new 'Extract Component'\nextractComponent1 = ExtractComponent(Input=rockerArmvtu)\nextractComponent1.InputArray = [\"POINTS\", \"OutputEigenFunctions\"]\nextractComponent1.Component = 83\n\n# create a new 'TTK ScalarFieldNormalizer'\ntTKScalarFieldNormalizer1 = TTKScalarFieldNormalizer(Input=extractComponent1)\ntTKScalarFieldNormalizer1.ScalarField = [\"POINTS\", \"Result\"]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=tTKScalarFieldNormalizer1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"Result\"]\ntTKPersistenceDiagram1.EmbedinDomain = 1\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"Persistence\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 0.001\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=tTKScalarFieldNormalizer1, Constraints=threshold1\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"Result\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"Result\"]\n\n# create a new 'TTK MorseSmaleQuadrangulation'\ntTKMorseSmaleQuadrangulation1 = TTKMorseSmaleQuadrangulation(\n    Triangulatedsurface=OutputPort(tTKMorseSmaleComplex1, 3),\n    MorseSmalecriticalpoints=tTKMorseSmaleComplex1,\n    MorseSmale1separatrices=OutputPort(tTKMorseSmaleComplex1, 1),\n)\ntTKMorseSmaleQuadrangulation1.DualQuadrangulation = 1\n\n# create a new 'TTK QuadrangulationSubdivision'\ntTKQuadrangulationSubdivision1 = TTKQuadrangulationSubdivision(\n    Triangulatedsurface=OutputPort(tTKMorseSmaleComplex1, 3),\n    Coarsequadrangulation=tTKMorseSmaleQuadrangulation1,\n)\ntTKQuadrangulationSubdivision1.Levelofsubdivisions = 3\ntTKQuadrangulationSubdivision1.Numberofrelaxationiterations = 100\n\n# save the output\nSaveData(\"Quadrangulation.vtp\", tTKQuadrangulationSubdivision1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/morseSmaleQuadrangulation.py\n</code></pre></p>"},{"location":"morseSmaleQuadrangulation/#inputs","title":"Inputs","text":"<ul> <li>rockerArm.vtu: a two-dimensional triangulated mechanical model.</li> </ul>"},{"location":"morseSmaleQuadrangulation/#outputs","title":"Outputs","text":"<ul> <li><code>Quadrangulation.vtp</code>: the output quadrangulated surface.</li> </ul>"},{"location":"morseSmaleQuadrangulation/#cpython-api","title":"C++/Python API","text":"<p>EigenField</p> <p>MorseSmaleComplex</p> <p>MorseSmaleQuadrangulation</p> <p>PersistenceDiagram</p> <p>QuadrangulationSubdivision</p> <p>ScalarFieldNormalizer</p> <p>TopologicalSimplification</p>"},{"location":"morseSmaleSegmentation_at/","title":"Morse-Smale Segmentation AT","text":""},{"location":"morseSmaleSegmentation_at/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the ascending and descending Morse segmentations from an electronic density of the Adenine-Thymine molecular complex. The descending segmentation separators (red) represent the influence areas of maxima, giving each atom its own pocket since they are the most dense points in the dataset. The ascending segmentation separators (blue) represent the influence area of minima, providing the interactions (covalent and non-covalent) between the atoms in this example.</p> <p>The segmentations are computed using PathCompression. The separating geometry is generated using MarchingTetrahedra</p> <p>The python script simply computes the segmentation and saves the separating surfaces as <code>.vtu</code> files.</p>"},{"location":"morseSmaleSegmentation_at/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/morseSmaleSegmentation_at.pvsm\n</code></pre></p>"},{"location":"morseSmaleSegmentation_at/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\natvti = XMLImageDataReader(FileName=[\"at.vti\"])\n\n# create a new 'Calculator'\ncalculator1 = Calculator(registrationName=\"Calculator1\", Input=atvti)\ncalculator1.ResultArrayName = \"negdensity\"\ncalculator1.Function = \"-density\"\n\n# create a new 'TTK PathCompression'\ntTKPathCompression1 = TTKPathCompression(\n    registrationName=\"TTKPathCompression1\", Input=calculator1\n)\ntTKPathCompression1.ScalarField = [\"POINTS\", \"negdensity\"]\n\n# create a new 'TTK MarchingTetrahedra'\ntTKMarchingTetrahedra1 = TTKMarchingTetrahedra(\n    registrationName=\"TTKMarchingTetrahedra1\", Input=tTKPathCompression1\n)\ntTKMarchingTetrahedra1.ScalarField = [\"POINTS\", \"negdensity_DescendingManifold\"]\n\n# create a new 'Clean to Grid'\ncleantoGrid1 = CleantoGrid(\n    registrationName=\"CleantoGrid1\", Input=tTKMarchingTetrahedra1\n)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother1 = TTKGeometrySmoother(\n    registrationName=\"TTKGeometrySmoother1\", Input=cleantoGrid1\n)\ntTKGeometrySmoother1.IterationNumber = 20\n\n# create a new 'TTK MarchingTetrahedra'\ntTKMarchingTetrahedra2 = TTKMarchingTetrahedra(\n    registrationName=\"TTKMarchingTetrahedra2\", Input=tTKPathCompression1\n)\ntTKMarchingTetrahedra2.ScalarField = [\"POINTS\", \"negdensity_AscendingManifold\"]\n\n# create a new 'Clean to Grid'\ncleantoGrid2 = CleantoGrid(\n    registrationName=\"CleantoGrid2\", Input=tTKMarchingTetrahedra2\n)\n\n# create a new 'TTK GeometrySmoother'\ntTKGeometrySmoother2 = TTKGeometrySmoother(\n    registrationName=\"TTKGeometrySmoother2\", Input=cleantoGrid2\n)\ntTKGeometrySmoother2.IterationNumber = 20\n\nSaveData(\"descendingSeparatorAt.vtu\", tTKGeometrySmoother1)\nSaveData(\"ascendingSeparatorAt.vtu\", tTKGeometrySmoother2)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/morseSmaleSegmentation_at.py\n</code></pre></p>"},{"location":"morseSmaleSegmentation_at/#inputs","title":"Inputs","text":"<ul> <li>at.vti: A molecular dataset: a three-dimensional regular grid with 1 scalar field, the electronic density in the Adenine Thymine complex.</li> </ul>"},{"location":"morseSmaleSegmentation_at/#outputs","title":"Outputs","text":"<ul> <li><code>ascendingSeparatorAt.vtu</code>: the ascending separator geometry.</li> <li><code>descendingSeparatorAt.vtu</code>: the descending separator geometry.</li> </ul>"},{"location":"morseSmaleSegmentation_at/#cpython-api","title":"C++/Python API","text":"<p>GeometrySmoother</p> <p>MarchingTetrahedra</p> <p>PathCompression</p>"},{"location":"nestedTrackingFromOverlap/","title":"Nested Tracking From Overlap","text":""},{"location":"nestedTrackingFromOverlap/#pipeline-description","title":"Pipeline description","text":"<p>This example first opens the viscous fingering cinema database via the <code>ttkCinemaReader</code>, and then queries all entries of one specific simulation run ordered by time via the <code>ttkCinemaQuery</code> filter. Then the pipeline iterates over the resulting database entries via the <code>ttkForEach</code> and <code>ttkEndFor</code> filters, and loads the corresponding data product of each iteration with the <code>ttkCinemaProductReader</code>. Then the script computes three superlevel sets for the levels 20, 28, and 32 via three separate <code>Threshold</code> filters. Next the pipeline computs the connected components of these sets via the <code>Connectivity</code> filter. Then the components are packaged into a specific <code>vtkMultiBlockDataSet</code> hierrachy via <code>ttkBlockAggregator</code> filters, and this structure is then fed sequentially into the <code>ttkTrackingFromOverlap</code> filter which computes the overlap of the components across time and levels. After all iterations, the <code>ttkTrackingFromOverlap</code> filter will produce the resulting nested tracking graph. The <code>ttkPlanarGraphLayout</code> filter then computes an optimized layout for the NTG, where the actual transformation of the graph coordinates is applied in the following <code>Calculator</code> filter. Finally the <code>ttkMeshGraph</code> filter generates a <code>vtkUnstructuredGrid</code> of the NTG with dynamic edge widths, which is then stored to disk.</p>"},{"location":"nestedTrackingFromOverlap/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/nestedTrackingFromOverlap.py\n</code></pre></p>"},{"location":"nestedTrackingFromOverlap/#python-code","title":"Python code","text":"<pre><code>#### import the simple module from the paraview\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\nttkCinemaReader1 = TTKCinemaReader(DatabasePath=\"ViscousFingers.cdb\")\n\n# create a new 'TTK CinemaQuery'\nttkCinemaQuery1 = TTKCinemaQuery(InputTable=ttkCinemaReader1)\nttkCinemaQuery1.SQLStatement = \"\"\"SELECT * FROM InputTable0\nWHERE Sim='run01'\nORDER BY Time\nLIMIT 100 OFFSET 20\"\"\"\n\n# create a new 'TTK ForEach'\nttkForEach1 = TTKForEach(Input=ttkCinemaQuery1)\n\n# create a new 'TTK CinemaProductReader'\nttkCinemaProductReader1 = TTKCinemaProductReader(Input=ttkForEach1)\n\n# create a new 'Merge Blocks'\nmergeBlocks1 = MergeBlocks(Input=ttkCinemaProductReader1)\n\n# create a new 'Clip'\nclip1 = Clip(Input=mergeBlocks1)\nclip1.ClipType = \"Plane\"\nclip1.HyperTreeGridClipper = \"Plane\"\nclip1.Value = 38.38161849975586\n\n# init the 'Plane' selected for 'ClipType'\nclip1.ClipType.Origin = [31.5, 31.5, 50.0]\nclip1.ClipType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=clip1)\nthreshold1.Scalars = [\"POINTS\", \"ImageFile\"]\nthreshold1.ThresholdMethod = \"Above Upper Threshold\"\nthreshold1.UpperThreshold = 20\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=clip1)\nthreshold2.Scalars = [\"POINTS\", \"ImageFile\"]\nthreshold2.ThresholdMethod = \"Above Upper Threshold\"\nthreshold2.UpperThreshold = 28\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=clip1)\nthreshold3.Scalars = [\"POINTS\", \"ImageFile\"]\nthreshold3.ThresholdMethod = \"Above Upper Threshold\"\nthreshold3.UpperThreshold = 32\n\n# create a new 'Connectivity'\nconnectivity1 = Connectivity(Input=threshold1)\n\n# create a new 'Connectivity'\nconnectivity2 = Connectivity(Input=threshold2)\n\n# create a new 'Connectivity'\nconnectivity3 = Connectivity(Input=threshold3)\n\n# create a new 'TTK BlockAggregator'\nttkBlockAggregator5 = TTKBlockAggregator(Input=connectivity1)\nttkBlockAggregator5.ForceReset = 1\n\n# create a new 'TTK BlockAggregator'\nttkBlockAggregator6 = TTKBlockAggregator(Input=connectivity2)\nttkBlockAggregator6.ForceReset = 1\n\n# create a new 'TTK BlockAggregator'\nttkBlockAggregator7 = TTKBlockAggregator(Input=connectivity3)\nttkBlockAggregator7.ForceReset = 1\n\n# create a new 'TTK BlockAggregator'\nttkBlockAggregator1 = TTKBlockAggregator(\n    Input=[ttkBlockAggregator5, ttkBlockAggregator6, ttkBlockAggregator7]\n)\nttkBlockAggregator1.ForceReset = 1\nttkBlockAggregator1.FlattenInput = 0\n\n# create a new 'TTK ArrayEditor'\nttkArrayEditor1 = TTKArrayEditor(\n    Target=ttkBlockAggregator1, Source=ttkCinemaProductReader1\n)\nttkArrayEditor1.EditorMode = \"Add Arrays from Source\"\nttkArrayEditor1.TargetAttributeType = \"Field Data\"\nttkArrayEditor1.SourceFieldDataArrays = [\"_ttk_IterationInfo\"]\n\n# create a new 'TTK TrackingFromOverlap'\nttkTrackingFromOverlap1 = TTKTrackingFromOverlap(Input=ttkArrayEditor1)\nttkTrackingFromOverlap1.Labels = \"RegionId\"\n\n# create a new 'TTK EndFor'\nttkEndFor1 = TTKEndFor(Data=ttkTrackingFromOverlap1, For=ttkForEach1)\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=ttkEndFor1)\ncalculator1.ResultArrayName = \"Size\"\ncalculator1.Function = \"Size/6000\"\ncalculator1.ResultArrayType = \"Float\"\n\n# create a new 'TTK PlanarGraphLayout'\nttkPlanarGraphLayout1 = TTKPlanarGraphLayout(Input=calculator1)\nttkPlanarGraphLayout1.UseSequences = 1\nttkPlanarGraphLayout1.SequenceArray = [\"POINTS\", \"SequenceIndex\"]\nttkPlanarGraphLayout1.UseSizes = 1\nttkPlanarGraphLayout1.SizeArray = [\"POINTS\", \"Size\"]\nttkPlanarGraphLayout1.UseBranches = 1\nttkPlanarGraphLayout1.BranchArray = [\"POINTS\", \"BranchId\"]\nttkPlanarGraphLayout1.UseLevels = 1\nttkPlanarGraphLayout1.LevelArray = [\"POINTS\", \"LevelIndex\"]\n\n# create a new 'Calculator'\ncalculator2 = Calculator(Input=ttkPlanarGraphLayout1)\ncalculator2.CoordinateResults = 1\ncalculator2.Function = \"iHat*SequenceIndex+jHat*Layout_Y+kHat*LevelIndex\"\n\n# create a new 'TTK MeshGraph'\nttkMeshGraph1 = TTKMeshGraph(Input=calculator2)\nttkMeshGraph1.SizeArray = [\"POINTS\", \"Size\"]\n\nSaveData(\"NestedTrackingGraph.vtu\", ttkMeshGraph1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/nestedTrackingFromOverlap.py\n</code></pre></p>"},{"location":"nestedTrackingFromOverlap/#inputs","title":"Inputs","text":"<ul> <li>ViscousFingers.cdb: a cinema database containing 3D volume data of salt concentrations.</li> </ul>"},{"location":"nestedTrackingFromOverlap/#outputs","title":"Outputs","text":"<ul> <li><code>NTG.vtu</code>: the meshed nested tracking graph of superlevel set components for the levels 20, 28, and 32.</li> </ul>"},{"location":"nestedTrackingFromOverlap/#cpython-api","title":"C++/Python API","text":"<p>ArrayEditor</p> <p>BlockAggregator</p> <p>CinemaProductReader</p> <p>CinemaQuery</p> <p>CinemaReader</p> <p>EndFor</p> <p>ForEach</p> <p>MeshGraph</p> <p>PlanarGraphLayout</p> <p>TrackingFromOverlap</p>"},{"location":"persistenceClustering0/","title":"Persistence Clustering 0","text":""},{"location":"persistenceClustering0/#pipeline-description","title":"Pipeline description","text":"<p>This example performs a persistence driven clustering of a 2D toy data set, taken from the scikit-learn examples. Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline to a real-life, high-dimensional, data set.</p> <p>The pipeline starts by estimating the density of the input point cloud with a Gaussian kernel, by the <code>GaussianResampling</code>  filter, coupled with the <code>Slice</code> filter (to restrict the estimation to a 2D plane).</p> <p>Next, the PersistenceDiagram of the density field is computed and only the 2 most persistent density maxima are selected (corresponding to the desired 2 output clusters, bottom left view in the above screenshot).</p> <p>Next, the simplified persistence diagram is used as a constraint for the TopologicalSimplification of the density field (top right view, above screenshot). The simplified density field then contains only 2 maxima and it is used as an input to the Morse-Smale complex computation, for the separation of the 2D space into the output clusters (background color in the bottom right view, above screenshot).</p> <p>Finally, the cluster identifier of each input point is given by the identifier of the  corresponding ascending manifold of the Morse-Smale complex (<code>AscendingManifold</code>), with the <code>ResampleWithDataset</code> filter.</p>"},{"location":"persistenceClustering0/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceClustering0.pvsm\n</code></pre></p>"},{"location":"persistenceClustering0/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\nclustering0csv = CSVReader(FileName=[\"clustering0.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clustering0csv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=tTKPersistenceDiagram1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\nresampleWithDataset1.CellLocator = \"Static Cell Locator\"\n\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering0.py\n</code></pre></p>"},{"location":"persistenceClustering0/#inputs","title":"Inputs","text":"<ul> <li>clustering0.csv: a 2D point cloud taken from the scikit-learn examples.</li> </ul>"},{"location":"persistenceClustering0/#outputs","title":"Outputs","text":"<ul> <li><code>OutputClustering.csv</code>: the output clustering of the input point cloud (output cluster identifier: <code>AscendingManifold</code> column)</li> </ul>"},{"location":"persistenceClustering0/#cpython-api","title":"C++/Python API","text":"<p>Morse-Smale complex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"persistenceClustering1/","title":"Persistence Clustering 1","text":""},{"location":"persistenceClustering1/#pipeline-description","title":"Pipeline description","text":"<p>This pipeline performs a clustering by persistence on a 2D data set taken from the scikit-learn examples. Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set.</p> <p>First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data.</p> <p>Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data.</p> <p>From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.</p>"},{"location":"persistenceClustering1/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceClustering1.pvsm\n</code></pre></p>"},{"location":"persistenceClustering1/#python-code","title":"Python code","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering1.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering1.py\n</code></pre></p>"},{"location":"persistenceClustering1/#inputs","title":"Inputs","text":"<ul> <li>clustering1.csv: a table of 2 dimension points.</li> </ul>"},{"location":"persistenceClustering1/#outputs","title":"Outputs","text":"<ul> <li><code>data1Resampled.csv</code>: the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.</li> </ul>"},{"location":"persistenceClustering1/#cpython-api","title":"C++/Python API","text":"<p>PersistenceDiagram</p> <p>TopologicalSimplification</p> <p>MorseSmaleComplex</p>"},{"location":"persistenceClustering2/","title":"Persistence Clustering 2","text":""},{"location":"persistenceClustering2/#pipeline-description","title":"Pipeline description","text":"<p>This pipeline is similar to the previous examples of persistence clustering and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples. Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set..</p> <p>First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data.</p> <p>Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data.</p> <p>From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.</p>"},{"location":"persistenceClustering2/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceClustering2.pvsm\n</code></pre></p>"},{"location":"persistenceClustering2/#python-code","title":"Python code","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering2.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.GaussianSplatRadius = 0.05\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 5.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering2.py\n</code></pre></p>"},{"location":"persistenceClustering2/#inputs","title":"Inputs","text":"<ul> <li>clustering2.csv: a table of 2 dimension points.</li> </ul>"},{"location":"persistenceClustering2/#outputs","title":"Outputs","text":"<ul> <li><code>data2Resampled.csv</code>: the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.</li> </ul>"},{"location":"persistenceClustering2/#cpython-api","title":"C++/Python API","text":"<p>PersistenceDiagram</p> <p>TopologicalSimplification</p> <p>MorseSmaleComplex</p>"},{"location":"persistenceClustering3/","title":"Persistence Clustering 3","text":""},{"location":"persistenceClustering3/#pipeline-description","title":"Pipeline description","text":"<p>This pipeline is similar to the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples. Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set..</p> <p>First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data.</p> <p>Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data.</p> <p>From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.</p>"},{"location":"persistenceClustering3/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceClustering3.pvsm\n</code></pre></p>"},{"location":"persistenceClustering3/#python-code","title":"Python code","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering3.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering3.py\n</code></pre></p>"},{"location":"persistenceClustering3/#inputs","title":"Inputs","text":"<ul> <li>clustering3.csv: a table of 2 dimension points.</li> </ul>"},{"location":"persistenceClustering3/#outputs","title":"Outputs","text":"<ul> <li><code>data3Resampled.csv</code>: the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.</li> </ul>"},{"location":"persistenceClustering3/#cpython-api","title":"C++/Python API","text":"<p>PersistenceDiagram</p> <p>TopologicalSimplification</p> <p>MorseSmaleComplex</p>"},{"location":"persistenceClustering4/","title":"Persistence Clustering 4","text":""},{"location":"persistenceClustering4/#pipeline-description","title":"Pipeline description","text":"<p>This pipeline is the same as the previous ones and performs a clustering by persistence on a 2D data set taken from the scikit-learn examples. Please check out the Karhunen-Love Digits 64-Dimensions example for an application of this pipeline on a real-life data set..</p> <p>First, this example loads a point cloud from disk (top left view in the above screenshot), then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top right view in the above screenshot). This density field will be considered as the input scalar data.</p> <p>Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram (bottom left view in the above screenshot).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data.</p> <p>From there a MorseSmaleComplex is computed (bottom right view in the above screenshot). Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster identifier, encoded in the AscendingManifold field in the ouput, is given to it.</p>"},{"location":"persistenceClustering4/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceClustering4.pvsm\n</code></pre></p>"},{"location":"persistenceClustering4/#python-code","title":"Python code","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering4.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering4.py\n</code></pre></p>"},{"location":"persistenceClustering4/#inputs","title":"Inputs","text":"<ul> <li>clustering4.csv: a table of 2 dimension points.</li> </ul>"},{"location":"persistenceClustering4/#outputs","title":"Outputs","text":"<ul> <li><code>data4Resampled.csv</code>: the output is the data resampled in CSV file format, the cluster identifier of a point is given in the AscendingManifold field.</li> </ul>"},{"location":"persistenceClustering4/#cpython-api","title":"C++/Python API","text":"<p>PersistenceDiagram</p> <p>TopologicalSimplification</p> <p>MorseSmaleComplex</p>"},{"location":"persistenceClusteringGallery/","title":"Persistence Clustering Gallery","text":"<p>The Persistence Clustering Gallery is composed of the following examples (from left to right):</p> <ul> <li>Persistence clustering0</li> <li>Persistence clustering1</li> <li>Persistence clustering2</li> <li>Persistence clustering3</li> <li>Persistence clustering4</li> </ul> <p>Each example is explained in more details in its own documentation and is shown in the above screenshot in a pair of images, one showing the dataset (upper half), the other showing the results of the pipeline (bottom half).</p>"},{"location":"persistenceClusteringGallery/#pipeline-description","title":"Pipeline description","text":"<p>All examples of the Gallery have a similar pipeline. </p> <p>First, it loads a point cloud from disk, then it computes a mesh on which a density field is obtained with a Gaussian Resampling on the points (top view in the above screenshot). This density field will be considered as the input scalar data.</p> <p>Next, a PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the features with a persistence above a certain value. The result is a simplified persistence diagram.</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data, giving us a simplified data.</p> <p>From there a MorseSmaleComplex is computed (bottom view in the above screenshot) then smoothed. Finally, by using the identifier of the 2-dimension cell of the Morse Smale complex where one point lands, a cluster is given to it.</p>"},{"location":"persistenceClusteringGallery/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your <code>ttk-data</code>  directory and enter the following command: <pre><code>paraview states/persistenceClusteringGallery.pvsm\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#python-code","title":"Python code","text":""},{"location":"persistenceClusteringGallery/#persistence-clusering-0","title":"Persistence clusering 0","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\nclustering0csv = CSVReader(FileName=[\"clustering0.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clustering0csv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=tTKPersistenceDiagram1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\nresampleWithDataset1.CellLocator = \"Static Cell Locator\"\n\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering0.py\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#persistence-clusering-1","title":"Persistence clusering 1","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering1.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering1.py\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#persistence-clusering-2","title":"Persistence clusering 2","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering2.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.GaussianSplatRadius = 0.05\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 5.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering2.py\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#persistence-clusering-3","title":"Persistence clusering 3","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering3.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKPersistenceDiagram1.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering3.py\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#persistence-clusering-4","title":"Persistence clusering 4","text":"<pre><code>from paraview.simple import *\n\n# create a new 'CSV Reader'\nclusteringcsv = CSVReader(FileName=[\"clustering4.csv\"])\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=clusteringcsv)\ntableToPoints1.XColumn = \"X\"\ntableToPoints1.YColumn = \"Y\"\ntableToPoints1.a2DPoints = 1\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=tableToPoints1)\ngaussianResampling1.ResampleField = [\"POINTS\", \"ignore arrays\"]\ngaussianResampling1.ResamplingGrid = [256, 256, 3]\ngaussianResampling1.SplatAccumulationMode = \"Sum\"\n\n# create a new 'Slice'\nslice1 = Slice(Input=gaussianResampling1)\nslice1.SliceType = \"Plane\"\n\n# init the 'Plane' selected for 'SliceType'\nslice1.SliceType.Normal = [0.0, 0.0, 1.0]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=slice1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold0 = Threshold(Input=threshold1)\npersistenceThreshold0.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold0.ThresholdMethod = \"Between\"\npersistenceThreshold0.LowerThreshold = 10.0\npersistenceThreshold0.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=slice1, Constraints=persistenceThreshold0\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Resample With Dataset'\nresampleWithDataset1 = ResampleWithDataset(\n    SourceDataArrays=OutputPort(tTKMorseSmaleComplex1, 3),\n    DestinationMesh=tableToPoints1,\n)\n\n# save the output(s)\nSaveData(\"OutputClustering.csv\", resampleWithDataset1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceClustering4.py\n</code></pre></p>"},{"location":"persistenceClusteringGallery/#cpython-api","title":"C++/Python API","text":"<p>GeometrySmoother</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p> <p>MorseSmaleComplex</p>"},{"location":"persistenceDiagramClustering/","title":"Persistence Diagram Clustering","text":""},{"location":"persistenceDiagramClustering/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the PersistenceDiagram is computed on each scalar field.</p> <p>All these diagrams are passed to PersistenceDiagramClustering to compute a clustering in the space of persistence diagrams. The clustering is done using a progressive algorithm. In particular, a time constraint can be set to the approach. The algorithm delivers an partial but meaningful result within this constraint, prioritizing high-persistence pairs in the computation. Each centroid is also an explicit persistence diagram. Upon convergence, it is a Wasserstein barycenter of the diagrams within each cluster. As such, it is representative of the repartition of topological features within each cluster.</p> <p>In the ParaView state, the extrema corresponding to each centroids are represented in the original 3d domain, scaled by topological persistence.</p> <p>The python script computes the clustering and saves the related classification in a .csv file. Additionally, the resulting diagram centroids are saved as a multiblock dataset.</p>"},{"location":"persistenceDiagramClustering/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceDiagramClustering.pvsm\n</code></pre></p>"},{"location":"persistenceDiagramClustering/#python-code","title":"Python code","text":"<pre><code>#! /usr/bin/env/python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(\n    registrationName=\"TTKCinemaReader1\", DatabasePath=\"Isabel.cdb\"\n)\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(\n    registrationName=\"TTKCinemaProductReader1\", Input=tTKCinemaReader1\n)\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram13 = TTKPersistenceDiagram(\n    registrationName=\"TTKPersistenceDiagram13\", Input=tTKCinemaProductReader1\n)\ntTKPersistenceDiagram13.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKPersistenceDiagram13.InputOffsetField = [\"POINTS\", \"velocityMag\"]\n\n# create a new 'TTK PersistenceDiagramClustering'\ntTKPersistenceDiagramClustering1 = TTKPersistenceDiagramClustering(\n    registrationName=\"TTKPersistenceDiagramClustering1\", Input=tTKPersistenceDiagram13\n)\ntTKPersistenceDiagramClustering1.Numberofclusters = 3\ntTKPersistenceDiagramClustering1.Maximalcomputationtimes = 10.0\ntTKPersistenceDiagramClustering1.Displayingmethod = \"Clusters as stars\"\ntTKPersistenceDiagramClustering1.Spacing = 1.1\ntTKPersistenceDiagramClustering1.GeometricalLiftingalpha = 0.2\n\n# save the output\nSaveData(\n    \"PersistenceDiagramClustering_centroids.vtm\",\n    OutputPort(tTKPersistenceDiagramClustering1, 1),\n)\n\nSaveData(\n    \"PersistenceDiagramClustering_clustering.csv\",\n    proxy=tTKPersistenceDiagramClustering1,\n    ChooseArraysToWrite=1,\n    FieldDataArrays=[\"FILE\", \"TimeStep\", \"ClusterId\"],\n    FieldAssociation=\"Field Data\",\n    AddMetaData=0,\n)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceDiagramClustering.py\n</code></pre></p>"},{"location":"persistenceDiagramClustering/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 scalarfields defined on a regular grid, corresponding to 12 timesteps of a hurricane simulation.</li> </ul>"},{"location":"persistenceDiagramClustering/#outputs","title":"Outputs","text":"<ul> <li><code>PersistenceDiagramClustering_clustering.csv</code>: the output classification.</li> <li><code>PersistenceDiagramClustering_centroids.vtm</code>: the output centroids.</li> </ul>"},{"location":"persistenceDiagramClustering/#cpython-api","title":"C++/Python API","text":"<p>CinemaReader</p> <p>CinemaProductReader</p> <p>PersistenceDiagram</p> <p>PersistenceDiagramClustering</p>"},{"location":"persistenceDiagramDistance/","title":"Persistence Diagram Distance","text":""},{"location":"persistenceDiagramDistance/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of twelve scalar fields inside a cinema database from disk. Two scalar fields are extracted from the ensemble. Then, the PersistenceDiagram is computed on both fields.</p> <p>PersistenceDiagramClustering is then used to compute the Wasserstein distance between the two persistence diagrams. The assignment problem associated to the distance is computed using the Auction algorithm, and the corresponding matchings are displayed in ParaView. The actual distance is available in the field data of the 'matchings' output.</p> <p>The python script computes the distance and prints it in the terminal output. Additionally, it saves the distance as a .csv file.</p>"},{"location":"persistenceDiagramDistance/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceDiagramDistance.pvsm\n</code></pre></p>"},{"location":"persistenceDiagramDistance/#python-code","title":"Python code","text":"<pre><code>#! /usr/bin/env/python\n\nfrom paraview.simple import *\n\nimport numpy as np\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"Isabel.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\n\n# create a new 'Extract Block'\nextractBlock1 = ExtractBlock(Input=tTKCinemaProductReader1)\nextractBlock1.Selectors = [\"/Root/Block0\", \"/Root/Block10\"]\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=extractBlock1)\ncalculator1.ResultArrayName = \"velocityMag\"\ncalculator1.Function = \"-velocityMag\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram3 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram3.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKPersistenceDiagram3.InputOffsetField = [\"POINTS\", \"velocityMag\"]\ntTKPersistenceDiagram3.IgnoreBoundary = False\n\n# create a new 'Threshold'\nthreshold7 = Threshold(Input=tTKPersistenceDiagram3)\nthreshold7.Scalars = [\"CELLS\", \"Persistence\"]\nthreshold7.LowerThreshold = 1.2\nthreshold7.UpperThreshold = 136.490955383565\n\n# create a new 'TTK PersistenceDiagramClustering'\ntTKPersistenceDiagramClustering1 = TTKPersistenceDiagramClustering(Input=threshold7)\nUpdatePipeline()\n\n# Get the data\nmatchings_data = FetchData(OutputPort(tTKPersistenceDiagramClustering1, 2))[0]\n\n# Get field data\nfield_data = matchings_data.GetBlock(0).GetFieldData()\n\n# Display the Wasserstein distance\nwasserstein_distance = field_data.GetArray(\"WassersteinDistance\").GetValue(0)\n\n# Save the Wasserstein distance in a csv file\nnp.savetxt(\"WassersteinDistance.csv\", [wasserstein_distance])\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceDiagramDistance.py\n</code></pre></p>"},{"location":"persistenceDiagramDistance/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 scalarfields defined on a regular grid, corresponding to 12 timesteps of a hurricane simulation.</li> </ul>"},{"location":"persistenceDiagramDistance/#outputs","title":"Outputs","text":"<ul> <li><code>WassersteinDistance.csv</code>: the output distance between the two persistence diagrams.</li> </ul>"},{"location":"persistenceDiagramDistance/#cpython-api","title":"C++/Python API","text":"<p>CinemaReader</p> <p>CinemaProductReader</p> <p>PersistenceDiagram</p> <p>PersistenceDiagramClustering</p>"},{"location":"persistenceDiagramWAE/","title":"Persistence Diagram Wasserstein Auto-Encoder","text":""},{"location":"persistenceDiagramWAE/#pipeline-description","title":"Pipeline description","text":"<p>This example first loads an ensemble of scalar fields inside a cinema database from disk. Then, the PersistenceDiagram is computed on each scalar field.</p> <p>All these diagrams are passed to MergeTreeAutoencoder to compute a wasserstein auto-encoding in the metric space of persistence diagrams. </p> <p>Then the filter MergeTreeAutoencoderDecoding is used to reconstruct the input diagrams. </p> <p>In terms of visualization, a scalar field is displayed for each cluster. The original diagrams are displayed alongside their reconstruction at their right. The persistence pairs of the diagrams are colored by ID to see what features they correspond to in the scalar field.</p> <p>The 2D planar layout is displayed with the persistence correlation view at the top right. The 12 scalar fields are colored by Cluster ID.</p> <p>The python script computes the PD-WAE basis. This computation is not deterministic and it may take a minute  (depending on your hardware). It saves the resulting coefficients of the input diagrams and the axes of the bases and their origins. Finally it saves the reconstructed diagrams given the bases and the coordinates of the diagrams in the basis.</p>"},{"location":"persistenceDiagramWAE/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistenceDiagramWAEDecoding.pvsm\n</code></pre></p> <p>To reproduce the above analysis pipeline as well as the (non-deterministic) training procedure, go to your ttk-data directory and enter the following command (the computation may take a minute, depending on your hardware): <pre><code>paraview states/persistenceDiagramWAE.pvsm\n</code></pre></p>"},{"location":"persistenceDiagramWAE/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader2_Isabel = TTKCinemaReader(DatabasePath=\"./Isabel.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader7 = TTKCinemaProductReader(Input=tTKCinemaReader2_Isabel)\ntTKCinemaProductReader7.AddFieldDataRecursively = 1\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=tTKCinemaProductReader7)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"velocityMag\"]\ntTKPersistenceDiagram1.Backend = \"FTM (IEEE TPSD 2019)\"\n\n# create a new 'TTK MergeTreeAutoencoder'\ntTKMergeTreeAutoencoder1 = TTKMergeTreeAutoencoder(\n    Input=tTKPersistenceDiagram1, OptionalInput=None, Info=None\n)\ntTKMergeTreeAutoencoder1.NormalizedWasserstein = 0\ntTKMergeTreeAutoencoder1.ScaleLayerAfterLatent = 1\ntTKMergeTreeAutoencoder1.InputOriginPrimeSizePercent = 12.0\ntTKMergeTreeAutoencoder1.LatentSpaceNumberofAxes = 1\ntTKMergeTreeAutoencoder1.LatentSpaceOriginPrimeSizePercent = 5.0\ntTKMergeTreeAutoencoder1.BarycenterSizeLimitPercent = 0.0\ntTKMergeTreeAutoencoder1.MinIteration = 500\ntTKMergeTreeAutoencoder1.GradientStepSize = 0.15\ntTKMergeTreeAutoencoder1.TrackingLossWeight = 1e-06\ntTKMergeTreeAutoencoder1.ClusteringArrayName = \"\"\ntTKMergeTreeAutoencoder1.InitOriginPrimeStructByCopy = 0\ntTKMergeTreeAutoencoder1.PairTypeMixtureCoefficient = 0.0\ntTKMergeTreeAutoencoder1.Epsilon1 = 100.0\ntTKMergeTreeAutoencoder1.PersistenceThreshold = 5.0\n\n# create a new 'TTK MergeTreeAutoencoderDecoding'\ntTKMergeTreeAutoencoderDecoding1 = TTKMergeTreeAutoencoderDecoding(\n    Origins=OutputPort(tTKMergeTreeAutoencoder1, 0),\n    BasesVectors=OutputPort(tTKMergeTreeAutoencoder1, 1),\n    Coefficients=OutputPort(tTKMergeTreeAutoencoder1, 2),\n)\n\n# save the output\nSaveData(\"PD-WAE_processed_diagrams.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 0))\nSaveData(\"PD-WAE_origins.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 1))\nSaveData(\"PD-WAE_axes.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 2))\nSaveData(\"PD-WAE_coef.vtm\", OutputPort(tTKMergeTreeAutoencoder1, 3))\nSaveData(\"PD-WAE_reconstructed_diagrams.vtm\", tTKMergeTreeAutoencoderDecoding1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceDiagramWAE.py\n</code></pre></p>"},{"location":"persistenceDiagramWAE/#inputs","title":"Inputs","text":"<ul> <li>Isabel.cdb: a cinema database containing 12 regular grids.</li> </ul>"},{"location":"persistenceDiagramWAE/#outputs","title":"Outputs","text":"<ul> <li><code>PD-WAE_processed_diagrams.vtm</code>: the processed input diagrams.</li> <li><code>PD-WAE_origins.vtm</code>: the origins of each basis.</li> <li><code>PD-WAE_axes.vtm</code>: the axes of each basis.</li> <li><code>PD-WAE_coef.vtm</code>: the coefficients of the input diagrams corresponding to their coordinates in each basis.</li> <li><code>PD-WAE_reconstructed_diagrams.vtm</code>: the reconstructed input diagrams.</li> </ul>"},{"location":"persistenceDiagramWAE/#cpython-api","title":"C++/Python API","text":"<p>CinemaProductReader</p> <p>CinemaReader</p> <p>DataSetToTable</p> <p>IcospheresFromPoints</p> <p>PersistenceDiagram</p> <p>MergeTreeAutoencoder</p> <p>MergeTreeAutoencoderDecoding</p>"},{"location":"persistenceDrivenCompression/","title":"Persistence-Driven Compression","text":""},{"location":"persistenceDrivenCompression/#pipeline-description","title":"Pipeline description","text":"<p>This example helps comparing three outputs of the TopologicalCompression filter to the original input grayscale image (top-left view in the above screenshot), with the following parameters:</p> <ul> <li>ZFP relative error tolerance set to 50%, no topological compression   (bottom-left view in the above screenshot),</li> <li>Topological loss set to 10%, no ZFP extra compression (top-right view),</li> <li>Topological loss set to 10% and ZFP relative error tolerance set to 50% (bottom-right view).</li> </ul> <p>Those files have been generated from the original VTI image using the TopologicalCompressionWriter filter. To read them, Paraview uses its counterpart, TopologicalCompressionReader.</p>"},{"location":"persistenceDrivenCompression/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command:</p> <pre><code>paraview states/persistenceDrivenCompression.pvsm\n</code></pre>"},{"location":"persistenceDrivenCompression/#python-code","title":"Python code","text":"<p>This script loads the uncompressed naturalImage_original.vti input file, saves it as in the TTK Topological Compressed Image Data file format, using TopologicalCompressionWriter under the hood. The produced file is then loaded with TopologicalCompressionReader and saved back to VTI. This demonstrates the use of the <code>TopologicalCompression</code> I/O modules.</p> <pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# read input VTI with 'XML Image Data Reader'\nnaturalImage = XMLImageDataReader(FileName=[\"naturalImage_original.vti\"])\n\n# compress &amp; save to TTK Topological Compression format\nSaveData(\n    \"naturalImage_persistence10_zfp50.ttk\",\n    proxy=naturalImage,\n    ScalarField=[\"POINTS\", \"PNGImage\"],\n    Topologicallosspersistencepercentage=10,  # Topological loss\n    ZFPRelativeErrorToleranceextra=50,  # ZFP Relative Error Tolerance\n)\n\n# read the compressed file with 'TTK TopologicalCompressionReader'\nnaturalImage_compressed = TTKTopologicalCompressionReader(\n    FileName=\"naturalImage_persistence10_zfp50.ttk\",\n)\n\n# write compressed data-set to VTI\nSaveData(\n    \"uncompressed_naturalImage_persistence10_zfp50.vti\",\n    naturalImage_compressed,\n)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistenceDrivenCompression.py\n</code></pre></p>"},{"location":"persistenceDrivenCompression/#inputs","title":"Inputs","text":"<ul> <li> <p>naturalImage_original.vti:   a grayscale picture converted to the VTI format</p> </li> <li> <p>naturalImage_zpf50.ttk:   the previous image, compressed using <code>TopologicalCompressionWriter</code>   with ZFP compressor only (no topological compression). ZFP relative   error tolerance was set to 50%.</p> </li> <li> <p>naturalImage_persistence10.ttk:   the first input image, compressed using   <code>TopologicalCompressionWriter</code> with a Topological loss of 10% and   without ZFP (ZFP relative error tolerance set to a negative value).</p> </li> <li> <p>naturalImage_persistence10_zpf50.ttk:   the first input image, compressed using   <code>TopologicalCompressionWriter</code> with a Topological loss of 10% and a   ZFP relative error tolerance set to 50%.</p> </li> </ul>"},{"location":"persistenceDrivenCompression/#outputs","title":"Outputs","text":"<ul> <li><code>uncompressed_naturalImage_persistence10_zfp50.vti</code>: the first   input, compressed and saved as a VTI file.</li> </ul>"},{"location":"persistenceDrivenCompression/#cpython-api","title":"C++/Python API","text":"<p>TopologicalCompression</p> <p>TopologicalCompressionReader</p> <p>TopologicalCompressionWriter</p>"},{"location":"persistentGenerators_at/","title":"Persistent Generators AT","text":""},{"location":"persistentGenerators_at/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the persistent one-dimensional generators of the electronic density of the Adenine-Thymine molecular complex. These generators characterize the cycles in the interactions between atoms, whether they are covalent (cycles in the carbonate chains), or weaker non-covalent interactions (cycles in the hydrogen bonds).</p> <p>Generators are computed using PersistentGenerators. For context, the one-dimensional separatrices of the MorseSmale complex are computed using MorseSmaleComplex and shown in the ParaView example.</p> <p>The python script simply computes the generators and saves the result as a .vtp file.</p>"},{"location":"persistentGenerators_at/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_at.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_at/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\natvti = XMLImageDataReader(FileName=[\"at.vti\"])\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=atvti)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"density\"]\n\nSaveData(\"PersistentGeneratorsAt.vtp\", tTKPersistentGenerators1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_at.py\n</code></pre></p>"},{"location":"persistentGenerators_at/#inputs","title":"Inputs","text":"<ul> <li>at.vti: A molecular dataset: a three-dimensional regular grid with 1 scalar field, the electronic density in the Adenine Thymine complex.</li> </ul>"},{"location":"persistentGenerators_at/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsAt.vtp</code>: the raw one-dimensional generators of the field.</li> </ul>"},{"location":"persistentGenerators_at/#cpython-api","title":"C++/Python API","text":"<p>MorseSmaleComplex</p> <p>PersistentGenerators</p>"},{"location":"persistentGenerators_casting/","title":"Persistent Generators Casting","text":""},{"location":"persistentGenerators_casting/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the infinitely persistent 1-cycles of the surface. These cycles smoothly capture the topological handles of the surface.</p> <p>The surface generators are extracted using the eigenfunctions of the Laplace-Beltrami operator. These eigenfunctions are computed with EigenField Generators are then computed on this smooth scalarfield using PersistentGenerators.</p> <p>Finally, the cycles are smoothed along the original surface using SurfaceGeometrySmoother</p> <p>The python script simply computes the cycles and saves the result as a .vtp file.</p>"},{"location":"persistentGenerators_casting/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_casting.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_casting/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\ncastingvtu = XMLUnstructuredGridReader(FileName=[\"casting.vtu\"])\n\n# create a new 'TTK EigenField'\ntTKEigenField1 = TTKEigenField(InputGeometry=castingvtu)\ntTKEigenField1.Numberofeigenfunctions = 98\ntTKEigenField1.Computestatistics = 1\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKEigenField1)\ncalculator1.Function = \"Statistics_EigenMagnitude\"\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=calculator1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"Result\"]\ntTKPersistentGenerators1.PruneHandlesGenerators = 1\n\nSaveData(\"PersistentGeneratorsCasting.vtp\", tTKPersistentGenerators1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_casting.py\n</code></pre></p>"},{"location":"persistentGenerators_casting/#inputs","title":"Inputs","text":"<ul> <li>casting.vtu: A 2-dimensionnal triangulation of the casting dataset, representing a mechanical piece.</li> </ul>"},{"location":"persistentGenerators_casting/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsCasting.vtp</code>: the infinitely persistent 1-cycles of the surface.</li> </ul>"},{"location":"persistentGenerators_casting/#cpython-api","title":"C++/Python API","text":"<p>EigenField</p> <p>PersistentGenerators</p> <p>SurfaceGeometrySmoother</p>"},{"location":"persistentGenerators_darkSky/","title":"Persistent Generators DarkSky","text":""},{"location":"persistentGenerators_darkSky/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the most persistent one-dimensional generators of the opposite of the density of dark matter in an astrophysics simulation. These generators characterize prominent loops in the cosmic web.</p> <p>The data is originally a point cloud. It is processed into a scalar field defined on a regular grid using Gaussian resampling.</p> <p>Generators are then computed using PersistentGenerators, and thresholded in order to keep the most persistent ones..</p> <p>For context, the one-dimensional separatrices of the MorseSmale complex are computed using MorseSmaleComplex after some topological simplification using TopologicalSimplificationand shown in the ParaView example.</p> <p>The python script simply computes the most persistent generators and saves the result as a .vtu file.</p>"},{"location":"persistentGenerators_darkSky/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_darkSky.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_darkSky/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML PolyData Reader'\nds14_scivis_0128_e4_dt04_06800vtp = XMLPolyDataReader(\n    FileName=[\"ds14_scivis_0128_e4_dt04_1.0000.vtp\"]\n)\n\n# create a new 'Gaussian Resampling'\ngaussianResampling1 = GaussianResampling(Input=ds14_scivis_0128_e4_dt04_06800vtp)\ngaussianResampling1.ResampleField = [\"POINTS\", \"DarkMatter_Phi\"]\ngaussianResampling1.ResamplingGrid = [200, 200, 200]\ngaussianResampling1.GaussianSplatRadius = 0.008\ngaussianResampling1.ScaleSplats = 0\ngaussianResampling1.EllipticalSplats = 0\ngaussianResampling1.FillVolumeBoundary = 0\n\n# create a new 'TTK ScalarFieldSmoother'\ntTKScalarFieldSmoother1 = TTKScalarFieldSmoother(Input=gaussianResampling1)\ntTKScalarFieldSmoother1.ScalarField = [\"POINTS\", \"SplatterValues\"]\ntTKScalarFieldSmoother1.IterationNumber = 7\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKScalarFieldSmoother1)\ncalculator1.ResultArrayName = \"SplatterValues\"\ncalculator1.Function = \"-SplatterValues\"\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=calculator1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"SplatterValues\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistentGenerators1)\nthreshold1.Scalars = [\"CELLS\", \"Persistence\"]\nthreshold1.LowerThreshold = 0.24\nthreshold1.UpperThreshold = 0.2863966089734687\n\nSaveData(\"PersistentGeneratorsDarkSky.vtu\", threshold1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_darkSky.py\n</code></pre></p>"},{"location":"persistentGenerators_darkSky/#inputs","title":"Inputs","text":"<ul> <li>ds14_scivis_0128_e4_dt04_1.0000.vtp: A point cloud dataset representing a simulation of the density of dark matter in the universe.</li> </ul>"},{"location":"persistentGenerators_darkSky/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsDarkSky.vtu</code>: the raw one-dimensional most persistent generators of the field.</li> </ul>"},{"location":"persistentGenerators_darkSky/#cpython-api","title":"C++/Python API","text":"<p>MorseSmaleComplex</p> <p>PersistentGenerators</p> <p>ScalarFieldSmoother</p>"},{"location":"persistentGenerators_fertility/","title":"Persistent Generators Fertility","text":""},{"location":"persistentGenerators_fertility/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the infinitely persistent 1-cycles of the surface. These cycles smoothly capture the topological handles of the surface.</p> <p>The surface generators are extracted using the eigenfunctions of the Laplace-Beltrami operator. These eigenfunctions are computed with EigenField Generators are then computed on this smooth scalarfield using PersistentGenerators.</p> <p>Finally, the cycles are smoothed along the original surface using SurfaceGeometrySmoother</p> <p>The python script simply computes the cycles and saves the result as a .vtu file.</p>"},{"location":"persistentGenerators_fertility/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_fertility.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_fertility/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nfertilityvtu = XMLUnstructuredGridReader(FileName=[\"fertility.vtu\"])\n\n# create a new 'TTK EigenField'\ntTKEigenField1 = TTKEigenField(InputGeometry=fertilityvtu)\ntTKEigenField1.Numberofeigenfunctions = 100\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKEigenField1)\ncalculator1.Function = '\"OutputEigenFunctions_4\"'\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=calculator1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"Result\"]\ntTKPersistentGenerators1.PruneHandlesGenerators = 1\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistentGenerators1)\nthreshold1.Scalars = [\"CELLS\", \"IsFinite\"]\n\nSaveData(\"PersistentGeneratorsFertility.vtu\", threshold1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_fertility.py\n</code></pre></p>"},{"location":"persistentGenerators_fertility/#inputs","title":"Inputs","text":"<ul> <li>fertility.vtu: A 2-dimensionnal triangulation of the fertility dataset.</li> </ul>"},{"location":"persistentGenerators_fertility/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsFertility.vtu</code>: the infinitely persistent 1-cycles of the surface.</li> </ul>"},{"location":"persistentGenerators_fertility/#cpython-api","title":"C++/Python API","text":"<p>EigenField</p> <p>PersistentGenerators</p> <p>SurfaceGeometrySmoother</p>"},{"location":"persistentGenerators_householdAnalysis/","title":"Persistent Generators Household Analysis","text":""},{"location":"persistentGenerators_householdAnalysis/#pipeline-description","title":"Pipeline description","text":"<p>This example shows the detection of a circular pattern in high-dimensional data. The data contains seven mesurements of electric power consumption for a single household over two years, for a daily sampling. This can be interpreted as 700 points (on per day) in R^7.</p> <p>The distance matrix between these points is computed using TableDistanceMatrix. Using the distance matrix, a clustering of the input data is performed using ParaView's K-means algorithm (with k=8). The points are then embedded in 3D using MDS, with DimensionReduction.</p> <p>At this point, the 2-dimensional Rips complex is computed with RipsComplex from the high-dimensional point cloud, and shown in 3D via MDS projection.</p> <p>Finally an infinitely persistent 1-cycle is extracted from the Rips complex with PersistentGenerators, on the diameter function. This cycle captures a circular pattern present in the data, implying that in practice, continuous displacements from one cluster to another are likely to imply transformations through other clusters present along the cycle.</p> <p>The python script saves the resulting point cloud, Rips complex and output cycle as vtk files.</p>"},{"location":"persistentGenerators_householdAnalysis/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_householdAnalysis.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_householdAnalysis/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'CSV Reader'\nhousehold_part1_ID_dailycsv = CSVReader(FileName=[\"household_part1_ID_daily.csv\"])\nhousehold_part1_ID_dailycsv.HaveHeaders = 0\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction1 = TTKDimensionReduction(\n    Input=household_part1_ID_dailycsv, ModulePath=\"default\"\n)\ntTKDimensionReduction1.InputColumns = [\n    \"Field 2\",\n    \"Field 3\",\n    \"Field 4\",\n    \"Field 5\",\n    \"Field 6\",\n    \"Field 7\",\n    \"Field 8\",\n]\ntTKDimensionReduction1.Method = \"Principal Component Analysis\"\ntTKDimensionReduction1.Components = 3\n\n# create a new 'TTK TableDistanceMatrix'\ntTKTableDistanceMatrix1 = TTKTableDistanceMatrix(Input=tTKDimensionReduction1)\ntTKTableDistanceMatrix1.InputColumns = [\n    \"Field 2\",\n    \"Field 3\",\n    \"Field 4\",\n    \"Field 5\",\n    \"Field 6\",\n    \"Field 7\",\n    \"Field 8\",\n]\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=tTKDimensionReduction1)\ntableToPoints1.XColumn = \"Component_0\"\ntableToPoints1.YColumn = \"Component_1\"\ntableToPoints1.ZColumn = \"Component_2\"\ntableToPoints1.KeepAllDataArrays = 1\n\n# create a new 'K Means'\nkMeans1 = KMeans(Input=tableToPoints1, ModelInput=None)\nkMeans1.VariablesofInterest = [\"Component_0\", \"Component_1\", \"Component_2\"]\nkMeans1.k = 8\n\n# create a new 'TTK RipsComplex'\ntTKRipsComplex1 = TTKRipsComplex(Input=tTKTableDistanceMatrix1)\ntTKRipsComplex1.SelectFieldswithaRegexp = 1\ntTKRipsComplex1.Regexp = \"Dist.*\"\ntTKRipsComplex1.Diameterepsilon = 18.0\n\n# create a new 'Cell Data to Point Data'\ncellDatatoPointData1 = CellDatatoPointData(Input=tTKRipsComplex1)\ncellDatatoPointData1.CellDataArraytoprocess = [\"Diameter\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=cellDatatoPointData1)\nthreshold1.Scalars = [\"POINTS\", \"Diameter\"]\nthreshold1.LowerThreshold = 9.0\nthreshold1.UpperThreshold = 17.38239404772305\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=threshold1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"Diameter\"]\ntTKPersistentGenerators1.PruneHandlesGenerators = 1\n\nSaveData(\"PersistentGeneratorsHouseholdAnalysis_cycle.vtp\", tTKPersistentGenerators1)\nSaveData(\"PersistentGeneratorsHouseholdAnalysis_points.vtp\", OutputPort(kMeans1, 1))\nSaveData(\"PersistentGeneratorsHouseholdAnalysis_ripsComplex.vtu\", tTKRipsComplex1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_householdAnalysis.py\n</code></pre></p>"},{"location":"persistentGenerators_householdAnalysis/#inputs","title":"Inputs","text":"<ul> <li>household_part1_ID_daily.csv: A csv file containing the high-dimensional data.</li> </ul>"},{"location":"persistentGenerators_householdAnalysis/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsHouseholdAnalysis_points.vtp</code>: the high-dimensionnal point cloud embedded in 3D.</li> <li><code>PersistentGeneratorsHouseholdAnalysis_ripsComplex</code>: the 2-dimensional Rips complex of the point cloud.</li> <li><code>PersistentGeneratorsHouseholdAnalysis_cycle</code>: the infinitely persistent 1-cycle of the Rips complex.</li> </ul>"},{"location":"persistentGenerators_householdAnalysis/#cpython-api","title":"C++/Python API","text":"<p>DimensionReduction</p> <p>PersistentGenerators</p> <p>RipsComplex</p> <p>TableDistanceMatrix</p>"},{"location":"persistentGenerators_periodicPicture/","title":"Persistent Generators Periodic Picture","text":""},{"location":"persistentGenerators_periodicPicture/#pipeline-description","title":"Pipeline description","text":"<p>This example shows the detection of a circular pattern in high-dimensional data. 100 greyscale pictures of resolution 32x32 of a syntethic terrain were taken in ParaView, from 100 viewpoints arranged along a circle, and stored in a cinema database.</p> <p>The ParaView example starts by loading the database. The set of pictures and the corresponding viewpoints can be navigated using the time controls of ParaView.</p> <p>This set of images can be interpreted as 100 points in R^1024.  The distance matrix between these points is computed using TableDistanceMatrix. These points are then embedded in 3D using MDS, with DimensionReduction.</p> <p>At this point, the 2-dimensional Rips complex is computed with RipsComplex from the high-dimensional point cloud, and shown in 3D via MDS projection.</p> <p>Finally the infinitely persistent 1-cycle is extracted from the Rips complex with PersistentGenerators, on the diameter function. This cycle captures the circular pattern synthetically injected in the data.</p> <p>The python script saves the resulting point cloud, Rips complex and output cycle as vtk files.</p>"},{"location":"persistentGenerators_periodicPicture/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_periodicPicture.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_periodicPicture/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'TTK CinemaReader'\ntTKCinemaReader1 = TTKCinemaReader(DatabasePath=\"periodicPicture.cdb\")\n\n# create a new 'TTK CinemaProductReader'\ntTKCinemaProductReader1 = TTKCinemaProductReader(Input=tTKCinemaReader1)\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKCinemaProductReader1)\ncalculator1.Function = \"PNGImage_X\"\n\n# create a new 'TTK DataSetToTable'\ntTKDataSetToTable1 = TTKDataSetToTable(Input=calculator1)\ntTKDataSetToTable1.DataAssociation = \"Point\"\n\n# create a new 'Transpose Table'\ntransposeTable1 = TransposeTable(Input=tTKDataSetToTable1)\ntransposeTable1.VariablesofInterest = [\"Result\"]\n\n# create a new 'TTK MergeBlockTables'\ntTKMergeBlockTables1 = TTKMergeBlockTables(Input=transposeTable1)\n\n# create a new 'TTK TableDistanceMatrix'\ntTKTableDistanceMatrix1 = TTKTableDistanceMatrix(Input=tTKMergeBlockTables1)\ntTKTableDistanceMatrix1.SelectFieldswithaRegexp = 1\ntTKTableDistanceMatrix1.Regexp = \"[01].*\"\n\n# create a new 'TTK DimensionReduction'\ntTKDimensionReduction1 = TTKDimensionReduction(\n    Input=tTKTableDistanceMatrix1, ModulePath=\"default\"\n)\ntTKDimensionReduction1.SelectFieldswithaRegexp = 1\ntTKDimensionReduction1.Regexp = \"Dist.*\"\ntTKDimensionReduction1.Components = 3\ntTKDimensionReduction1.InputIsaDistanceMatrix = 1\n\n# create a new 'TTK RipsComplex'\ntTKRipsComplex1 = TTKRipsComplex(Input=tTKDimensionReduction1)\ntTKRipsComplex1.SelectFieldswithaRegexp = 1\ntTKRipsComplex1.Regexp = \"Dist.*\"\ntTKRipsComplex1.Diameterepsilon = 1500.0\n\n# create a new 'Cell Data to Point Data'\ncellDatatoPointData1 = CellDatatoPointData(Input=tTKRipsComplex1)\ncellDatatoPointData1.CellDataArraytoprocess = [\"Diameter\"]\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=cellDatatoPointData1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"Diameter\"]\n\n# create a new 'Table To Points'\ntableToPoints1 = TableToPoints(Input=tTKDimensionReduction1)\ntableToPoints1.XColumn = \"Component_0\"\ntableToPoints1.YColumn = \"Component_1\"\ntableToPoints1.ZColumn = \"Component_2\"\ntableToPoints1.KeepAllDataArrays = 1\n\nSaveData(\"PersistentGeneratorsPeriodicPicture_cycle.vtp\", tTKPersistentGenerators1)\nSaveData(\"PersistentGeneratorsPeriodicPicture_points.vtp\", tableToPoints1)\nSaveData(\"PersistentGeneratorsPeriodicPicture_ripsComplex.vtu\", tTKRipsComplex1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_periodicPicture.py\n</code></pre></p>"},{"location":"persistentGenerators_periodicPicture/#inputs","title":"Inputs","text":"<ul> <li>periodicPicture.cdb: A cinema database containing all 100 pictures, with metadata (the associated camera angle).</li> </ul>"},{"location":"persistentGenerators_periodicPicture/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsPeriodicPicture_points.vtp</code>: the high-dimensionnal point cloud embedded in 3D.</li> <li><code>PersistentGeneratorsPeriodicPicture_ripsComplex.vtu</code>: the 2-dimensional Rips complex of the point cloud.</li> <li><code>PersistentGeneratorsPeriodicPicture_cycle.vtp</code>: the infinitely persistent 1-cycle of the Rips complex.</li> </ul>"},{"location":"persistentGenerators_periodicPicture/#cpython-api","title":"C++/Python API","text":"<p>CinemaReader</p> <p>CinemaProductReader</p> <p>DataSetToTable</p> <p>DimensionReduction</p> <p>MergeBlockTables</p> <p>PersistentGenerators</p> <p>RipsComplex</p> <p>TableDistanceMatrix</p>"},{"location":"persistentGenerators_skull/","title":"Persistent Generators Skull","text":""},{"location":"persistentGenerators_skull/#pipeline-description","title":"Pipeline description","text":"<p>This example computes the infinitely persistent 1-cycles of the surface of the skull. These cycles smoothly capture the topological handles of the surface.</p> <p>First the surface of the 3-dimensional triangulation is extracted. The surface generators are then extracted using the eigenfunctions of the Laplace-Beltrami operator. These eigenfunctions are computed with EigenField Generators are then computed on this smooth scalarfield using PersistentGenerators.</p> <p>Finally, the cycles are smoothed along the original surface using SurfaceGeometrySmoother</p> <p>The python script simply computes the cycles and saves the result as a .vtp file.</p>"},{"location":"persistentGenerators_skull/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/persistentGenerators_skull.pvsm\n</code></pre></p>"},{"location":"persistentGenerators_skull/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\nskullvtu = XMLUnstructuredGridReader(FileName=[\"skull.vtu\"])\n\n# create a new 'Extract Surface'\nextractSurface1 = ExtractSurface(Input=skullvtu)\n\n# create a new 'TTK EigenField'\ntTKEigenField1 = TTKEigenField(InputGeometry=extractSurface1)\ntTKEigenField1.Numberofeigenfunctions = 50\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tTKEigenField1)\ncalculator1.Function = '-\"OutputEigenFunctions_22\"'\n\n# create a new 'TTK PersistentGenerators'\ntTKPersistentGenerators1 = TTKPersistentGenerators(Input=calculator1)\ntTKPersistentGenerators1.ScalarField = [\"POINTS\", \"Result\"]\ntTKPersistentGenerators1.PruneHandlesGenerators = 1\n\nSaveData(\"PersistentGeneratorsSkull.vtp\", tTKPersistentGenerators1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/persistentGenerators_skull.py\n</code></pre></p>"},{"location":"persistentGenerators_skull/#inputs","title":"Inputs","text":"<ul> <li>skull.vtu: A 3-dimensionnal triangulation of the skull dataset.</li> </ul>"},{"location":"persistentGenerators_skull/#outputs","title":"Outputs","text":"<ul> <li><code>PersistentGeneratorsSkull.vtp</code>: the infinitely persistent 1-cycles of the surface.</li> </ul>"},{"location":"persistentGenerators_skull/#cpython-api","title":"C++/Python API","text":"<p>EigenField</p> <p>PersistentGenerators</p> <p>SurfaceGeometrySmoother</p>"},{"location":"tectonicPuzzle/","title":"Tectonic Puzzle","text":""},{"location":"tectonicPuzzle/#pipeline-description","title":"Pipeline description","text":"<p>This example processes a two-dimensional geophysics model of the Earth surface to segment it according to the tectonic plates.</p> <p>The outer surface of the data-set is first extracted with a combination of ParaView's <code>Connectivity</code> and <code>Threshold</code>. Then, the <code>log10</code> of the <code>Viscosity</code> scalar field is computed with a <code>Calculator</code> (bottom-right view on the above screenshot).</p> <p>Several passes of topological simplification are then combined, using PersistenceDiagram, TopologicalSimplification and MorseSmaleComplex to further clean the scalar field. The Persistence Diagram of the scalar field at the end of this cleaning step is represented in the bottom-right view on the above screenshot.</p> <p>Once this is done, since the low values of the scalar field represent the plates borders and the regions of high values the plates themselves, the <code>Descending 1-Separatrices</code> of the Morse-Smale Complex follow the plates borders and the <code>AscendingManifold</code> Segmentation of the Morse-Smale Complex gives us the expected segmentation of the tectonic plates (top-right view on the above screenshot).</p> <p>Finally, the IdentifierRandomizer filter is used to color neighbor cells with a distinct color (top right view on the above screenshot).</p>"},{"location":"tectonicPuzzle/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command:</p> <pre><code>paraview states/tectonicPuzzle.pvsm\n</code></pre>"},{"location":"tectonicPuzzle/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Unstructured Grid Reader'\ntectonicPuzzlevtu = XMLUnstructuredGridReader(FileName=[\"tectonicPuzzle.vtu\"])\n\n# create a new 'Extract Surface'\nextractSurface1 = ExtractSurface(Input=tectonicPuzzlevtu)\n\n# create a new 'Clean to Grid'\ncleantoGrid1 = CleantoGrid(Input=extractSurface1)\n\n# create a new 'Tetrahedralize'\ntetrahedralize1 = Tetrahedralize(Input=cleantoGrid1)\n\n# create a new 'Connectivity'\nconnectivity1 = Connectivity(Input=tetrahedralize1)\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=connectivity1)\nthreshold1.Scalars = [\"POINTS\", \"RegionId\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = 1.0\nthreshold1.UpperThreshold = 1.0\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=threshold1)\ncalculator1.ResultArrayName = \"logViscosity\"\ncalculator1.Function = \"log10(Viscosity)\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold2.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = -0.1\nthreshold2.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=threshold2)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 0.5\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints1 = TTKIcospheresFromPoints(Input=persistenceThreshold)\ntTKIcospheresFromPoints1.Radius = 0.5\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=calculator1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex1 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification1)\ntTKMorseSmaleComplex1.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints2 = TTKIcospheresFromPoints(Input=tTKMorseSmaleComplex1)\ntTKIcospheresFromPoints2.Radius = 0.1\n\n# create a new 'Threshold'\nthreshold3 = Threshold(Input=tTKIcospheresFromPoints2)\nthreshold3.Scalars = [\"POINTS\", \"CellDimension\"]\nthreshold3.ThresholdMethod = \"Between\"\nthreshold3.LowerThreshold = 2.0\nthreshold3.UpperThreshold = 2.0\n\n# create a new 'Threshold'\nlARGE_MAXIMA_THRESHOLD = Threshold(Input=threshold3)\nlARGE_MAXIMA_THRESHOLD.Scalars = [\"POINTS\", \"ManifoldSize\"]\nlARGE_MAXIMA_THRESHOLD.ThresholdMethod = \"Between\"\nlARGE_MAXIMA_THRESHOLD.LowerThreshold = 75.0\nlARGE_MAXIMA_THRESHOLD.UpperThreshold = 999999999\n\n# create a new 'Threshold'\npERSISTENT_MINIMA = Threshold(Input=tTKIcospheresFromPoints1)\npERSISTENT_MINIMA.Scalars = [\"POINTS\", \"CriticalType\"]\n\n# create a new 'Append Datasets'\npERSISTENT_MINIMA_AND_LARGE_MAXIMA = AppendDatasets(\n    Input=[pERSISTENT_MINIMA, lARGE_MAXIMA_THRESHOLD]\n)\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification2 = TTKTopologicalSimplification(\n    Domain=tTKTopologicalSimplification1, Constraints=pERSISTENT_MINIMA_AND_LARGE_MAXIMA\n)\ntTKTopologicalSimplification2.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram2 = TTKPersistenceDiagram(Input=tTKTopologicalSimplification2)\ntTKPersistenceDiagram2.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'Threshold'\nthreshold4 = Threshold(Input=tTKPersistenceDiagram2)\nthreshold4.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold4.ThresholdMethod = \"Between\"\nthreshold4.LowerThreshold = -0.1\nthreshold4.UpperThreshold = 999999999\n\n# create a new 'Threshold'\nthreshold5 = Threshold(Input=threshold4)\nthreshold5.Scalars = [\"CELLS\", \"PairType\"]\nthreshold5.ThresholdMethod = \"Between\"\nthreshold5.LowerThreshold = 1.0\nthreshold5.UpperThreshold = 1.0\n\n# create a new 'Calculator'\ncalculator2 = Calculator(Input=threshold5)\ncalculator2.ResultArrayName = \"SaddleValue\"\ncalculator2.Function = \"coordsX\"\n\n# create a new 'Threshold'\nsADDLE_VALUE_THRESHOLD = Threshold(Input=calculator2)\nsADDLE_VALUE_THRESHOLD.Scalars = [\"POINTS\", \"SaddleValue\"]\nsADDLE_VALUE_THRESHOLD.ThresholdMethod = \"Between\"\nsADDLE_VALUE_THRESHOLD.LowerThreshold = -0.2\nsADDLE_VALUE_THRESHOLD.UpperThreshold = 1.75\n\n# create a new 'TTK IcospheresFromPoints'\ntTKIcospheresFromPoints3 = TTKIcospheresFromPoints(Input=sADDLE_VALUE_THRESHOLD)\ntTKIcospheresFromPoints3.Radius = 0.5\n\n# create a new 'Threshold'\nlARGE_MAXIMA_LOW_SADDLE = Threshold(Input=tTKIcospheresFromPoints3)\nlARGE_MAXIMA_LOW_SADDLE.Scalars = [\"POINTS\", \"CriticalType\"]\nlARGE_MAXIMA_LOW_SADDLE.ThresholdMethod = \"Between\"\nlARGE_MAXIMA_LOW_SADDLE.LowerThreshold = 3.0\nlARGE_MAXIMA_LOW_SADDLE.UpperThreshold = 3.0\n\n# create a new 'Append Datasets'\nlARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA = AppendDatasets(\n    Input=[pERSISTENT_MINIMA, lARGE_MAXIMA_LOW_SADDLE]\n)\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification3 = TTKTopologicalSimplification(\n    Domain=tTKTopologicalSimplification2,\n    Constraints=lARGE_MAXIMA_LOW_SADDLE_AND_PERSISTENT_MINIMA,\n)\ntTKTopologicalSimplification3.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex2 = TTKMorseSmaleComplex(Input=tTKTopologicalSimplification3)\ntTKMorseSmaleComplex2.ScalarField = [\"POINTS\", \"logViscosity\"]\n\n# create a new 'TTK IdentifierRandomizer'\ntTKIdentifierRandomizer1 = TTKIdentifierRandomizer(\n    Input=OutputPort(tTKMorseSmaleComplex2, 3)\n)\ntTKIdentifierRandomizer1.ScalarField = [\"POINTS\", \"AscendingManifold\"]\n\nSaveData(\"Segmentation.vtu\", tTKIdentifierRandomizer1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/tectonicPuzzle.py\n</code></pre></p>"},{"location":"tectonicPuzzle/#inputs","title":"Inputs","text":"<ul> <li>tectonicPuzzle.vtu:   two 2-dimensional spheres (one around the other) made up of a   triangular mesh. There are several point data arrays attached to it.   Those scalar fields represent geophysics measures on the earth   surface (and at a certain depth under it); only the <code>Viscosity</code>   field will be used in the current example.</li> </ul>"},{"location":"tectonicPuzzle/#outputs","title":"Outputs","text":"<ul> <li><code>Segmentation.vtu</code>: the output segmentation in VTK file format (top   right view, above screenshot). This corresponds to a segmentation of   the tectonic plates from the <code>Viscosity</code> scalar field.</li> </ul>"},{"location":"tectonicPuzzle/#cpython-api","title":"C++/Python API","text":"<p>IcospheresFromPoints</p> <p>IdentifierRandomizer</p> <p>MorseSmaleComplex</p> <p>PersistenceDiagram</p> <p>TopologicalSimplification</p>"},{"location":"timeTracking/","title":"Time Tracking","text":""},{"location":"timeTracking/#pipeline-description","title":"Pipeline description","text":"<p>This example loads a 2D time-dependent scalar field, where time steps are stored as a sequence of data arrays.</p> <p>Using TrackingFromFields, a tracking mesh for the temporal evolution of critical points is computed. This filter computes an optimal matching between persistence diagrams (with respect to Wasserstein metric), and discards critical point pairs below a persistence of 1% by default (parameter <code>Tolerance</code>).</p> <p>The state file further contains an animation of the critical points over time.</p>"},{"location":"timeTracking/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/timeTracking.pvsm\n</code></pre></p>"},{"location":"timeTracking/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\ntimeTrackingvti = XMLImageDataReader(FileName=[\"timeTracking.vti\"])\ntimeTrackingvti.CellArrayStatus = []\n# select data arrays 000, 002, 004, ..., 118\ntimeTrackingvti.PointArrayStatus = [\"{:0&gt;3}\".format(i) for i in range(0, 120, 2)]\n\n# create a new 'TTK TrackingFromFields'\ntTKTrackingFromFields1 = TTKTrackingFromFields(Input=timeTrackingvti)\ntTKTrackingFromFields1.ForceZtranslation = 1\ntTKTrackingFromFields1.ZTranslation = 0.125\n\n# create a new 'Extract Surface'\nextractSurface1 = ExtractSurface(Input=tTKTrackingFromFields1)\n\n# save the output\nSaveData(\"timeTracking.vtp\", extractSurface1)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/timeTracking.py\n</code></pre></p>"},{"location":"timeTracking/#inputs","title":"Inputs","text":"<ul> <li>timeTracking.vti: time-dependent vorticity of a 2D vortex street, with time steps represented by data arrays '000', '002', ..., '118'</li> </ul>"},{"location":"timeTracking/#outputs","title":"Outputs","text":"<ul> <li><code>timeTracking.vtp</code>: tracking mesh of critical points</li> </ul>"},{"location":"timeTracking/#cpython-api","title":"C++/Python API","text":"<p>TrackingFromFields</p>"},{"location":"topoMapTeaser/","title":"TopoMap Teaser","text":""},{"location":"topoMapTeaser/#pipeline-description","title":"Pipeline description","text":"<p>This example illustrates the TopoMap dimensionality reduction technique on a series of toy examples. TopoMap is a projection algorithm (presented at IEEE VIS 2020) which strictly preserves the persistent connected components of the original data, or put differently, its hierarchy of clusters. Intuitively, with TopoMap, you have the guarantee that the \"salient\" clusters of your high-dimensional data are preserved while projecting it to lower dimensions.</p> <p>Technically, TopoMap provides the guarantee that the 0-dimensional persistent diagram of the Rips filtration of its output is strictly equal to that of its input. Alternatively, TopoMap guarantees that the hierarchical clustering (with single linkage) of its output is strictly identical to that of its input. </p> <p>Three toy examples are provided as CSV ASCII files (one line per point, one column per dimension). These are point clouds in 3D, which TopoMap projects down to 2D. Each of these point clouds illustrates a specific topological/geometrical behavior.</p> <p>The dataset 3blobs.csv contains 3 main clusters (one color per cluster in the above screenshot, top left view), shaped like blobs.</p> <p>The dataset 3rings.csv contains 3 main clusters (one color per cluster in the above screenshot, top center view), shaped as interleaved rings.</p> <p>The dataset 2cavities.csv contains 2 main clusters (one color per cluster in the above screenshot, top right view), one (in red) completely enclosed by the other (in blue).</p> <p>For each of these datasets, TopoMap computes a 2D projection (corresponding bottom views in the above screenshot), which separates well the ground truth clusters (shown with colors).</p>"},{"location":"topoMapTeaser/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/topoMapTeaser.pvsm\n</code></pre></p>"},{"location":"topoMapTeaser/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\na3blobscsv = CSVReader(FileName=[\"3blobs.csv\"])\ntTKDimensionReduction1 = TTKDimensionReduction(Input=a3blobscsv)\ntTKDimensionReduction1.InputColumns = [\"x\", \"y\", \"z\"]\ntTKDimensionReduction1.Method = \"TopoMap (IEEE VIS 2020)\"\nSaveData(\"3blobs_topoMap.csv\", tTKDimensionReduction1)\n\na3ringscsv = CSVReader(FileName=[\"3rings.csv\"])\ntTKDimensionReduction2 = TTKDimensionReduction(Input=a3ringscsv)\ntTKDimensionReduction2.InputColumns = [\"x\", \"y\", \"z\"]\ntTKDimensionReduction2.Method = \"TopoMap (IEEE VIS 2020)\"\nSaveData(\"3rings_topoMap.csv\", tTKDimensionReduction2)\n\na2cavitiescsv = CSVReader(FileName=[\"2cavities.csv\"])\ntTKDimensionReduction3 = TTKDimensionReduction(Input=a2cavitiescsv)\ntTKDimensionReduction3.InputColumns = [\"X\", \"Y\", \"Z\"]\ntTKDimensionReduction3.Method = \"TopoMap (IEEE VIS 2020)\"\nSaveData(\"2cavities_topoMap.csv\", tTKDimensionReduction3)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/topoMapTeaser.py\n</code></pre></p>"},{"location":"topoMapTeaser/#inputs","title":"Inputs","text":"<ul> <li>3blobs.csv: a 3D point cloud in CSV ASCII format (one line per point, one column per dimension), which exhibits 3 main clusters (in the shape of blobs).</li> <li>3rings.csv: a 3D point cloud in CSV ASCII format (one line per point, one column per dimension), which exhibits 3 main clusters (in the shape of interleaved rings).</li> <li>2cavities.csv: a 3D point cloud in CSV ASCII format (one line per point, one column per dimension), which exhibits 2 main clusters (one completely enclosed by the other one).</li> </ul>"},{"location":"topoMapTeaser/#outputs","title":"Outputs","text":"<ul> <li><code>3blobs_topoMap.csv</code>: the output 2D projection of the 3blobs.csv dataset in CSV ASCII format (one line per point, one column per dimension).</li> <li><code>3rings_topoMap.csv</code>: the output 2D projection of the 3rings.csv dataset in CSV ASCII form at (one line per point, one column per dimension).</li> <li><code>2cavities_topoMap.csv</code>: the output 2D projection of the 2cavities.csv dataset in CSV ASCII form at (one line per point, one column per dimension).</li> </ul>"},{"location":"topoMapTeaser/#cpython-api","title":"C++/Python API","text":"<p>DimensionReduction</p>"},{"location":"tribute/","title":"Tribute to Edelsbrunner and Harer's book","text":""},{"location":"tribute/#pipeline-description","title":"Pipeline description","text":"<p>This example loads a PNG microscopy image from disk, from which gray-scale scalar values are created.</p> <p>Then, the PersistenceDiagram is computed and thresholds are applied base on persistence to maintain only the most persistent features. This results in a simplified persistence diagram (top right; non-simplified persistence diagram shown in gray).</p> <p>The simplified persistence diagram is then used as a constraint for the TopologicalSimplification of the input scalar data.</p> <p>This simplified data is then used as the input of the computation of the MorseSmaleComplex. Its ascending manifolds, separatrices and critical points are shown in the bottom views (with scalar value mapped to height in the bottom right view). The separatrices are also shown, as overlay over the original scalar data, in the top left view.</p> <p>In this example, the MorseSmaleComplex segments the input microscopy data into biological cells.</p>"},{"location":"tribute/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/tribute.pvsm\n</code></pre></p>"},{"location":"tribute/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\nfrom paraview.simple import *\n\n# create a new 'PNG Series Reader'\ntributepng = PNGSeriesReader(FileNames=[\"tribute.png\"])\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=tributepng)\ncalculator1.ResultArrayName = \"originalData\"\ncalculator1.Function = \"-sqrt(PNGImage_X*PNGImage_X+PNGImage_Y*PNGImage_Y)\"\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"originalData\"]\n\n# create a new 'Threshold'\nthreshold1 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold1.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold1.ThresholdMethod = \"Between\"\nthreshold1.LowerThreshold = -0.1\nthreshold1.UpperThreshold = 999999999\n\n# create a new 'Threshold'\nminimumPairs = Threshold(Input=threshold1)\nminimumPairs.Scalars = [\"CELLS\", \"PairType\"]\nminimumPairs.ThresholdMethod = \"Between\"\nminimumPairs.LowerThreshold = -1.0\nminimumPairs.UpperThreshold = 0.0\n\n# create a new 'Calculator'\ncalculator6 = Calculator(Input=minimumPairs)\ncalculator6.AttributeType = \"Cell Data\"\ncalculator6.ResultArrayName = \"Death\"\ncalculator6.Function = \"Birth+Persistence\"\n\n# create a new 'Threshold'\ndeathThreshold = Threshold(Input=calculator6)\ndeathThreshold.Scalars = [\"CELLS\", \"Death\"]\ndeathThreshold.LowerThreshold = -297.0\ndeathThreshold.UpperThreshold = -257.391\n\n# create a new 'Threshold'\nmaximumPairs = Threshold(Input=threshold1)\nmaximumPairs.Scalars = [\"POINTS\", \"CriticalType\"]\nmaximumPairs.LowerThreshold = 3.0\nmaximumPairs.UpperThreshold = 3.0\nmaximumPairs.AllScalars = 0\n\n# create a new 'Append Datasets'\nappendDatasets1 = AppendDatasets(Input=[deathThreshold, maximumPairs])\n\n# create a new 'Threshold'\npersistenceThreshold = Threshold(Input=appendDatasets1)\npersistenceThreshold.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold.ThresholdMethod = \"Between\"\npersistenceThreshold.LowerThreshold = 8.5\npersistenceThreshold.UpperThreshold = 999999999\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=calculator1, Constraints=persistenceThreshold\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"originalData\"]\n\n# create a new 'Calculator'\ncalculator7 = Calculator(Input=tTKTopologicalSimplification1)\ncalculator7.ResultArrayName = \"originalData\"\ncalculator7.Function = \"-originalData\"\n\n# create a new 'Calculator'\ncalculator8 = Calculator(Input=calculator7)\ncalculator8.ResultArrayName = \"originalData_Order\"\ncalculator8.Function = \"-originalData_Order\"\n\n# create a new 'TTK MorseSmaleComplex'\ntTKMorseSmaleComplex2 = TTKMorseSmaleComplex(Input=calculator8)\ntTKMorseSmaleComplex2.ScalarField = [\"POINTS\", \"originalData_Order\"]\n\n# create a new 'TTK IdentifierRandomizer'\ntTKIdentifierRandomizer2 = TTKIdentifierRandomizer(\n    Input=OutputPort(tTKMorseSmaleComplex2, 3)\n)\ntTKIdentifierRandomizer2.ScalarField = [\"POINTS\", \"AscendingManifold\"]\n\n# save the output\nSaveData(\"tribute_segmentation.vti\", tTKIdentifierRandomizer2)\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/tribute.py\n</code></pre></p>"},{"location":"tribute/#inputs","title":"Inputs","text":"<ul> <li>tribute.png: PNG image of a microscopy of cell sheet morphogenesis (from Edelsbrunner &amp; Harer's book, page 217)</li> </ul>"},{"location":"tribute/#outputs","title":"Outputs","text":"<ul> <li><code>triubute_segmentation.vtu</code>: segmentation of <code>tribute.png</code> into cells (Morse\u2013Smale complex; data array <code>AscendingManifold</code>)</li> </ul>"},{"location":"tribute/#cpython-api","title":"C++/Python API","text":"<p>IdentifierRandomizer </p> <p>MorseSmaleComplex </p> <p>PersistenceDiagram </p> <p>TopologicalSimplification </p>"},{"location":"uncertainStartingVortex/","title":"Uncertain Starting Vortex","text":""},{"location":"uncertainStartingVortex/#pipeline-description","title":"Pipeline description","text":"<p>This example loads an uncertain 2D wing simulation (obtained from an ensemble simulation). This input data contains the upper and lower bounds for the simulation results as two separate scalar fields.</p> <p>Using both fields, the MandatoryCriticalPoints, representing areas that are guaranteed to locate a critical point of the selected type in any possible realization, are computed (both left views show them as areas in blue for minima and green for maxima).</p> <p>A realization of the simulation is created by using a normalized random scalar field, interpolating between the lower and upper bound using the random scalar at each point. </p> <p>As this process introduces noise, a PersistenceDiagram is created (both right views).</p> <p>From it, first all point pairs are extracted, then retrieving a persistence threshold that is used as a constraint for the TopologicalSimplification to filter the introduced noise.</p> <p>At last, the ScalarFieldCriticalPoints (top left view, above screenshot) are computed for the smoothed realization (both left views show them as spheres). The critial points extracted from this random realization are indeed located within the regions predicted by the MandatoryCriticalPoints.</p>"},{"location":"uncertainStartingVortex/#paraview","title":"ParaView","text":"<p>To reproduce the above screenshot, go to your ttk-data directory and enter the following command: <pre><code>paraview states/uncertainStartingVortex.pvsm\n</code></pre></p>"},{"location":"uncertainStartingVortex/#python-code","title":"Python code","text":"<pre><code>#!/usr/bin/env python\n\nfrom paraview.simple import *\n\n# create a new 'XML Image Data Reader'\nuncertainStartingVortexvti = XMLImageDataReader(\n    FileName=[\"uncertainStartingVortex.vti\"]\n)\n\n# create a new 'TTK MandatoryCriticalPoints'\ntTKMandatoryCriticalPoints1 = TTKMandatoryCriticalPoints(\n    Input=uncertainStartingVortexvti\n)\ntTKMandatoryCriticalPoints1.LowerBoundField = [\"POINTS\", \"lowerBoundField\"]\ntTKMandatoryCriticalPoints1.UpperBoundField = [\"POINTS\", \"upperBoundField\"]\ntTKMandatoryCriticalPoints1.NormalizedThreshold = 0.02\n\n# create a new 'Threshold' for the Minimas\nthreshold6 = Threshold(Input=tTKMandatoryCriticalPoints1)\nthreshold6.Scalars = [\"POINTS\", \"MinimumComponents\"]\nthreshold6.ThresholdMethod = \"Between\"\nthreshold6.LowerThreshold = 0.0\nthreshold6.UpperThreshold = 2.0\n\n# create a new 'Threshold' for the maximas\nthreshold5 = Threshold(Input=OutputPort(tTKMandatoryCriticalPoints1, 3))\nthreshold5.Scalars = [\"POINTS\", \"MaximumComponents\"]\nthreshold5.ThresholdMethod = \"Between\"\nthreshold5.LowerThreshold = 0.0\nthreshold5.UpperThreshold = 8.0\n\n# create a new 'Random Attributes'\nrandomAttributes1 = RandomAttributes(Input=uncertainStartingVortexvti)\nrandomAttributes1.DataType = \"Double\"\nrandomAttributes1.ComponentRange = [0.0, 0.999]\nrandomAttributes1.GeneratePointScalars = 1\n\n# create a new 'Calculator'\ncalculator1 = Calculator(Input=randomAttributes1)\ncalculator1.ResultArrayName = \"realization0\"\ncalculator1.Function = (\n    \"lowerBoundField+(upperBoundField-lowerBoundField)*RandomPointScalars\"\n)\n\n# create a new 'TTK PersistenceDiagram'\ntTKPersistenceDiagram1 = TTKPersistenceDiagram(Input=calculator1)\ntTKPersistenceDiagram1.ScalarField = [\"POINTS\", \"realization0\"]\n\n# create a new 'Threshold'\nthreshold2 = Threshold(Input=tTKPersistenceDiagram1)\nthreshold2.Scalars = [\"CELLS\", \"PairIdentifier\"]\nthreshold2.ThresholdMethod = \"Between\"\nthreshold2.LowerThreshold = 0.0\nthreshold2.UpperThreshold = 185374.0\n\n# create a new 'Threshold'\npersistenceThreshold1 = Threshold(Input=threshold2)\npersistenceThreshold1.Scalars = [\"CELLS\", \"Persistence\"]\npersistenceThreshold1.ThresholdMethod = \"Between\"\npersistenceThreshold1.LowerThreshold = 0.05\npersistenceThreshold1.UpperThreshold = 1.75475390406744\n\n# create a new 'TTK TopologicalSimplification'\ntTKTopologicalSimplification1 = TTKTopologicalSimplification(\n    Domain=calculator1, Constraints=persistenceThreshold1\n)\ntTKTopologicalSimplification1.ScalarField = [\"POINTS\", \"realization0\"]\n\n# create a new 'TTK ScalarFieldCriticalPoints'\ntTKScalarFieldCriticalPoints1 = TTKScalarFieldCriticalPoints(\n    Input=tTKTopologicalSimplification1\n)\ntTKScalarFieldCriticalPoints1.ScalarField = [\"POINTS\", \"realization0\"]\n\nSaveData(\"PersistenceDiagram.vtu\", tTKPersistenceDiagram1)\nSaveData(\"CriticalPoints.vtp\", tTKScalarFieldCriticalPoints1)\nSaveData(\"MandatoryCriticalMinima.csv\", OutputPort(tTKMandatoryCriticalPoints1, 0))\nSaveData(\"MandatoryCriticalMaxima.csv\", OutputPort(tTKMandatoryCriticalPoints1, 3))\n</code></pre> <p>To run the above Python script, go to your ttk-data directory and enter the following command: <pre><code>pvpython python/uncertainStartingVortex.py\n</code></pre></p>"},{"location":"uncertainStartingVortex/#inputs","title":"Inputs","text":"<ul> <li>uncertainStartingVortex.vti: two two-dimensional scalar fields.</li> </ul>"},{"location":"uncertainStartingVortex/#outputs","title":"Outputs","text":"<ul> <li><code>PersistenceDiagram.vtu</code>: the output persistence diagram in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtu</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>CriticalPoints.vtp</code>: the output critical points in VTK file format (bottom right view, above screenshot). You are free to change the <code>vtp</code> file extension to that of any other supported file format (e.g. <code>csv</code>) in the above python script.</li> <li><code>MandatoryCriticalMinima.csv</code>: the output mandatory critical minima points (both left views, blue areas).</li> <li><code>MandatoryCriticalMaxima.csv</code>: the output mandatory critical maxima points (both left views, green areas).</li> </ul>"},{"location":"uncertainStartingVortex/#cpython-api","title":"C++/Python API","text":"<p>MandatoryCriticalPoints</p> <p>PersistenceDiagram</p> <p>ScalarFieldCriticalPoints</p> <p>TopologicalSimplification</p>"}]}